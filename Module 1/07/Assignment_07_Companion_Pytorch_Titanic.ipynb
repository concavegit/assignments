{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 07 Companion - Pytorch Titanic",
      "provenance": [],
      "collapsed_sections": [
        "4i9WpTVdnXjS",
        "SPZY74FfqAT8"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlfa19/assignments/blob/master/Module%201/07/Assignment_07_Companion_Pytorch_Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-WMGMuojr6D",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch and Titanic\n",
        "\n",
        "Now that you've seen the very basics of how to use `pytorch`, we're going to see how to apply it to a machine learning problem.  Along the way we'll make connections back to the Titanic dataset and help solidify your understanding of the connection between the math we've been learning and the code we'll be writing using `pytorch`.\n",
        "\n",
        "To get started, let's load our trusty Titanic dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDXQfYGol5kt",
        "colab_type": "code",
        "outputId": "4a34e8b7-c0a1-4506-ed5d-b019a3d4be03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import gdown\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "gdown.download('https://drive.google.com/uc?authuser=0&id=1XIFiL3WxxR6M2nWgADi3xWvuRO6A-Ov8&export=download', 'titanic_train.csv', False)\n",
        "df = pd.read_csv('titanic_train.csv')\n",
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?authuser=0&id=1XIFiL3WxxR6M2nWgADi3xWvuRO6A-Ov8&export=download\n",
            "To: /content/titanic_train.csv\n",
            "100%|██████████| 61.2k/61.2k [00:00<00:00, 35.3MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Moran, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330877</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>McCarthy, Mr. Timothy J</td>\n",
              "      <td>male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17463</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>E46</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Palsson, Master. Gosta Leonard</td>\n",
              "      <td>male</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>349909</td>\n",
              "      <td>21.0750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
              "      <td>female</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>347742</td>\n",
              "      <td>11.1333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
              "      <td>female</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>237736</td>\n",
              "      <td>30.0708</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
              "      <td>female</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PP 9549</td>\n",
              "      <td>16.7000</td>\n",
              "      <td>G6</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Bonnell, Miss. Elizabeth</td>\n",
              "      <td>female</td>\n",
              "      <td>58.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>113783</td>\n",
              "      <td>26.5500</td>\n",
              "      <td>C103</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Saundercock, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5. 2151</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Andersson, Mr. Anders Johan</td>\n",
              "      <td>male</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>347082</td>\n",
              "      <td>31.2750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
              "      <td>female</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>350406</td>\n",
              "      <td>7.8542</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
              "      <td>female</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>248706</td>\n",
              "      <td>16.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Rice, Master. Eugene</td>\n",
              "      <td>male</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>382652</td>\n",
              "      <td>29.1250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Williams, Mr. Charles Eugene</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>244373</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
              "      <td>female</td>\n",
              "      <td>31.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>345763</td>\n",
              "      <td>18.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Masselmani, Mrs. Fatima</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2649</td>\n",
              "      <td>7.2250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Fynney, Mr. Joseph J</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>239865</td>\n",
              "      <td>26.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Beesley, Mr. Lawrence</td>\n",
              "      <td>male</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>248698</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>D56</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>McGowan, Miss. Anna \"Annie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330923</td>\n",
              "      <td>8.0292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Sloper, Mr. William Thompson</td>\n",
              "      <td>male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>113788</td>\n",
              "      <td>35.5000</td>\n",
              "      <td>A6</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Palsson, Miss. Torborg Danira</td>\n",
              "      <td>female</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>349909</td>\n",
              "      <td>21.0750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>347077</td>\n",
              "      <td>31.3875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Emir, Mr. Farred Chehab</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2631</td>\n",
              "      <td>7.2250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Fortune, Mr. Charles Alexander</td>\n",
              "      <td>male</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>19950</td>\n",
              "      <td>263.0000</td>\n",
              "      <td>C23 C25 C27</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330959</td>\n",
              "      <td>7.8792</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Todoroff, Mr. Lalio</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>349216</td>\n",
              "      <td>7.8958</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>861</th>\n",
              "      <td>862</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Giles, Mr. Frederick Edward</td>\n",
              "      <td>male</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>28134</td>\n",
              "      <td>11.5000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>862</th>\n",
              "      <td>863</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Swift, Mrs. Frederick Joel (Margaret Welles Ba...</td>\n",
              "      <td>female</td>\n",
              "      <td>48.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17466</td>\n",
              "      <td>25.9292</td>\n",
              "      <td>D17</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>863</th>\n",
              "      <td>864</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>CA. 2343</td>\n",
              "      <td>69.5500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>864</th>\n",
              "      <td>865</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Gill, Mr. John William</td>\n",
              "      <td>male</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>233866</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>866</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Bystrom, Mrs. (Karolina)</td>\n",
              "      <td>female</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>236852</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>866</th>\n",
              "      <td>867</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Duran y More, Miss. Asuncion</td>\n",
              "      <td>female</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>SC/PARIS 2149</td>\n",
              "      <td>13.8583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>867</th>\n",
              "      <td>868</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Roebling, Mr. Washington Augustus II</td>\n",
              "      <td>male</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17590</td>\n",
              "      <td>50.4958</td>\n",
              "      <td>A24</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>868</th>\n",
              "      <td>869</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>van Melkebeke, Mr. Philemon</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>345777</td>\n",
              "      <td>9.5000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>869</th>\n",
              "      <td>870</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnson, Master. Harold Theodor</td>\n",
              "      <td>male</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>347742</td>\n",
              "      <td>11.1333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>870</th>\n",
              "      <td>871</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Balkic, Mr. Cerin</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>349248</td>\n",
              "      <td>7.8958</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>871</th>\n",
              "      <td>872</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11751</td>\n",
              "      <td>52.5542</td>\n",
              "      <td>D35</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>872</th>\n",
              "      <td>873</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Carlsson, Mr. Frans Olof</td>\n",
              "      <td>male</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>695</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>B51 B53 B55</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>873</th>\n",
              "      <td>874</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Vander Cruyssen, Mr. Victor</td>\n",
              "      <td>male</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>345765</td>\n",
              "      <td>9.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>874</th>\n",
              "      <td>875</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Abelson, Mrs. Samuel (Hannah Wizosky)</td>\n",
              "      <td>female</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>P/PP 3381</td>\n",
              "      <td>24.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>875</th>\n",
              "      <td>876</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Najib, Miss. Adele Kiamie \"Jane\"</td>\n",
              "      <td>female</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2667</td>\n",
              "      <td>7.2250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>876</th>\n",
              "      <td>877</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Gustafsson, Mr. Alfred Ossian</td>\n",
              "      <td>male</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7534</td>\n",
              "      <td>9.8458</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>877</th>\n",
              "      <td>878</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Petroff, Mr. Nedelio</td>\n",
              "      <td>male</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>349212</td>\n",
              "      <td>7.8958</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>878</th>\n",
              "      <td>879</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Laleff, Mr. Kristo</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>349217</td>\n",
              "      <td>7.8958</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>879</th>\n",
              "      <td>880</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)</td>\n",
              "      <td>female</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>11767</td>\n",
              "      <td>83.1583</td>\n",
              "      <td>C50</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>880</th>\n",
              "      <td>881</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Shelley, Mrs. William (Imanita Parrish Hall)</td>\n",
              "      <td>female</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>230433</td>\n",
              "      <td>26.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>881</th>\n",
              "      <td>882</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Markun, Mr. Johann</td>\n",
              "      <td>male</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>349257</td>\n",
              "      <td>7.8958</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>882</th>\n",
              "      <td>883</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dahlberg, Miss. Gerda Ulrika</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7552</td>\n",
              "      <td>10.5167</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>883</th>\n",
              "      <td>884</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Banfield, Mr. Frederick James</td>\n",
              "      <td>male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>C.A./SOTON 34068</td>\n",
              "      <td>10.5000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884</th>\n",
              "      <td>885</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Sutehall, Mr. Henry Jr</td>\n",
              "      <td>male</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>SOTON/OQ 392076</td>\n",
              "      <td>7.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885</th>\n",
              "      <td>886</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Rice, Mrs. William (Margaret Norton)</td>\n",
              "      <td>female</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>382652</td>\n",
              "      <td>29.1250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...      Fare        Cabin  Embarked\n",
              "0              1         0       3  ...    7.2500          NaN         S\n",
              "1              2         1       1  ...   71.2833          C85         C\n",
              "2              3         1       3  ...    7.9250          NaN         S\n",
              "3              4         1       1  ...   53.1000         C123         S\n",
              "4              5         0       3  ...    8.0500          NaN         S\n",
              "5              6         0       3  ...    8.4583          NaN         Q\n",
              "6              7         0       1  ...   51.8625          E46         S\n",
              "7              8         0       3  ...   21.0750          NaN         S\n",
              "8              9         1       3  ...   11.1333          NaN         S\n",
              "9             10         1       2  ...   30.0708          NaN         C\n",
              "10            11         1       3  ...   16.7000           G6         S\n",
              "11            12         1       1  ...   26.5500         C103         S\n",
              "12            13         0       3  ...    8.0500          NaN         S\n",
              "13            14         0       3  ...   31.2750          NaN         S\n",
              "14            15         0       3  ...    7.8542          NaN         S\n",
              "15            16         1       2  ...   16.0000          NaN         S\n",
              "16            17         0       3  ...   29.1250          NaN         Q\n",
              "17            18         1       2  ...   13.0000          NaN         S\n",
              "18            19         0       3  ...   18.0000          NaN         S\n",
              "19            20         1       3  ...    7.2250          NaN         C\n",
              "20            21         0       2  ...   26.0000          NaN         S\n",
              "21            22         1       2  ...   13.0000          D56         S\n",
              "22            23         1       3  ...    8.0292          NaN         Q\n",
              "23            24         1       1  ...   35.5000           A6         S\n",
              "24            25         0       3  ...   21.0750          NaN         S\n",
              "25            26         1       3  ...   31.3875          NaN         S\n",
              "26            27         0       3  ...    7.2250          NaN         C\n",
              "27            28         0       1  ...  263.0000  C23 C25 C27         S\n",
              "28            29         1       3  ...    7.8792          NaN         Q\n",
              "29            30         0       3  ...    7.8958          NaN         S\n",
              "..           ...       ...     ...  ...       ...          ...       ...\n",
              "861          862         0       2  ...   11.5000          NaN         S\n",
              "862          863         1       1  ...   25.9292          D17         S\n",
              "863          864         0       3  ...   69.5500          NaN         S\n",
              "864          865         0       2  ...   13.0000          NaN         S\n",
              "865          866         1       2  ...   13.0000          NaN         S\n",
              "866          867         1       2  ...   13.8583          NaN         C\n",
              "867          868         0       1  ...   50.4958          A24         S\n",
              "868          869         0       3  ...    9.5000          NaN         S\n",
              "869          870         1       3  ...   11.1333          NaN         S\n",
              "870          871         0       3  ...    7.8958          NaN         S\n",
              "871          872         1       1  ...   52.5542          D35         S\n",
              "872          873         0       1  ...    5.0000  B51 B53 B55         S\n",
              "873          874         0       3  ...    9.0000          NaN         S\n",
              "874          875         1       2  ...   24.0000          NaN         C\n",
              "875          876         1       3  ...    7.2250          NaN         C\n",
              "876          877         0       3  ...    9.8458          NaN         S\n",
              "877          878         0       3  ...    7.8958          NaN         S\n",
              "878          879         0       3  ...    7.8958          NaN         S\n",
              "879          880         1       1  ...   83.1583          C50         C\n",
              "880          881         1       2  ...   26.0000          NaN         S\n",
              "881          882         0       3  ...    7.8958          NaN         S\n",
              "882          883         0       3  ...   10.5167          NaN         S\n",
              "883          884         0       2  ...   10.5000          NaN         S\n",
              "884          885         0       3  ...    7.0500          NaN         S\n",
              "885          886         0       3  ...   29.1250          NaN         Q\n",
              "886          887         0       2  ...   13.0000          NaN         S\n",
              "887          888         1       1  ...   30.0000          B42         S\n",
              "888          889         0       3  ...   23.4500          NaN         S\n",
              "889          890         1       1  ...   30.0000         C148         C\n",
              "890          891         0       3  ...    7.7500          NaN         Q\n",
              "\n",
              "[891 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlzr7ee_kZAn",
        "colab_type": "text"
      },
      "source": [
        "In the Assignment 6 companion notebook we fit two models:\n",
        "1.  We used the `Age` and `Sex` columns along with a synthetic feature called `is young male` as inputs to a logistic regression model in order to predict whether someone survived.\n",
        "2.  We used just the `Age` and `Sex` as inputs to a multilayer perceptron model in order to predict whether someone survived.\n",
        "\n",
        "In this notebook we'll be implementing both of these models in `pytorch`.  To get started, let's perform the following data processing / cleaning steps.\n",
        "1.  Get rid of any passengers where we don't know their age (don't do this in a real machine learning application as it will skew your results).\n",
        "2.  Convert the `Sex` column to a dummy variable called `male` that will take on value 1 if the passenger is male and 0 otherwise.\n",
        "3.  Create the `is young male` column that will be 1 for males under the age of 5 and 0 for everyone else."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmJqj_5omDmF",
        "colab_type": "code",
        "outputId": "efbb4c35-c87a-4dac-ed14-9634b167afa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# get rid of null values for age since this is just an illustrative example.\n",
        "# this would not be a good thing to do if we were trying to evalutate the \n",
        "# performance of a model.\n",
        "df_filtered = df[['Age', 'Sex', 'Survived']].dropna()\n",
        "is_young_male = ((df_filtered['Sex'] == 'male') & (df_filtered['Age'] < 5)).astype(int)\n",
        "is_young_male.name = 'is_young_male'\n",
        "experiment_1_data = pd.concat((pd.get_dummies(df_filtered['Sex'], drop_first=True), df_filtered['Age'], is_young_male), axis=1)\n",
        "experiment_1_outputs = df_filtered['Survived']\n",
        "experiment_1_data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>male</th>\n",
              "      <th>Age</th>\n",
              "      <th>is_young_male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1</td>\n",
              "      <td>66.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>1</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>1</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>856</th>\n",
              "      <td>0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857</th>\n",
              "      <td>1</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>1</td>\n",
              "      <td>41.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>861</th>\n",
              "      <td>1</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>862</th>\n",
              "      <td>0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>864</th>\n",
              "      <td>1</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>866</th>\n",
              "      <td>0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>867</th>\n",
              "      <td>1</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>869</th>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>870</th>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>871</th>\n",
              "      <td>0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>872</th>\n",
              "      <td>1</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>873</th>\n",
              "      <td>1</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>874</th>\n",
              "      <td>0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>875</th>\n",
              "      <td>0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>876</th>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>877</th>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>879</th>\n",
              "      <td>0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>880</th>\n",
              "      <td>0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>881</th>\n",
              "      <td>1</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>882</th>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>883</th>\n",
              "      <td>1</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884</th>\n",
              "      <td>1</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885</th>\n",
              "      <td>0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>1</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>714 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     male   Age  is_young_male\n",
              "0       1  22.0              0\n",
              "1       0  38.0              0\n",
              "2       0  26.0              0\n",
              "3       0  35.0              0\n",
              "4       1  35.0              0\n",
              "6       1  54.0              0\n",
              "7       1   2.0              1\n",
              "8       0  27.0              0\n",
              "9       0  14.0              0\n",
              "10      0   4.0              0\n",
              "11      0  58.0              0\n",
              "12      1  20.0              0\n",
              "13      1  39.0              0\n",
              "14      0  14.0              0\n",
              "15      0  55.0              0\n",
              "16      1   2.0              1\n",
              "18      0  31.0              0\n",
              "20      1  35.0              0\n",
              "21      1  34.0              0\n",
              "22      0  15.0              0\n",
              "23      1  28.0              0\n",
              "24      0   8.0              0\n",
              "25      0  38.0              0\n",
              "27      1  19.0              0\n",
              "30      1  40.0              0\n",
              "33      1  66.0              0\n",
              "34      1  28.0              0\n",
              "35      1  42.0              0\n",
              "37      1  21.0              0\n",
              "38      0  18.0              0\n",
              "..    ...   ...            ...\n",
              "856     0  45.0              0\n",
              "857     1  51.0              0\n",
              "858     0  24.0              0\n",
              "860     1  41.0              0\n",
              "861     1  21.0              0\n",
              "862     0  48.0              0\n",
              "864     1  24.0              0\n",
              "865     0  42.0              0\n",
              "866     0  27.0              0\n",
              "867     1  31.0              0\n",
              "869     1   4.0              1\n",
              "870     1  26.0              0\n",
              "871     0  47.0              0\n",
              "872     1  33.0              0\n",
              "873     1  47.0              0\n",
              "874     0  28.0              0\n",
              "875     0  15.0              0\n",
              "876     1  20.0              0\n",
              "877     1  19.0              0\n",
              "879     0  56.0              0\n",
              "880     0  25.0              0\n",
              "881     1  33.0              0\n",
              "882     0  22.0              0\n",
              "883     1  28.0              0\n",
              "884     1  25.0              0\n",
              "885     0  39.0              0\n",
              "886     1  27.0              0\n",
              "887     0  19.0              0\n",
              "889     1  26.0              0\n",
              "890     1  32.0              0\n",
              "\n",
              "[714 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRCuTGuklo8i",
        "colab_type": "text"
      },
      "source": [
        "Next, we'll go ahead and build our logistic regression model just as we did in the assignment 6 companion notebook.  The only small twist we will introduce is turning off the ridge term of the model so that it will make comparing the results from this analysis to what we do in pytorch easier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPcsVBFeloVB",
        "colab_type": "code",
        "outputId": "b025fd17-7a91-4f39-bf18-ae35f87d2176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(solver='lbfgs', penalty='none') # setting solve silences annoying warning\n",
        "model.fit(experiment_1_data, experiment_1_outputs)\n",
        "print(\"coefs\", model.coef_)\n",
        "print(\"intercept\", model.intercept_)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "coefs [[-2.67342472  0.00808732  2.38307187]]\n",
            "intercept [0.9018627]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOUL_e0Ql-Ve",
        "colab_type": "text"
      },
      "source": [
        "### Notebook Exercise 1 (10 minutes)\n",
        "\n",
        "This is a bit of review.  Provide an interpretation for the coefficients learned by the logistic regression model (e.g., what do they mean for the prediction of whether a passenger would survive)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i9WpTVdnXjS",
        "colab_type": "text"
      },
      "source": [
        "#### *Expand for Solution*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yyP0Nr5nnMK",
        "colab_type": "text"
      },
      "source": [
        "***Solution***\n",
        "\n",
        "The negative coefficient for the first feature means that male passengers ($x_1=1$) were less likely to survive than female passenngers ($x_1=0$).  The slightly positive coefficient for the second feature (age) means that older passengers were more likely to survive (the effect is not strong though).  The large and positive weight for `is young male` means that those passengers had a much higher survival rate in comparison with older males."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHE5P--nmhN8",
        "colab_type": "text"
      },
      "source": [
        "## Reimplementation in Pytorch\n",
        "\n",
        "Next, we'll be using `pytorch` to implement our own version of logistic regression!  When creating a neural network model (remember, we can think of logistic regression as a perceptron with 2 layers, an input and an output), you create a class that inherits from `nn.Module`.  We'll give you an implementation of logistic regression and then give a detailed breakdown of the key lines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBY7RqSWmT_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class LogisticRegressionPytorch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LogisticRegressionPytorch, self).__init__()\n",
        "        self.linear = nn.Linear(3,1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\" Propagate data through the network.\n",
        "\n",
        "            This model first applies the linear layer and then a sigmoid\n",
        "        \"\"\"\n",
        "        X = self.linear(X)\n",
        "        return torch.sigmoid(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQu4NKeOoC6Q",
        "colab_type": "text"
      },
      "source": [
        "Here is a breakdown of some of the key lines in this implementation.\n",
        "\n",
        "Inherit from the super class `nn.Module`:\n",
        "```python\n",
        "class LogisticRegressionPytorch(nn.Module):\n",
        "```\n",
        "\n",
        "Since we're inheriting from `nn.Module`, we need to make sure to call the `__init__` method of `nn.Module` when initializating our class.\n",
        "```python\n",
        "super(LogisticRegressionPytorch, self).__init__()\n",
        "```\n",
        "\n",
        "The linear layer will store the weight vector of our model.  The $3$ arises from the fact that our model will have 3 inputs (age, male, and is young male).  It is very important that you store your layers as attributes of your class.  This is how `pytorch` knows about them and can optimize them.  If you need to have a list of layers, look into `nn.ModuleList`.\n",
        "\n",
        "```python\n",
        "self.linear = nn.Linear(3,1)\n",
        "```\n",
        "\n",
        "The `forward` function is the heart of the model.  It runs input data through the network and returns the output.  Writing such functions usually amounts to passing data between the various layers that were created in the `__init__` method.  The syntax for this is a little funny.  For instance, in the code below, `self.linear(X)` implicitly calls the `forward` function of the `nn.Linear` class.  Yes, we find this kind of weird, but that's how it's done in `pytorch`.  Thius is really just a syntactic quirk rather than anything substantive that you need to worry about.  The last step of the function involves applying the `sigmoid` and returning the result.\n",
        "\n",
        "Next, we'll show how to pass some data into the model.\n",
        "\n",
        "```python\n",
        "def forward(self, X):\n",
        "    \"\"\" Propagate data through the network.\n",
        "\n",
        "        This model first applies the linear layer and then a sigmoid\n",
        "    \"\"\"\n",
        "    X = self.linear(X)\n",
        "    return torch.sigmoid(X)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOfiM3_wpvvI",
        "colab_type": "code",
        "outputId": "2ffd6f35-bce5-42f7-9ddf-9b9d5bc7ec7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# sample_data represents a male passenger who is 10 years old\n",
        "sample_data = Variable(torch.FloatTensor([1.0, 10.0, 0.0]))\n",
        "model_pytorch = LogisticRegressionPytorch()\n",
        "model_pytorch(sample_data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0079], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80wRe1EvqNcG",
        "colab_type": "text"
      },
      "source": [
        "The code we computed the probability that the specific passenger would survive.  It is very important to realize that right now the model *has not been trained*.  This means that we don't expect the output of the model to make any sense (although it might just by chance).  If you rerun the code repeatedly, you'll get different results due to the fact that the weights are initialized randomly.\n",
        "\n",
        "Next, we're going to actually train the network!  This is where things get interesting.  Run the code and either look through the code on your own or look below for a line-by-line breakdown."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZB9XkoLpoO7",
        "colab_type": "code",
        "outputId": "fae3ef8a-4eec-4789-ba00-64c5c1cf7d73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_pytorch = LogisticRegressionPytorch()\n",
        "model_pytorch.train()\n",
        "\n",
        "optimizer = torch.optim.SGD(model_pytorch.parameters(), lr=0.01)\n",
        "criterion = torch.nn.BCELoss()\n",
        "grad_magnitudes = []\n",
        "\n",
        "X_data = Variable(torch.Tensor(np.array(experiment_1_data)))\n",
        "y_data = Variable(torch.Tensor(np.array(experiment_1_outputs)))\n",
        "for epoch in range(20000):\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    y_pred = model_pytorch(X_data)\n",
        "    # Compute Loss\n",
        "    loss = criterion(y_pred, y_data)\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    for name, param in model_pytorch.named_parameters():\n",
        "        if name == 'linear.weight':\n",
        "            grad_magnitudes.append(np.abs(param.grad.numpy()).mean())\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(\"epoch\", epoch)\n",
        "        for name, param in model_pytorch.named_parameters():\n",
        "            print(name, \"value\", param.data, \"gradient\", param.grad)\n",
        "    optimizer.step()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(grad_magnitudes)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('average magnitude of weight gradient')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:512: UserWarning: Using a target size (torch.Size([714])) that is different to the input size (torch.Size([714, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0\n",
            "linear.weight value tensor([[-0.1913, -0.0223, -0.2724]]) gradient tensor([[ 0.0378, -3.9375, -0.0101]])\n",
            "linear.bias value tensor([-0.1534]) gradient tensor([-0.1215])\n",
            "epoch 100\n",
            "linear.weight value tensor([[-0.2959, -0.0545, -0.2622]]) gradient tensor([[-0.0492, -8.3113, -0.0111]])\n",
            "linear.bias value tensor([-0.1342]) gradient tensor([-0.2576])\n",
            "epoch 200\n",
            "linear.weight value tensor([[-0.3953, -0.0531, -0.2515]]) gradient tensor([[-0.0521, -8.2982, -0.0115]])\n",
            "linear.bias value tensor([-0.1129]) gradient tensor([-0.2578])\n",
            "epoch 300\n",
            "linear.weight value tensor([[-0.4904, -0.0518, -0.2404]]) gradient tensor([[-0.0547, -8.2726, -0.0119]])\n",
            "linear.bias value tensor([-0.0908]) gradient tensor([-0.2575])\n",
            "epoch 400\n",
            "linear.weight value tensor([[-0.5814, -0.0504, -0.2290]]) gradient tensor([[-0.0569, -8.2357, -0.0122]])\n",
            "linear.bias value tensor([-0.0679]) gradient tensor([-0.2568])\n",
            "epoch 500\n",
            "linear.weight value tensor([[-0.6686, -0.0491, -0.2171]]) gradient tensor([[-0.0588, -8.1887, -0.0126]])\n",
            "linear.bias value tensor([-0.0445]) gradient tensor([-0.2556])\n",
            "epoch 600\n",
            "linear.weight value tensor([[-0.7521, -0.0478, -0.2050]]) gradient tensor([[-0.0604, -8.1322, -0.0128]])\n",
            "linear.bias value tensor([-0.0205]) gradient tensor([-0.2541])\n",
            "epoch 700\n",
            "linear.weight value tensor([[-0.8322, -0.0465, -0.1926]]) gradient tensor([[-0.0618, -8.0670, -0.0131]])\n",
            "linear.bias value tensor([0.0038]) gradient tensor([-0.2522])\n",
            "epoch 800\n",
            "linear.weight value tensor([[-0.9090, -0.0453, -0.1800]]) gradient tensor([[-0.0630, -7.9936, -0.0133]])\n",
            "linear.bias value tensor([0.0283]) gradient tensor([-0.2500])\n",
            "epoch 900\n",
            "linear.weight value tensor([[-0.9825, -0.0440, -0.1671]]) gradient tensor([[-0.0640, -7.9126, -0.0135]])\n",
            "linear.bias value tensor([0.0531]) gradient tensor([-0.2476])\n",
            "epoch 1000\n",
            "linear.weight value tensor([[-1.0530, -0.0428, -0.1540]]) gradient tensor([[-0.0648, -7.8244, -0.0137]])\n",
            "linear.bias value tensor([0.0780]) gradient tensor([-0.2448])\n",
            "epoch 1100\n",
            "linear.weight value tensor([[-1.1205, -0.0416, -0.1408]]) gradient tensor([[-0.0655, -7.7292, -0.0138]])\n",
            "linear.bias value tensor([0.1029]) gradient tensor([-0.2418])\n",
            "epoch 1200\n",
            "linear.weight value tensor([[-1.1852, -0.0404, -0.1274]]) gradient tensor([[-0.0660, -7.6276, -0.0139]])\n",
            "linear.bias value tensor([0.1279]) gradient tensor([-0.2386])\n",
            "epoch 1300\n",
            "linear.weight value tensor([[-1.2471, -0.0393, -0.1139]]) gradient tensor([[-0.0664, -7.5196, -0.0141]])\n",
            "linear.bias value tensor([0.1528]) gradient tensor([-0.2352])\n",
            "epoch 1400\n",
            "linear.weight value tensor([[-1.3063, -0.0381, -0.1002]]) gradient tensor([[-0.0666, -7.4056, -0.0142]])\n",
            "linear.bias value tensor([0.1776]) gradient tensor([-0.2316])\n",
            "epoch 1500\n",
            "linear.weight value tensor([[-1.3630, -0.0370, -0.0864]]) gradient tensor([[-0.0667, -7.2858, -0.0142]])\n",
            "linear.bias value tensor([0.2022]) gradient tensor([-0.2278])\n",
            "epoch 1600\n",
            "linear.weight value tensor([[-1.4172, -0.0358, -0.0726]]) gradient tensor([[-0.0667, -7.1604, -0.0143]])\n",
            "linear.bias value tensor([0.2266]) gradient tensor([-0.2238])\n",
            "epoch 1700\n",
            "linear.weight value tensor([[-1.4689, -0.0347, -0.0587]]) gradient tensor([[-0.0666, -7.0296, -0.0144]])\n",
            "linear.bias value tensor([0.2508]) gradient tensor([-0.2196])\n",
            "epoch 1800\n",
            "linear.weight value tensor([[-1.5183, -0.0336, -0.0447]]) gradient tensor([[-0.0664, -6.8936, -0.0144]])\n",
            "linear.bias value tensor([0.2748]) gradient tensor([-0.2153])\n",
            "epoch 1900\n",
            "linear.weight value tensor([[-1.5653, -0.0325, -0.0307]]) gradient tensor([[-0.0661, -6.7525, -0.0145]])\n",
            "linear.bias value tensor([0.2984]) gradient tensor([-0.2108])\n",
            "epoch 2000\n",
            "linear.weight value tensor([[-1.6102, -0.0315, -0.0166]]) gradient tensor([[-0.0656, -6.6065, -0.0145]])\n",
            "linear.bias value tensor([0.3218]) gradient tensor([-0.2062])\n",
            "epoch 2100\n",
            "linear.weight value tensor([[-1.6528, -0.0304, -0.0025]]) gradient tensor([[-0.0651, -6.4557, -0.0145]])\n",
            "linear.bias value tensor([0.3448]) gradient tensor([-0.2014])\n",
            "epoch 2200\n",
            "linear.weight value tensor([[-1.6934, -0.0293,  0.0117]]) gradient tensor([[-0.0644, -6.3003, -0.0145]])\n",
            "linear.bias value tensor([0.3674]) gradient tensor([-0.1965])\n",
            "epoch 2300\n",
            "linear.weight value tensor([[-1.7319, -0.0283,  0.0258]]) gradient tensor([[-0.0637, -6.1403, -0.0145]])\n",
            "linear.bias value tensor([0.3897]) gradient tensor([-0.1915])\n",
            "epoch 2400\n",
            "linear.weight value tensor([[-1.7684, -0.0272,  0.0400]]) gradient tensor([[-0.0628, -5.9759, -0.0145]])\n",
            "linear.bias value tensor([0.4115]) gradient tensor([-0.1863])\n",
            "epoch 2500\n",
            "linear.weight value tensor([[-1.8030, -0.0261,  0.0541]]) gradient tensor([[-0.0619, -5.8072, -0.0145]])\n",
            "linear.bias value tensor([0.4329]) gradient tensor([-0.1810])\n",
            "epoch 2600\n",
            "linear.weight value tensor([[-1.8357, -0.0251,  0.0683]]) gradient tensor([[-0.0608, -5.6342, -0.0145]])\n",
            "linear.bias value tensor([0.4539]) gradient tensor([-0.1757])\n",
            "epoch 2700\n",
            "linear.weight value tensor([[-1.8666, -0.0240,  0.0824]]) gradient tensor([[-0.0596, -5.4571, -0.0144]])\n",
            "linear.bias value tensor([0.4744]) gradient tensor([-0.1702])\n",
            "epoch 2800\n",
            "linear.weight value tensor([[-1.8957, -0.0230,  0.0965]]) gradient tensor([[-0.0584, -5.2759, -0.0144]])\n",
            "linear.bias value tensor([0.4945]) gradient tensor([-0.1646])\n",
            "epoch 2900\n",
            "linear.weight value tensor([[-1.9232, -0.0219,  0.1106]]) gradient tensor([[-0.0570, -5.0905, -0.0143]])\n",
            "linear.bias value tensor([0.5141]) gradient tensor([-0.1588])\n",
            "epoch 3000\n",
            "linear.weight value tensor([[-1.9490, -0.0209,  0.1246]]) gradient tensor([[-0.0555, -4.9010, -0.0143]])\n",
            "linear.bias value tensor([0.5332]) gradient tensor([-0.1530])\n",
            "epoch 3100\n",
            "linear.weight value tensor([[-1.9732, -0.0198,  0.1386]]) gradient tensor([[-0.0539, -4.7074, -0.0142]])\n",
            "linear.bias value tensor([0.5518]) gradient tensor([-0.1471])\n",
            "epoch 3200\n",
            "linear.weight value tensor([[-1.9959, -0.0188,  0.1525]]) gradient tensor([[-0.0521, -4.5096, -0.0142]])\n",
            "linear.bias value tensor([0.5699]) gradient tensor([-0.1411])\n",
            "epoch 3300\n",
            "linear.weight value tensor([[-2.0171, -0.0177,  0.1664]]) gradient tensor([[-0.0503, -4.3074, -0.0141]])\n",
            "linear.bias value tensor([0.5875]) gradient tensor([-0.1350])\n",
            "epoch 3400\n",
            "linear.weight value tensor([[-2.0369, -0.0166,  0.1802]]) gradient tensor([[-0.0483, -4.1006, -0.0140]])\n",
            "linear.bias value tensor([0.6046]) gradient tensor([-0.1287])\n",
            "epoch 3500\n",
            "linear.weight value tensor([[-2.0554, -0.0155,  0.1940]]) gradient tensor([[-0.0462, -3.8889, -0.0140]])\n",
            "linear.bias value tensor([0.6211]) gradient tensor([-0.1224])\n",
            "epoch 3600\n",
            "linear.weight value tensor([[-2.0727, -0.0144,  0.2077]]) gradient tensor([[-0.0439, -3.6718, -0.0139]])\n",
            "linear.bias value tensor([0.6372]) gradient tensor([-0.1159])\n",
            "epoch 3700\n",
            "linear.weight value tensor([[-2.0887, -0.0133,  0.2213]]) gradient tensor([[-0.0414, -3.4489, -0.0138]])\n",
            "linear.bias value tensor([0.6527]) gradient tensor([-0.1092])\n",
            "epoch 3800\n",
            "linear.weight value tensor([[-2.1035, -0.0121,  0.2348]]) gradient tensor([[-0.0388, -3.2193, -0.0137]])\n",
            "linear.bias value tensor([0.6678]) gradient tensor([-0.1024])\n",
            "epoch 3900\n",
            "linear.weight value tensor([[-2.1172, -0.0110,  0.2483]]) gradient tensor([[-0.0360, -2.9820, -0.0136]])\n",
            "linear.bias value tensor([0.6823]) gradient tensor([-0.0954])\n",
            "epoch 4000\n",
            "linear.weight value tensor([[-2.1300, -0.0097,  0.2617]]) gradient tensor([[-0.0330, -2.7354, -0.0135]])\n",
            "linear.bias value tensor([0.6963]) gradient tensor([-0.0881])\n",
            "epoch 4100\n",
            "linear.weight value tensor([[-2.1417, -0.0085,  0.2750]]) gradient tensor([[-0.0297, -2.4776, -0.0134]])\n",
            "linear.bias value tensor([0.7097]) gradient tensor([-0.0806])\n",
            "epoch 4200\n",
            "linear.weight value tensor([[-2.1525, -0.0072,  0.2882]]) gradient tensor([[-0.0261, -2.2058, -0.0133]])\n",
            "linear.bias value tensor([0.7227]) gradient tensor([-0.0727])\n",
            "epoch 4300\n",
            "linear.weight value tensor([[-2.1625, -0.0058,  0.3013]]) gradient tensor([[-0.0222, -1.9165, -0.0132]])\n",
            "linear.bias value tensor([0.7352]) gradient tensor([-0.0643])\n",
            "epoch 4400\n",
            "linear.weight value tensor([[-2.1717, -0.0043,  0.3143]]) gradient tensor([[-0.0178, -1.6053, -0.0131]])\n",
            "linear.bias value tensor([0.7473]) gradient tensor([-0.0554])\n",
            "epoch 4500\n",
            "linear.weight value tensor([[-2.1803, -0.0026,  0.3272]]) gradient tensor([[-0.0129, -1.2685, -0.0130]])\n",
            "linear.bias value tensor([0.7588]) gradient tensor([-0.0457])\n",
            "epoch 4600\n",
            "linear.weight value tensor([[-2.1882e+00, -9.1807e-04,  3.4007e-01]]) gradient tensor([[-0.0075, -0.9091, -0.0128]])\n",
            "linear.bias value tensor([0.7699]) gradient tensor([-0.0355])\n",
            "epoch 4700\n",
            "linear.weight value tensor([[-2.1956e+00,  7.5940e-04,  3.5280e-01]]) gradient tensor([[-0.0019, -0.5524, -0.0127]])\n",
            "linear.bias value tensor([0.7807]) gradient tensor([-0.0255])\n",
            "epoch 4800\n",
            "linear.weight value tensor([[-2.2027e+00,  2.0932e-03,  3.6544e-01]]) gradient tensor([[ 0.0027, -0.2594, -0.0126]])\n",
            "linear.bias value tensor([0.7910]) gradient tensor([-0.0172])\n",
            "epoch 4900\n",
            "linear.weight value tensor([[-2.2097,  0.0028,  0.3780]]) gradient tensor([[ 0.0055, -0.0868, -0.0125]])\n",
            "linear.bias value tensor([0.8009]) gradient tensor([-0.0122])\n",
            "epoch 5000\n",
            "linear.weight value tensor([[-2.2165,  0.0030,  0.3904]]) gradient tensor([[ 0.0065, -0.0199, -0.0124]])\n",
            "linear.bias value tensor([0.8106]) gradient tensor([-0.0100])\n",
            "epoch 5100\n",
            "linear.weight value tensor([[-2.2233,  0.0029,  0.4028]]) gradient tensor([[ 0.0066, -0.0030, -0.0123]])\n",
            "linear.bias value tensor([0.8199]) gradient tensor([-0.0093])\n",
            "epoch 5200\n",
            "linear.weight value tensor([[-2.2299,  0.0028,  0.4151]]) gradient tensor([[ 0.0066, -0.0002, -0.0122]])\n",
            "linear.bias value tensor([0.8290]) gradient tensor([-0.0089])\n",
            "epoch 5300\n",
            "linear.weight value tensor([[-2.2364,  0.0027,  0.4272]]) gradient tensor([[ 0.0065,  0.0001, -0.0121]])\n",
            "linear.bias value tensor([0.8377]) gradient tensor([-0.0086])\n",
            "epoch 5400\n",
            "linear.weight value tensor([[-2.2428,  0.0026,  0.4393]]) gradient tensor([[ 0.0063,  0.0001, -0.0120]])\n",
            "linear.bias value tensor([0.8462]) gradient tensor([-0.0084])\n",
            "epoch 5500\n",
            "linear.weight value tensor([[-2.2491,  0.0024,  0.4513]]) gradient tensor([[ 0.0062,  0.0001, -0.0119]])\n",
            "linear.bias value tensor([0.8545]) gradient tensor([-0.0081])\n",
            "epoch 5600\n",
            "linear.weight value tensor([[-2.2553,  0.0023,  0.4632]]) gradient tensor([[ 0.0061,  0.0001, -0.0119]])\n",
            "linear.bias value tensor([0.8625]) gradient tensor([-0.0079])\n",
            "epoch 5700\n",
            "linear.weight value tensor([[-2.2614e+00,  2.2230e-03,  4.7502e-01]]) gradient tensor([[ 0.0060,  0.0001, -0.0118]])\n",
            "linear.bias value tensor([0.8702]) gradient tensor([-0.0076])\n",
            "epoch 5800\n",
            "linear.weight value tensor([[-2.2673e+00,  2.1182e-03,  4.8675e-01]]) gradient tensor([[ 0.0059,  0.0001, -0.0117]])\n",
            "linear.bias value tensor([0.8777]) gradient tensor([-0.0074])\n",
            "epoch 5900\n",
            "linear.weight value tensor([[-2.2732e+00,  2.0180e-03,  4.9839e-01]]) gradient tensor([[ 0.0058,  0.0001, -0.0116]])\n",
            "linear.bias value tensor([0.8849]) gradient tensor([-0.0071])\n",
            "epoch 6000\n",
            "linear.weight value tensor([[-2.2790e+00,  1.9223e-03,  5.0995e-01]]) gradient tensor([[ 5.7217e-03,  9.4076e-05, -1.1517e-02]])\n",
            "linear.bias value tensor([0.8920]) gradient tensor([-0.0069])\n",
            "epoch 6100\n",
            "linear.weight value tensor([[-2.2846e+00,  1.8309e-03,  5.2143e-01]]) gradient tensor([[ 5.6227e-03,  8.9941e-05, -1.1434e-02]])\n",
            "linear.bias value tensor([0.8988]) gradient tensor([-0.0067])\n",
            "epoch 6200\n",
            "linear.weight value tensor([[-2.2902e+00,  1.7436e-03,  5.3282e-01]]) gradient tensor([[ 5.5252e-03,  8.6103e-05, -1.1351e-02]])\n",
            "linear.bias value tensor([0.9054]) gradient tensor([-0.0065])\n",
            "epoch 6300\n",
            "linear.weight value tensor([[-2.2957e+00,  1.6603e-03,  5.4413e-01]]) gradient tensor([[ 5.4291e-03,  7.8127e-05, -1.1270e-02]])\n",
            "linear.bias value tensor([0.9118]) gradient tensor([-0.0063])\n",
            "epoch 6400\n",
            "linear.weight value tensor([[-2.3011e+00,  1.5809e-03,  5.5536e-01]]) gradient tensor([[ 5.3345e-03,  7.7276e-05, -1.1189e-02]])\n",
            "linear.bias value tensor([0.9180]) gradient tensor([-0.0061])\n",
            "epoch 6500\n",
            "linear.weight value tensor([[-2.3064e+00,  1.5052e-03,  5.6651e-01]]) gradient tensor([[ 5.2413e-03,  7.1738e-05, -1.1109e-02]])\n",
            "linear.bias value tensor([0.9240]) gradient tensor([-0.0059])\n",
            "epoch 6600\n",
            "linear.weight value tensor([[-2.3116e+00,  1.4331e-03,  5.7758e-01]]) gradient tensor([[ 5.1496e-03,  7.0756e-05, -1.1030e-02]])\n",
            "linear.bias value tensor([0.9298]) gradient tensor([-0.0057])\n",
            "epoch 6700\n",
            "linear.weight value tensor([[-2.3167e+00,  1.3645e-03,  5.8857e-01]]) gradient tensor([[ 5.0593e-03,  6.8600e-05, -1.0951e-02]])\n",
            "linear.bias value tensor([0.9354]) gradient tensor([-0.0055])\n",
            "epoch 6800\n",
            "linear.weight value tensor([[-2.3217e+00,  1.2992e-03,  5.9949e-01]]) gradient tensor([[ 4.9704e-03,  6.5610e-05, -1.0873e-02]])\n",
            "linear.bias value tensor([0.9409]) gradient tensor([-0.0054])\n",
            "epoch 6900\n",
            "linear.weight value tensor([[-2.3266e+00,  1.2371e-03,  6.1032e-01]]) gradient tensor([[ 4.8829e-03,  5.7168e-05, -1.0796e-02]])\n",
            "linear.bias value tensor([0.9461]) gradient tensor([-0.0052])\n",
            "epoch 7000\n",
            "linear.weight value tensor([[-2.3315e+00,  1.1782e-03,  6.2108e-01]]) gradient tensor([[ 4.7970e-03,  5.5568e-05, -1.0720e-02]])\n",
            "linear.bias value tensor([0.9513]) gradient tensor([-0.0050])\n",
            "epoch 7100\n",
            "linear.weight value tensor([[-2.3362e+00,  1.1223e-03,  6.3176e-01]]) gradient tensor([[ 4.7125e-03,  5.7982e-05, -1.0645e-02]])\n",
            "linear.bias value tensor([0.9562]) gradient tensor([-0.0049])\n",
            "epoch 7200\n",
            "linear.weight value tensor([[-2.3409e+00,  1.0693e-03,  6.4237e-01]]) gradient tensor([[ 4.6293e-03,  5.1477e-05, -1.0570e-02]])\n",
            "linear.bias value tensor([0.9610]) gradient tensor([-0.0047])\n",
            "epoch 7300\n",
            "linear.weight value tensor([[-2.3455e+00,  1.0192e-03,  6.5290e-01]]) gradient tensor([[ 4.5476e-03,  4.8151e-05, -1.0496e-02]])\n",
            "linear.bias value tensor([0.9656]) gradient tensor([-0.0046])\n",
            "epoch 7400\n",
            "linear.weight value tensor([[-2.3500e+00,  9.7176e-04,  6.6336e-01]]) gradient tensor([[ 4.4672e-03,  4.8265e-05, -1.0423e-02]])\n",
            "linear.bias value tensor([0.9701]) gradient tensor([-0.0044])\n",
            "epoch 7500\n",
            "linear.weight value tensor([[-2.3544e+00,  9.2694e-04,  6.7375e-01]]) gradient tensor([[ 4.3882e-03,  4.1556e-05, -1.0350e-02]])\n",
            "linear.bias value tensor([0.9744]) gradient tensor([-0.0043])\n",
            "epoch 7600\n",
            "linear.weight value tensor([[-2.3588e+00,  8.8471e-04,  6.8406e-01]]) gradient tensor([[ 4.3107e-03,  4.2624e-05, -1.0278e-02]])\n",
            "linear.bias value tensor([0.9786]) gradient tensor([-0.0041])\n",
            "epoch 7700\n",
            "linear.weight value tensor([[-2.3630e+00,  8.4491e-04,  6.9431e-01]]) gradient tensor([[ 4.2344e-03,  3.5860e-05, -1.0207e-02]])\n",
            "linear.bias value tensor([0.9827]) gradient tensor([-0.0040])\n",
            "epoch 7800\n",
            "linear.weight value tensor([[-2.3672e+00,  8.0752e-04,  7.0448e-01]]) gradient tensor([[ 4.1595e-03,  3.5269e-05, -1.0136e-02]])\n",
            "linear.bias value tensor([0.9866]) gradient tensor([-0.0039])\n",
            "epoch 7900\n",
            "linear.weight value tensor([[-2.3713e+00,  7.7242e-04,  7.1458e-01]]) gradient tensor([[ 4.0860e-03,  3.4564e-05, -1.0066e-02]])\n",
            "linear.bias value tensor([0.9904]) gradient tensor([-0.0037])\n",
            "epoch 8000\n",
            "linear.weight value tensor([[-2.3754e+00,  7.3955e-04,  7.2461e-01]]) gradient tensor([[ 4.0138e-03,  3.2451e-05, -9.9969e-03]])\n",
            "linear.bias value tensor([0.9941]) gradient tensor([-0.0036])\n",
            "epoch 8100\n",
            "linear.weight value tensor([[-2.3794e+00,  7.0881e-04,  7.3458e-01]]) gradient tensor([[ 3.9429e-03,  2.8937e-05, -9.9282e-03]])\n",
            "linear.bias value tensor([0.9976]) gradient tensor([-0.0035])\n",
            "epoch 8200\n",
            "linear.weight value tensor([[-2.3833e+00,  6.8019e-04,  7.4447e-01]]) gradient tensor([[ 3.8733e-03,  2.8888e-05, -9.8601e-03]])\n",
            "linear.bias value tensor([1.0011]) gradient tensor([-0.0034])\n",
            "epoch 8300\n",
            "linear.weight value tensor([[-2.3871e+00,  6.5356e-04,  7.5430e-01]]) gradient tensor([[ 3.8049e-03,  2.5960e-05, -9.7926e-03]])\n",
            "linear.bias value tensor([1.0044]) gradient tensor([-0.0033])\n",
            "epoch 8400\n",
            "linear.weight value tensor([[-2.3909e+00,  6.2888e-04,  7.6406e-01]]) gradient tensor([[ 3.7379e-03,  2.4672e-05, -9.7258e-03]])\n",
            "linear.bias value tensor([1.0076]) gradient tensor([-0.0031])\n",
            "epoch 8500\n",
            "linear.weight value tensor([[-2.3946e+00,  6.0609e-04,  7.7375e-01]]) gradient tensor([[ 3.6720e-03,  2.2181e-05, -9.6595e-03]])\n",
            "linear.bias value tensor([1.0107]) gradient tensor([-0.0030])\n",
            "epoch 8600\n",
            "linear.weight value tensor([[-2.3982e+00,  5.8513e-04,  7.8338e-01]]) gradient tensor([[ 3.6073e-03,  1.9222e-05, -9.5938e-03]])\n",
            "linear.bias value tensor([1.0136]) gradient tensor([-0.0029])\n",
            "epoch 8700\n",
            "linear.weight value tensor([[-2.4018e+00,  5.6593e-04,  7.9294e-01]]) gradient tensor([[ 3.5438e-03,  1.8203e-05, -9.5287e-03]])\n",
            "linear.bias value tensor([1.0165]) gradient tensor([-0.0028])\n",
            "epoch 8800\n",
            "linear.weight value tensor([[-2.4053e+00,  5.4843e-04,  8.0243e-01]]) gradient tensor([[ 3.4816e-03,  1.5425e-05, -9.4642e-03]])\n",
            "linear.bias value tensor([1.0193]) gradient tensor([-0.0027])\n",
            "epoch 8900\n",
            "linear.weight value tensor([[-2.4088e+00,  5.3261e-04,  8.1187e-01]]) gradient tensor([[ 3.4205e-03,  1.3796e-05, -9.4002e-03]])\n",
            "linear.bias value tensor([1.0220]) gradient tensor([-0.0026])\n",
            "epoch 9000\n",
            "linear.weight value tensor([[-2.4122e+00,  5.1836e-04,  8.2124e-01]]) gradient tensor([[ 3.3606e-03,  1.4472e-05, -9.3368e-03]])\n",
            "linear.bias value tensor([1.0246]) gradient tensor([-0.0025])\n",
            "epoch 9100\n",
            "linear.weight value tensor([[-2.4155e+00,  5.0570e-04,  8.3054e-01]]) gradient tensor([[ 3.3017e-03,  1.3116e-05, -9.2739e-03]])\n",
            "linear.bias value tensor([1.0271]) gradient tensor([-0.0024])\n",
            "epoch 9200\n",
            "linear.weight value tensor([[-2.4188e+00,  4.9447e-04,  8.3978e-01]]) gradient tensor([[ 3.2440e-03,  9.5544e-06, -9.2116e-03]])\n",
            "linear.bias value tensor([1.0294]) gradient tensor([-0.0024])\n",
            "epoch 9300\n",
            "linear.weight value tensor([[-2.4220e+00,  4.8474e-04,  8.4897e-01]]) gradient tensor([[ 3.1874e-03,  8.5915e-06, -9.1498e-03]])\n",
            "linear.bias value tensor([1.0318]) gradient tensor([-0.0023])\n",
            "epoch 9400\n",
            "linear.weight value tensor([[-2.4251e+00,  4.7639e-04,  8.5808e-01]]) gradient tensor([[ 3.1318e-03,  4.6156e-06, -9.0885e-03]])\n",
            "linear.bias value tensor([1.0340]) gradient tensor([-0.0022])\n",
            "epoch 9500\n",
            "linear.weight value tensor([[-2.4283e+00,  4.6942e-04,  8.6714e-01]]) gradient tensor([[ 3.0774e-03,  7.6964e-06, -9.0278e-03]])\n",
            "linear.bias value tensor([1.0361]) gradient tensor([-0.0021])\n",
            "epoch 9600\n",
            "linear.weight value tensor([[-2.4313e+00,  4.6373e-04,  8.7614e-01]]) gradient tensor([[ 3.0239e-03,  3.8836e-06, -8.9676e-03]])\n",
            "linear.bias value tensor([1.0382]) gradient tensor([-0.0020])\n",
            "epoch 9700\n",
            "linear.weight value tensor([[-2.4343e+00,  4.5935e-04,  8.8508e-01]]) gradient tensor([[ 2.9715e-03,  1.8617e-06, -8.9079e-03]])\n",
            "linear.bias value tensor([1.0402]) gradient tensor([-0.0019])\n",
            "epoch 9800\n",
            "linear.weight value tensor([[-2.4372e+00,  4.5620e-04,  8.9396e-01]]) gradient tensor([[ 2.9201e-03,  2.0126e-06, -8.8486e-03]])\n",
            "linear.bias value tensor([1.0421]) gradient tensor([-0.0019])\n",
            "epoch 9900\n",
            "linear.weight value tensor([[-2.4401e+00,  4.5422e-04,  9.0278e-01]]) gradient tensor([[ 2.8697e-03,  8.3633e-07, -8.7899e-03]])\n",
            "linear.bias value tensor([1.0439]) gradient tensor([-0.0018])\n",
            "epoch 10000\n",
            "linear.weight value tensor([[-2.4430e+00,  4.5339e-04,  9.1154e-01]]) gradient tensor([[ 2.8202e-03,  8.3167e-07, -8.7317e-03]])\n",
            "linear.bias value tensor([1.0457]) gradient tensor([-0.0017])\n",
            "epoch 10100\n",
            "linear.weight value tensor([[-2.4458e+00,  4.5368e-04,  9.2024e-01]]) gradient tensor([[ 2.7718e-03,  1.7788e-07, -8.6739e-03]])\n",
            "linear.bias value tensor([1.0473]) gradient tensor([-0.0017])\n",
            "epoch 10200\n",
            "linear.weight value tensor([[-2.4485e+00,  4.5507e-04,  9.2889e-01]]) gradient tensor([[ 2.7242e-03,  5.5041e-07, -8.6167e-03]])\n",
            "linear.bias value tensor([1.0490]) gradient tensor([-0.0016])\n",
            "epoch 10300\n",
            "linear.weight value tensor([[-2.4512e+00,  4.5748e-04,  9.3747e-01]]) gradient tensor([[ 2.6775e-03, -3.6806e-06, -8.5599e-03]])\n",
            "linear.bias value tensor([1.0505]) gradient tensor([-0.0015])\n",
            "epoch 10400\n",
            "linear.weight value tensor([[-2.4539e+00,  4.6092e-04,  9.4601e-01]]) gradient tensor([[ 2.6318e-03, -2.8666e-06, -8.5035e-03]])\n",
            "linear.bias value tensor([1.0520]) gradient tensor([-0.0015])\n",
            "epoch 10500\n",
            "linear.weight value tensor([[-2.4565e+00,  4.6532e-04,  9.5448e-01]]) gradient tensor([[ 2.5869e-03, -5.6736e-06, -8.4477e-03]])\n",
            "linear.bias value tensor([1.0534]) gradient tensor([-0.0014])\n",
            "epoch 10600\n",
            "linear.weight value tensor([[-2.4591e+00,  4.7065e-04,  9.6290e-01]]) gradient tensor([[ 2.5429e-03, -7.9134e-06, -8.3923e-03]])\n",
            "linear.bias value tensor([1.0548]) gradient tensor([-0.0013])\n",
            "epoch 10700\n",
            "linear.weight value tensor([[-2.4616e+00,  4.7691e-04,  9.7127e-01]]) gradient tensor([[ 2.4998e-03, -7.0948e-06, -8.3373e-03]])\n",
            "linear.bias value tensor([1.0561]) gradient tensor([-0.0013])\n",
            "epoch 10800\n",
            "linear.weight value tensor([[-2.4641e+00,  4.8407e-04,  9.7958e-01]]) gradient tensor([[ 2.4576e-03, -6.5900e-06, -8.2828e-03]])\n",
            "linear.bias value tensor([1.0573]) gradient tensor([-0.0012])\n",
            "epoch 10900\n",
            "linear.weight value tensor([[-2.4665e+00,  4.9209e-04,  9.8783e-01]]) gradient tensor([[ 2.4160e-03, -8.2925e-06, -8.2287e-03]])\n",
            "linear.bias value tensor([1.0585]) gradient tensor([-0.0012])\n",
            "epoch 11000\n",
            "linear.weight value tensor([[-2.4689e+00,  5.0091e-04,  9.9604e-01]]) gradient tensor([[ 2.3754e-03, -9.3617e-06, -8.1751e-03]])\n",
            "linear.bias value tensor([1.0596]) gradient tensor([-0.0011])\n",
            "epoch 11100\n",
            "linear.weight value tensor([[-2.4713e+00,  5.1053e-04,  1.0042e+00]]) gradient tensor([[ 2.3355e-03, -1.1862e-05, -8.1218e-03]])\n",
            "linear.bias value tensor([1.0607]) gradient tensor([-0.0010])\n",
            "epoch 11200\n",
            "linear.weight value tensor([[-2.4736e+00,  5.2094e-04,  1.0123e+00]]) gradient tensor([[ 2.2964e-03, -1.1548e-05, -8.0691e-03]])\n",
            "linear.bias value tensor([1.0617]) gradient tensor([-0.0010])\n",
            "epoch 11300\n",
            "linear.weight value tensor([[-2.4758e+00,  5.3210e-04,  1.0203e+00]]) gradient tensor([[ 2.2581e-03, -1.0778e-05, -8.0167e-03]])\n",
            "linear.bias value tensor([1.0627]) gradient tensor([-0.0009])\n",
            "epoch 11400\n",
            "linear.weight value tensor([[-2.4781e+00,  5.4397e-04,  1.0283e+00]]) gradient tensor([[ 2.2205e-03, -1.1796e-05, -7.9647e-03]])\n",
            "linear.bias value tensor([1.0636]) gradient tensor([-0.0009])\n",
            "epoch 11500\n",
            "linear.weight value tensor([[-2.4803e+00,  5.5656e-04,  1.0363e+00]]) gradient tensor([[ 2.1836e-03, -1.2204e-05, -7.9132e-03]])\n",
            "linear.bias value tensor([1.0645]) gradient tensor([-0.0008])\n",
            "epoch 11600\n",
            "linear.weight value tensor([[-2.4825e+00,  5.6977e-04,  1.0441e+00]]) gradient tensor([[ 2.1475e-03, -1.4271e-05, -7.8621e-03]])\n",
            "linear.bias value tensor([1.0653]) gradient tensor([-0.0008])\n",
            "epoch 11700\n",
            "linear.weight value tensor([[-2.4846e+00,  5.8369e-04,  1.0520e+00]]) gradient tensor([[ 2.1120e-03, -1.3752e-05, -7.8113e-03]])\n",
            "linear.bias value tensor([1.0661]) gradient tensor([-0.0008])\n",
            "epoch 11800\n",
            "linear.weight value tensor([[-2.4867e+00,  5.9820e-04,  1.0598e+00]]) gradient tensor([[ 2.0773e-03, -1.5642e-05, -7.7610e-03]])\n",
            "linear.bias value tensor([1.0668]) gradient tensor([-0.0007])\n",
            "epoch 11900\n",
            "linear.weight value tensor([[-2.4887e+00,  6.1335e-04,  1.0675e+00]]) gradient tensor([[ 2.0432e-03, -1.4692e-05, -7.7111e-03]])\n",
            "linear.bias value tensor([1.0675]) gradient tensor([-0.0007])\n",
            "epoch 12000\n",
            "linear.weight value tensor([[-2.4908e+00,  6.2907e-04,  1.0752e+00]]) gradient tensor([[ 2.0097e-03, -1.7096e-05, -7.6615e-03]])\n",
            "linear.bias value tensor([1.0682]) gradient tensor([-0.0006])\n",
            "epoch 12100\n",
            "linear.weight value tensor([[-2.4928e+00,  6.4535e-04,  1.0828e+00]]) gradient tensor([[ 1.9770e-03, -1.7080e-05, -7.6123e-03]])\n",
            "linear.bias value tensor([1.0688]) gradient tensor([-0.0006])\n",
            "epoch 12200\n",
            "linear.weight value tensor([[-2.4947e+00,  6.6221e-04,  1.0904e+00]]) gradient tensor([[ 1.9448e-03, -1.8109e-05, -7.5636e-03]])\n",
            "linear.bias value tensor([1.0693]) gradient tensor([-0.0005])\n",
            "epoch 12300\n",
            "linear.weight value tensor([[-2.4966e+00,  6.7957e-04,  1.0980e+00]]) gradient tensor([[ 1.9134e-03, -1.6275e-05, -7.5152e-03]])\n",
            "linear.bias value tensor([1.0699]) gradient tensor([-0.0005])\n",
            "epoch 12400\n",
            "linear.weight value tensor([[-2.4985e+00,  6.9742e-04,  1.1054e+00]]) gradient tensor([[ 1.8825e-03, -1.8351e-05, -7.4671e-03]])\n",
            "linear.bias value tensor([1.0704]) gradient tensor([-0.0005])\n",
            "epoch 12500\n",
            "linear.weight value tensor([[-2.5004e+00,  7.1579e-04,  1.1129e+00]]) gradient tensor([[ 1.8522e-03, -1.9254e-05, -7.4195e-03]])\n",
            "linear.bias value tensor([1.0708]) gradient tensor([-0.0004])\n",
            "epoch 12600\n",
            "linear.weight value tensor([[-2.5022e+00,  7.3465e-04,  1.1203e+00]]) gradient tensor([[ 1.8225e-03, -1.9158e-05, -7.3722e-03]])\n",
            "linear.bias value tensor([1.0712]) gradient tensor([-0.0004])\n",
            "epoch 12700\n",
            "linear.weight value tensor([[-2.5041e+00,  7.5392e-04,  1.1276e+00]]) gradient tensor([[ 1.7934e-03, -1.9726e-05, -7.3252e-03]])\n",
            "linear.bias value tensor([1.0716]) gradient tensor([-0.0004])\n",
            "epoch 12800\n",
            "linear.weight value tensor([[-2.5058e+00,  7.7364e-04,  1.1349e+00]]) gradient tensor([[ 1.7649e-03, -2.1093e-05, -7.2786e-03]])\n",
            "linear.bias value tensor([1.0720]) gradient tensor([-0.0003])\n",
            "epoch 12900\n",
            "linear.weight value tensor([[-2.5076e+00,  7.9381e-04,  1.1422e+00]]) gradient tensor([[ 1.7369e-03, -1.9585e-05, -7.2324e-03]])\n",
            "linear.bias value tensor([1.0723]) gradient tensor([-0.0003])\n",
            "epoch 13000\n",
            "linear.weight value tensor([[-2.5093e+00,  8.1438e-04,  1.1494e+00]]) gradient tensor([[ 1.7094e-03, -1.9575e-05, -7.1865e-03]])\n",
            "linear.bias value tensor([1.0726]) gradient tensor([-0.0003])\n",
            "epoch 13100\n",
            "linear.weight value tensor([[-2.5110e+00,  8.3536e-04,  1.1566e+00]]) gradient tensor([[ 1.6824e-03, -2.0973e-05, -7.1410e-03]])\n",
            "linear.bias value tensor([1.0728]) gradient tensor([-0.0002])\n",
            "epoch 13200\n",
            "linear.weight value tensor([[-2.5127e+00,  8.5670e-04,  1.1637e+00]]) gradient tensor([[ 1.6560e-03, -1.9859e-05, -7.0958e-03]])\n",
            "linear.bias value tensor([1.0731]) gradient tensor([-0.0002])\n",
            "epoch 13300\n",
            "linear.weight value tensor([[-2.5143e+00,  8.7839e-04,  1.1708e+00]]) gradient tensor([[ 1.6302e-03, -2.0771e-05, -7.0510e-03]])\n",
            "linear.bias value tensor([1.0733]) gradient tensor([-0.0002])\n",
            "epoch 13400\n",
            "linear.weight value tensor([[-2.5159e+00,  9.0042e-04,  1.1778e+00]]) gradient tensor([[ 1.6047e-03, -2.2435e-05, -7.0065e-03]])\n",
            "linear.bias value tensor([1.0734]) gradient tensor([-0.0002])\n",
            "epoch 13500\n",
            "linear.weight value tensor([[-2.5175e+00,  9.2278e-04,  1.1848e+00]]) gradient tensor([[ 1.5799e-03, -2.3136e-05, -6.9623e-03]])\n",
            "linear.bias value tensor([1.0736]) gradient tensor([-0.0001])\n",
            "epoch 13600\n",
            "linear.weight value tensor([[-2.5191e+00,  9.4548e-04,  1.1917e+00]]) gradient tensor([[ 1.5554e-03, -2.4675e-05, -6.9184e-03]])\n",
            "linear.bias value tensor([1.0737]) gradient tensor([-9.8928e-05])\n",
            "epoch 13700\n",
            "linear.weight value tensor([[-2.5206e+00,  9.6851e-04,  1.1986e+00]]) gradient tensor([[ 1.5315e-03, -2.3440e-05, -6.8749e-03]])\n",
            "linear.bias value tensor([1.0738]) gradient tensor([-7.3120e-05])\n",
            "epoch 13800\n",
            "linear.weight value tensor([[-2.5222e+00,  9.9183e-04,  1.2055e+00]]) gradient tensor([[ 1.5080e-03, -2.2237e-05, -6.8317e-03]])\n",
            "linear.bias value tensor([1.0738]) gradient tensor([-4.8051e-05])\n",
            "epoch 13900\n",
            "linear.weight value tensor([[-2.5237e+00,  1.0154e-03,  1.2123e+00]]) gradient tensor([[ 1.4849e-03, -2.3474e-05, -6.7888e-03]])\n",
            "linear.bias value tensor([1.0739]) gradient tensor([-2.3750e-05])\n",
            "epoch 14000\n",
            "linear.weight value tensor([[-2.5251e+00,  1.0393e-03,  1.2190e+00]]) gradient tensor([[ 1.4623e-03, -2.3679e-05, -6.7463e-03]])\n",
            "linear.bias value tensor([1.0739]) gradient tensor([-1.1857e-07])\n",
            "epoch 14100\n",
            "linear.weight value tensor([[-2.5266e+00,  1.0634e-03,  1.2258e+00]]) gradient tensor([[ 1.4401e-03, -2.4921e-05, -6.7040e-03]])\n",
            "linear.bias value tensor([1.0739]) gradient tensor([2.2781e-05])\n",
            "epoch 14200\n",
            "linear.weight value tensor([[-2.5280e+00,  1.0878e-03,  1.2324e+00]]) gradient tensor([[ 1.4183e-03, -2.3393e-05, -6.6621e-03]])\n",
            "linear.bias value tensor([1.0738]) gradient tensor([4.5091e-05])\n",
            "epoch 14300\n",
            "linear.weight value tensor([[-2.5294e+00,  1.1124e-03,  1.2391e+00]]) gradient tensor([[ 1.3970e-03, -2.5069e-05, -6.6205e-03]])\n",
            "linear.bias value tensor([1.0738]) gradient tensor([6.6707e-05])\n",
            "epoch 14400\n",
            "linear.weight value tensor([[-2.5308e+00,  1.1372e-03,  1.2457e+00]]) gradient tensor([[ 1.3762e-03, -2.4669e-05, -6.5792e-03]])\n",
            "linear.bias value tensor([1.0737]) gradient tensor([8.7739e-05])\n",
            "epoch 14500\n",
            "linear.weight value tensor([[-2.5322e+00,  1.1623e-03,  1.2522e+00]]) gradient tensor([[ 1.3557e-03, -2.4820e-05, -6.5381e-03]])\n",
            "linear.bias value tensor([1.0736]) gradient tensor([0.0001])\n",
            "epoch 14600\n",
            "linear.weight value tensor([[-2.5335e+00,  1.1875e-03,  1.2588e+00]]) gradient tensor([[ 1.3356e-03, -2.6989e-05, -6.4974e-03]])\n",
            "linear.bias value tensor([1.0735]) gradient tensor([0.0001])\n",
            "epoch 14700\n",
            "linear.weight value tensor([[-2.5348e+00,  1.2130e-03,  1.2652e+00]]) gradient tensor([[ 1.3158e-03, -2.5486e-05, -6.4570e-03]])\n",
            "linear.bias value tensor([1.0733]) gradient tensor([0.0001])\n",
            "epoch 14800\n",
            "linear.weight value tensor([[-2.5361e+00,  1.2387e-03,  1.2717e+00]]) gradient tensor([[ 1.2964e-03, -2.7402e-05, -6.4169e-03]])\n",
            "linear.bias value tensor([1.0732]) gradient tensor([0.0002])\n",
            "epoch 14900\n",
            "linear.weight value tensor([[-2.5374e+00,  1.2646e-03,  1.2781e+00]]) gradient tensor([[ 1.2774e-03, -2.5786e-05, -6.3770e-03]])\n",
            "linear.bias value tensor([1.0730]) gradient tensor([0.0002])\n",
            "epoch 15000\n",
            "linear.weight value tensor([[-2.5387e+00,  1.2905e-03,  1.2844e+00]]) gradient tensor([[ 1.2588e-03, -2.5984e-05, -6.3375e-03]])\n",
            "linear.bias value tensor([1.0728]) gradient tensor([0.0002])\n",
            "epoch 15100\n",
            "linear.weight value tensor([[-2.5399e+00,  1.3167e-03,  1.2908e+00]]) gradient tensor([[ 1.2406e-03, -2.5627e-05, -6.2982e-03]])\n",
            "linear.bias value tensor([1.0726]) gradient tensor([0.0002])\n",
            "epoch 15200\n",
            "linear.weight value tensor([[-2.5412e+00,  1.3430e-03,  1.2970e+00]]) gradient tensor([[ 1.2226e-03, -2.5968e-05, -6.2592e-03]])\n",
            "linear.bias value tensor([1.0724]) gradient tensor([0.0002])\n",
            "epoch 15300\n",
            "linear.weight value tensor([[-2.5424e+00,  1.3696e-03,  1.3033e+00]]) gradient tensor([[ 1.2048e-03, -2.6603e-05, -6.2205e-03]])\n",
            "linear.bias value tensor([1.0721]) gradient tensor([0.0003])\n",
            "epoch 15400\n",
            "linear.weight value tensor([[-2.5436e+00,  1.3961e-03,  1.3095e+00]]) gradient tensor([[ 1.1877e-03, -2.7576e-05, -6.1821e-03]])\n",
            "linear.bias value tensor([1.0719]) gradient tensor([0.0003])\n",
            "epoch 15500\n",
            "linear.weight value tensor([[-2.5448e+00,  1.4228e-03,  1.3156e+00]]) gradient tensor([[ 1.1708e-03, -2.7635e-05, -6.1439e-03]])\n",
            "linear.bias value tensor([1.0716]) gradient tensor([0.0003])\n",
            "epoch 15600\n",
            "linear.weight value tensor([[-2.5459e+00,  1.4497e-03,  1.3218e+00]]) gradient tensor([[ 1.1540e-03, -2.6466e-05, -6.1061e-03]])\n",
            "linear.bias value tensor([1.0713]) gradient tensor([0.0003])\n",
            "epoch 15700\n",
            "linear.weight value tensor([[-2.5471e+00,  1.4767e-03,  1.3278e+00]]) gradient tensor([[ 1.1377e-03, -2.7659e-05, -6.0684e-03]])\n",
            "linear.bias value tensor([1.0710]) gradient tensor([0.0003])\n",
            "epoch 15800\n",
            "linear.weight value tensor([[-2.5482e+00,  1.5038e-03,  1.3339e+00]]) gradient tensor([[ 1.1218e-03, -2.6702e-05, -6.0311e-03]])\n",
            "linear.bias value tensor([1.0707]) gradient tensor([0.0003])\n",
            "epoch 15900\n",
            "linear.weight value tensor([[-2.5493e+00,  1.5310e-03,  1.3399e+00]]) gradient tensor([[ 1.1059e-03, -2.8152e-05, -5.9940e-03]])\n",
            "linear.bias value tensor([1.0704]) gradient tensor([0.0003])\n",
            "epoch 16000\n",
            "linear.weight value tensor([[-2.5504e+00,  1.5582e-03,  1.3459e+00]]) gradient tensor([[ 1.0906e-03, -2.9203e-05, -5.9572e-03]])\n",
            "linear.bias value tensor([1.0700]) gradient tensor([0.0003])\n",
            "epoch 16100\n",
            "linear.weight value tensor([[-2.5515e+00,  1.5856e-03,  1.3518e+00]]) gradient tensor([[ 1.0755e-03, -2.6012e-05, -5.9206e-03]])\n",
            "linear.bias value tensor([1.0697]) gradient tensor([0.0004])\n",
            "epoch 16200\n",
            "linear.weight value tensor([[-2.5526e+00,  1.6131e-03,  1.3577e+00]]) gradient tensor([[ 1.0605e-03, -2.6246e-05, -5.8843e-03]])\n",
            "linear.bias value tensor([1.0693]) gradient tensor([0.0004])\n",
            "epoch 16300\n",
            "linear.weight value tensor([[-2.5536e+00,  1.6405e-03,  1.3636e+00]]) gradient tensor([[ 1.0461e-03, -2.5780e-05, -5.8483e-03]])\n",
            "linear.bias value tensor([1.0689]) gradient tensor([0.0004])\n",
            "epoch 16400\n",
            "linear.weight value tensor([[-2.5547e+00,  1.6681e-03,  1.3694e+00]]) gradient tensor([[ 1.0317e-03, -2.6470e-05, -5.8125e-03]])\n",
            "linear.bias value tensor([1.0685]) gradient tensor([0.0004])\n",
            "epoch 16500\n",
            "linear.weight value tensor([[-2.5557e+00,  1.6958e-03,  1.3752e+00]]) gradient tensor([[ 1.0176e-03, -2.7810e-05, -5.7769e-03]])\n",
            "linear.bias value tensor([1.0681]) gradient tensor([0.0004])\n",
            "epoch 16600\n",
            "linear.weight value tensor([[-2.5567e+00,  1.7235e-03,  1.3810e+00]]) gradient tensor([[ 1.0039e-03, -2.8674e-05, -5.7416e-03]])\n",
            "linear.bias value tensor([1.0677]) gradient tensor([0.0004])\n",
            "epoch 16700\n",
            "linear.weight value tensor([[-2.5577e+00,  1.7513e-03,  1.3867e+00]]) gradient tensor([[ 9.9023e-04, -2.7355e-05, -5.7066e-03]])\n",
            "linear.bias value tensor([1.0673]) gradient tensor([0.0004])\n",
            "epoch 16800\n",
            "linear.weight value tensor([[-2.5587e+00,  1.7790e-03,  1.3924e+00]]) gradient tensor([[ 9.7714e-04, -2.9746e-05, -5.6718e-03]])\n",
            "linear.bias value tensor([1.0669]) gradient tensor([0.0004])\n",
            "epoch 16900\n",
            "linear.weight value tensor([[-2.5597e+00,  1.8069e-03,  1.3980e+00]]) gradient tensor([[ 9.6393e-04, -2.8674e-05, -5.6372e-03]])\n",
            "linear.bias value tensor([1.0664]) gradient tensor([0.0004])\n",
            "epoch 17000\n",
            "linear.weight value tensor([[-2.5606e+00,  1.8348e-03,  1.4037e+00]]) gradient tensor([[ 9.5134e-04, -2.7217e-05, -5.6029e-03]])\n",
            "linear.bias value tensor([1.0660]) gradient tensor([0.0005])\n",
            "epoch 17100\n",
            "linear.weight value tensor([[-2.5616e+00,  1.8627e-03,  1.4093e+00]]) gradient tensor([[ 9.3861e-04, -2.7518e-05, -5.5688e-03]])\n",
            "linear.bias value tensor([1.0655]) gradient tensor([0.0005])\n",
            "epoch 17200\n",
            "linear.weight value tensor([[-2.5625e+00,  1.8906e-03,  1.4148e+00]]) gradient tensor([[ 9.2639e-04, -2.7802e-05, -5.5350e-03]])\n",
            "linear.bias value tensor([1.0650]) gradient tensor([0.0005])\n",
            "epoch 17300\n",
            "linear.weight value tensor([[-2.5634e+00,  1.9186e-03,  1.4203e+00]]) gradient tensor([[ 9.1420e-04, -2.7669e-05, -5.5014e-03]])\n",
            "linear.bias value tensor([1.0646]) gradient tensor([0.0005])\n",
            "epoch 17400\n",
            "linear.weight value tensor([[-2.5643e+00,  1.9465e-03,  1.4258e+00]]) gradient tensor([[ 9.0236e-04, -2.9069e-05, -5.4680e-03]])\n",
            "linear.bias value tensor([1.0641]) gradient tensor([0.0005])\n",
            "epoch 17500\n",
            "linear.weight value tensor([[-2.5652e+00,  1.9746e-03,  1.4313e+00]]) gradient tensor([[ 8.9061e-04, -2.6961e-05, -5.4348e-03]])\n",
            "linear.bias value tensor([1.0636]) gradient tensor([0.0005])\n",
            "epoch 17600\n",
            "linear.weight value tensor([[-2.5661e+00,  2.0025e-03,  1.4367e+00]]) gradient tensor([[ 8.7922e-04, -2.9389e-05, -5.4019e-03]])\n",
            "linear.bias value tensor([1.0631]) gradient tensor([0.0005])\n",
            "epoch 17700\n",
            "linear.weight value tensor([[-2.5670e+00,  2.0306e-03,  1.4421e+00]]) gradient tensor([[ 8.6780e-04, -2.7451e-05, -5.3692e-03]])\n",
            "linear.bias value tensor([1.0626]) gradient tensor([0.0005])\n",
            "epoch 17800\n",
            "linear.weight value tensor([[-2.5678e+00,  2.0585e-03,  1.4474e+00]]) gradient tensor([[ 8.5701e-04, -2.6597e-05, -5.3367e-03]])\n",
            "linear.bias value tensor([1.0621]) gradient tensor([0.0005])\n",
            "epoch 17900\n",
            "linear.weight value tensor([[-2.5687e+00,  2.0866e-03,  1.4527e+00]]) gradient tensor([[ 8.4578e-04, -2.8514e-05, -5.3045e-03]])\n",
            "linear.bias value tensor([1.0615]) gradient tensor([0.0005])\n",
            "epoch 18000\n",
            "linear.weight value tensor([[-2.5695e+00,  2.1145e-03,  1.4580e+00]]) gradient tensor([[ 8.3547e-04, -2.7745e-05, -5.2724e-03]])\n",
            "linear.bias value tensor([1.0610]) gradient tensor([0.0005])\n",
            "epoch 18100\n",
            "linear.weight value tensor([[-2.5704e+00,  2.1426e-03,  1.4633e+00]]) gradient tensor([[ 8.2472e-04, -2.6860e-05, -5.2406e-03]])\n",
            "linear.bias value tensor([1.0605]) gradient tensor([0.0005])\n",
            "epoch 18200\n",
            "linear.weight value tensor([[-2.5712e+00,  2.1704e-03,  1.4685e+00]]) gradient tensor([[ 8.1465e-04, -2.8213e-05, -5.2090e-03]])\n",
            "linear.bias value tensor([1.0599]) gradient tensor([0.0005])\n",
            "epoch 18300\n",
            "linear.weight value tensor([[-2.5720e+00,  2.1985e-03,  1.4737e+00]]) gradient tensor([[ 8.0447e-04, -2.5969e-05, -5.1776e-03]])\n",
            "linear.bias value tensor([1.0594]) gradient tensor([0.0005])\n",
            "epoch 18400\n",
            "linear.weight value tensor([[-2.5728e+00,  2.2264e-03,  1.4789e+00]]) gradient tensor([[ 7.9450e-04, -2.7901e-05, -5.1464e-03]])\n",
            "linear.bias value tensor([1.0588]) gradient tensor([0.0006])\n",
            "epoch 18500\n",
            "linear.weight value tensor([[-2.5736e+00,  2.2542e-03,  1.4840e+00]]) gradient tensor([[ 7.8486e-04, -2.8655e-05, -5.1155e-03]])\n",
            "linear.bias value tensor([1.0583]) gradient tensor([0.0006])\n",
            "epoch 18600\n",
            "linear.weight value tensor([[-2.5744e+00,  2.2823e-03,  1.4891e+00]]) gradient tensor([[ 7.7490e-04, -2.9478e-05, -5.0848e-03]])\n",
            "linear.bias value tensor([1.0577]) gradient tensor([0.0006])\n",
            "epoch 18700\n",
            "linear.weight value tensor([[-2.5751e+00,  2.3099e-03,  1.4942e+00]]) gradient tensor([[ 7.6587e-04, -2.9500e-05, -5.0541e-03]])\n",
            "linear.bias value tensor([1.0572]) gradient tensor([0.0006])\n",
            "epoch 18800\n",
            "linear.weight value tensor([[-2.5759e+00,  2.3378e-03,  1.4992e+00]]) gradient tensor([[ 7.5650e-04, -2.8547e-05, -5.0238e-03]])\n",
            "linear.bias value tensor([1.0566]) gradient tensor([0.0006])\n",
            "epoch 18900\n",
            "linear.weight value tensor([[-2.5766e+00,  2.3656e-03,  1.5042e+00]]) gradient tensor([[ 7.4739e-04, -2.6419e-05, -4.9937e-03]])\n",
            "linear.bias value tensor([1.0560]) gradient tensor([0.0006])\n",
            "epoch 19000\n",
            "linear.weight value tensor([[-2.5774e+00,  2.3932e-03,  1.5092e+00]]) gradient tensor([[ 7.3865e-04, -2.8085e-05, -4.9637e-03]])\n",
            "linear.bias value tensor([1.0554]) gradient tensor([0.0006])\n",
            "epoch 19100\n",
            "linear.weight value tensor([[-2.5781e+00,  2.4211e-03,  1.5141e+00]]) gradient tensor([[ 7.2958e-04, -2.6928e-05, -4.9340e-03]])\n",
            "linear.bias value tensor([1.0549]) gradient tensor([0.0006])\n",
            "epoch 19200\n",
            "linear.weight value tensor([[-2.5788e+00,  2.4487e-03,  1.5191e+00]]) gradient tensor([[ 7.2116e-04, -2.5980e-05, -4.9045e-03]])\n",
            "linear.bias value tensor([1.0543]) gradient tensor([0.0006])\n",
            "epoch 19300\n",
            "linear.weight value tensor([[-2.5795e+00,  2.4762e-03,  1.5239e+00]]) gradient tensor([[ 7.1284e-04, -2.5013e-05, -4.8751e-03]])\n",
            "linear.bias value tensor([1.0537]) gradient tensor([0.0006])\n",
            "epoch 19400\n",
            "linear.weight value tensor([[-2.5803e+00,  2.5039e-03,  1.5288e+00]]) gradient tensor([[ 7.0404e-04, -2.8764e-05, -4.8460e-03]])\n",
            "linear.bias value tensor([1.0531]) gradient tensor([0.0006])\n",
            "epoch 19500\n",
            "linear.weight value tensor([[-2.5810e+00,  2.5314e-03,  1.5336e+00]]) gradient tensor([[ 6.9617e-04, -2.7085e-05, -4.8170e-03]])\n",
            "linear.bias value tensor([1.0525]) gradient tensor([0.0006])\n",
            "epoch 19600\n",
            "linear.weight value tensor([[-2.5816e+00,  2.5588e-03,  1.5384e+00]]) gradient tensor([[ 6.8817e-04, -2.7915e-05, -4.7883e-03]])\n",
            "linear.bias value tensor([1.0519]) gradient tensor([0.0006])\n",
            "epoch 19700\n",
            "linear.weight value tensor([[-2.5823,  0.0026,  1.5432]]) gradient tensor([[ 6.7999e-04, -2.6338e-05, -4.7597e-03]])\n",
            "linear.bias value tensor([1.0513]) gradient tensor([0.0006])\n",
            "epoch 19800\n",
            "linear.weight value tensor([[-2.5830,  0.0026,  1.5480]]) gradient tensor([[ 6.7242e-04, -2.9160e-05, -4.7313e-03]])\n",
            "linear.bias value tensor([1.0507]) gradient tensor([0.0006])\n",
            "epoch 19900\n",
            "linear.weight value tensor([[-2.5837,  0.0026,  1.5527]]) gradient tensor([[ 6.6485e-04, -2.6628e-05, -4.7031e-03]])\n",
            "linear.bias value tensor([1.0501]) gradient tensor([0.0006])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzMJvRPosfXk",
        "colab_type": "text"
      },
      "source": [
        "*Code breakdown*\n",
        "\n",
        "Put the model into training mode (this only affects certain models that behave differently during training and testing).  Even though it doesn't affect our logistic regression model, calling the `.train` function is a good habit to get into.\n",
        "\n",
        "```python\n",
        "model_pytorch.train()\n",
        "```\n",
        "\n",
        "Create an optimizer that will tune the parameters of the network.  Here we are using an algorithm called *stochastic gradient descent*.  It's a very popular choice for an optimizer.  Similarly to gradient descent it optimizes a function by stepping down the gradient (step size is given by learning rate or `lr`).  Where it differs from normal gradient descent is that it doesn't necessarily use all of the data to compute the gradient.  If you have a big dataset, it might only use a small number of data points, compute gradient over those, and then step down that estimate of the gradient.  The collection of datapoints used for estimating the gradient is called a *mini batch*.  In this example we are using the entire dataset each time, so we are really doing normal gradient descent.\n",
        "\n",
        "```python\n",
        "optimizer = torch.optim.SGD(model_pytorch.parameters(), lr=0.01)\n",
        "```\n",
        "\n",
        "The criterion defines the loss function we are minimizing.  When the training outputs are binary, the `BCELoss` function is equivalent to the log loss that we have been using in this course.\n",
        "\n",
        "```python\n",
        "criterion = torch.nn.BCELoss()\n",
        "```\n",
        "\n",
        "In order to operate on data in pytorch, you have to convert any matrix or vector data into a pytorch variable.  This should be familiar based on the tutorial you went through earlier.\n",
        "\n",
        "```python\n",
        "X_data = Variable(torch.Tensor(np.array(experiment_1_data)))\n",
        "y_data = Variable(torch.Tensor(np.array(experiment_1_outputs)))\n",
        "```\n",
        "\n",
        "An *epoch* in neural network training is a single pass through the data.  In this case we are taking a single gradient step on the whole dataset, so the number of epochs is the same as the number of gradient steps.\n",
        "```python\n",
        "for epoch in range(200):\n",
        "```\n",
        "\n",
        "This tells the optimizer to throw away any gradients it has accumulated from previous data (do not forget to call this!!!).\n",
        "\n",
        "```python\n",
        "optimizer.zero_grad()\n",
        "```\n",
        "\n",
        "Apply the forward model to get predictions.\n",
        "\n",
        "```python\n",
        "y_pred = model_pytorch(X_data)\n",
        "```\n",
        "\n",
        "Calculate the loss of the model by comparing its predictions with the actual outputs.\n",
        "\n",
        "```python\n",
        "loss = criterion(y_pred, y_data)\n",
        "```\n",
        "\n",
        "Use backpropagation to compute the gradient of all of the model parameters with respect to the loss.\n",
        "\n",
        "```python\n",
        "loss.backward()\n",
        "```\n",
        "\n",
        "Calculate the gradient magnitudes so we can make a plot after training.\n",
        "```python\n",
        "for name, param in model_pytorch.named_parameters():\n",
        "    if name == 'linear.weight':\n",
        "        grad_magnitudes.append(np.abs(param.grad.numpy()).mean())\n",
        "```\n",
        "\n",
        "Print out the values of the parameters and the gradient of the parameters with respect to the loss every 50 epochs.\n",
        "\n",
        "```python\n",
        "if epoch % 50 == 0:\n",
        "    print(\"epoch\", epoch)\n",
        "    for name, param in model_pytorch.named_parameters():\n",
        "        print(name, \"value\", param.data, \"gradient\", param.grad)\n",
        "```\n",
        "\n",
        "Perform the gradient step.\n",
        "```python\n",
        "optimizer.step()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMWSRWPCwExp",
        "colab_type": "text"
      },
      "source": [
        "### Notebook Exercise 2 (30 minutes)\n",
        "\n",
        "(a) Explain the output you see when you run the previous code cell.  How are the weights changing over time?  How is the gradient changing over time?  Is the algorithm close to converging (i.e., computing the optimal solution)?  How would you know if it has converged?\n",
        "\n",
        "(b) Increase the number of epochs until you get convergence (you may want to make it so the gradient prints out less by changing the line `if epoch % 100 == 0` to `if epoch % 1000 == 0`).  Roughly how many did it take?\n",
        "\n",
        "(c) Tune the learning rate to some other values.  How does this change the algorithm's behavior?\n",
        "\n",
        "(d) Change the optimizer to the ADAM optimizer by swapping out the previous optimizer with this new line of code.\n",
        "\n",
        "```python\n",
        "optimizer = torch.optim.Adam(model_pytorch.parameters())\n",
        "```\n",
        "\n",
        "Roughly many epochs does it take to reach convergence now?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SPZY74FfqAT8"
      },
      "source": [
        "#### *Expand for Solution*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zLv51G9VqD9v"
      },
      "source": [
        "***Solution***\n",
        "\n",
        "(a) (this might vary based on the random initialization of the weights in the network).  In this run the weights slowly adjusted to the values computed by the sklearn model.  The size of the gradient remained largely constant over time (as seen both in the output and in the plot).  This indicates that the algorithm has not converged yet.  If the gradient magnitude was close to 0, that would indicate convergence.\n",
        "\n",
        "(b) It took about 150,000 epochs to reach convergence!\n",
        "\n",
        "(c) Setting it too high causes divergence of the algorithm.  Setting it too low causes slow convergence.\n",
        "\n",
        "(d) It seems to takea bout 10,000 epochs to converge (that's a huge speedup!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSCOWv0ax4Lc",
        "colab_type": "text"
      },
      "source": [
        "## Multilayer Perceptron\n",
        "\n",
        "Now that we've shown you how to implement the logistic regression model, we want you to implement the MLP model from the previous companion notebook.  Remember, the MLP had 2 input features (we didn't use `is young male` as an input) and 2 hidden units.  We'll provide you with the skeleton of the code as well as some code to generate the visualization from the previous notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c72OHAbKqqgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# start from this and modify it\n",
        "class LogisticRegressionPytorch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LogisticRegressionPytorch, self).__init__()\n",
        "        self.linear = nn.Linear(3,1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\" Propagate data through the network.\n",
        "\n",
        "            This model first applies the linear layer and then a sigmoid\n",
        "        \"\"\"\n",
        "        X = self.linear(X)\n",
        "        return torch.sigmoid(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRordq4Vq1VU",
        "colab_type": "text"
      },
      "source": [
        "### Notebook Exercise 3 (20 minutes + 20 minutes of optional work)\n",
        "\n",
        "Non-optional: modify the starter code listed above (where it says `class LogisticRegressionPytorch`) to create be a class called TitanicMLP that has 2 input units and 2 hidden units.  Train your network on the Titanic dataset (we recommend using the Adam optimizer you learned about in the last problem).  We have defined a function called `visualize_model_probs` for visualizing the probability plot tha we saw in the last companion notebook (this code should be run after the model is done training).\n",
        "\n",
        "*Optional:* visualize the hidden unit representations in the network (similar to what we did in the companion notebook last time).  Hint: you can define additional functions (rather than just `forward` to compute the hidden units in the network)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OSBbI-tr_bC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_model_probs(model):\n",
        "    xx, yy = np.mgrid[-.1:1.1:.01, 0:85:.1]\n",
        "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "    probs = model(Variable(torch.Tensor(grid))).detach().numpy().reshape(xx.shape)\n",
        "\n",
        "    f, ax = plt.subplots(figsize=(8, 6))\n",
        "    contour = ax.contourf(xx, yy, probs, 25, cmap=\"RdBu\",\n",
        "                        vmin=0, vmax=1)\n",
        "    ax_c = f.colorbar(contour)\n",
        "    ax_c.set_label(\"$P(survived)$\")\n",
        "    ax_c.set_ticks([0, .25, .5, .75, 1])\n",
        "\n",
        "    ax.scatter(experiment_1_data['male'], experiment_1_data['Age'], c=experiment_1_outputs, s=50,\n",
        "            cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
        "            edgecolor=\"white\", linewidth=1)\n",
        "\n",
        "    ax.set(xlim=(-.1, 1.1),\n",
        "        ylim=(0, 85),\n",
        "        xlabel=\"is male\", ylabel=\"age (years)\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qUUvrdbSrnJj"
      },
      "source": [
        "#### *Expand for Solution*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRlnM3duq5Vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TitanicMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TitanicMLP, self).__init__()\n",
        "        self.linear_1 = nn.Linear(2,2)\n",
        "        self.linear_2 = nn.Linear(2,1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\" Propagate data through the network.\n",
        "\n",
        "            This model first applies the linear layer, a sigmoid, a linear\n",
        "            layer, and finally a sigmoid\n",
        "        \"\"\"\n",
        "        X = self.linear_1(X)\n",
        "        X = torch.sigmoid(X)\n",
        "        X = self.linear_2(X)\n",
        "        return torch.sigmoid(X)\n",
        "    # Note: the hidden function is only needed if you want to visualize hidden\n",
        "    # layers.  If you didn't do that part, you wouldn't have this in your\n",
        "    # solution.\n",
        "    def hidden(self, X):\n",
        "        \"\"\" Propagate data to the hidden layer \"\"\"\n",
        "        X = self.linear_1(X)\n",
        "        return torch.sigmoid(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzl2zcUdr39P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "39d7cace-7a3e-481d-888e-5a6dbb22af3a"
      },
      "source": [
        "mlp_pytorch = TitanicMLP()\n",
        "mlp_pytorch.train()\n",
        "optimizer = torch.optim.Adam(mlp_pytorch.parameters())\n",
        "criterion = torch.nn.BCELoss()\n",
        "grad_magnitudes = []\n",
        "\n",
        "X_data = Variable(torch.Tensor(np.array(experiment_1_data.drop('is_young_male',axis=1))))\n",
        "y_data = Variable(torch.Tensor(np.array(experiment_1_outputs)))\n",
        "for epoch in range(20000):\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    y_pred = mlp_pytorch(X_data)\n",
        "    # Compute Loss\n",
        "    loss = criterion(y_pred, y_data)\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    for name, param in mlp_pytorch.named_parameters():\n",
        "        if name == 'linear_1.weight':\n",
        "            grad_magnitudes.append(np.abs(param.grad.numpy()).mean())\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print(\"epoch\", epoch)\n",
        "        for name, param in mlp_pytorch.named_parameters():\n",
        "            print(name, \"value\", param.data, \"gradient\", param.grad)\n",
        "    optimizer.step()\n",
        "\n",
        "plt.plot(grad_magnitudes)\n",
        "plt.show()\n",
        "visualize_model_probs(mlp_pytorch)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:512: UserWarning: Using a target size (torch.Size([714])) that is different to the input size (torch.Size([714, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0\n",
            "linear_1.weight value tensor([[-0.3479, -0.7030],\n",
            "        [ 0.1942,  0.0512]]) gradient tensor([[-0.0005, -0.0012],\n",
            "        [ 0.0162,  0.2848]])\n",
            "linear_1.bias value tensor([ 0.4141, -0.3528]) gradient tensor([-0.0008,  0.0095])\n",
            "linear_2.weight value tensor([[0.6170, 0.4961]]) gradient tensor([[-0.0022,  0.1157]])\n",
            "linear_2.bias value tensor([-0.2069]) gradient tensor([0.1384])\n",
            "epoch 1000\n",
            "linear_1.weight value tensor([[-1.3510, -0.0170],\n",
            "        [-0.1551, -0.1473]]) gradient tensor([[ 0.0374, -0.0001],\n",
            "        [ 0.0002,  0.0065]])\n",
            "linear_1.bias value tensor([ 0.6387, -0.4825]) gradient tensor([ 0.0021, -0.0004])\n",
            "linear_2.weight value tensor([[1.7959, 0.4372]]) gradient tensor([[-0.0144, -0.0016]])\n",
            "linear_2.bias value tensor([-0.8426]) gradient tensor([0.0418])\n",
            "epoch 2000\n",
            "linear_1.weight value tensor([[-2.4644e+00, -1.4188e-04],\n",
            "        [ 7.3446e-02, -2.1378e-01]]) gradient tensor([[ 1.8743e-02, -1.7690e-05],\n",
            "        [-1.6653e-03,  3.2413e-03]])\n",
            "linear_1.bias value tensor([0.8628, 0.1085]) gradient tensor([-0.0003, -0.0014])\n",
            "linear_2.weight value tensor([[3.2229, 0.7299]]) gradient tensor([[-0.0128, -0.0040]])\n",
            "linear_2.bias value tensor([-1.5523]) gradient tensor([0.0136])\n",
            "epoch 3000\n",
            "linear_1.weight value tensor([[-2.9435,  0.0133],\n",
            "        [ 0.9528, -0.3269]]) gradient tensor([[ 5.5826e-03, -2.9059e-05],\n",
            "        [-2.2675e-03,  2.5480e-03]])\n",
            "linear_1.bias value tensor([0.6025, 1.0225]) gradient tensor([ 0.0005, -0.0008])\n",
            "linear_2.weight value tensor([[3.8441, 1.4471]]) gradient tensor([[-0.0047, -0.0049]])\n",
            "linear_2.bias value tensor([-1.8432]) gradient tensor([0.0018])\n",
            "epoch 4000\n",
            "linear_1.weight value tensor([[-3.2102,  0.0240],\n",
            "        [ 1.7404, -0.4006]]) gradient tensor([[ 2.5315e-03, -1.4008e-05],\n",
            "        [-1.3481e-03,  3.1724e-04]])\n",
            "linear_1.bias value tensor([0.0771, 1.1053]) gradient tensor([0.0002, 0.0003])\n",
            "linear_2.weight value tensor([[4.2288, 2.0984]]) gradient tensor([[-0.0022, -0.0022]])\n",
            "linear_2.bias value tensor([-1.8515]) gradient tensor([-0.0003])\n",
            "epoch 5000\n",
            "linear_1.weight value tensor([[-3.4078,  0.0252],\n",
            "        [ 2.3434, -0.3935]]) gradient tensor([[ 0.0011,  0.0036],\n",
            "        [-0.0008, -0.0001]])\n",
            "linear_1.bias value tensor([-0.1054,  0.4255]) gradient tensor([0.0001, 0.0005])\n",
            "linear_2.weight value tensor([[4.4824, 2.4713]]) gradient tensor([[-0.0007, -0.0009]])\n",
            "linear_2.bias value tensor([-1.8191]) gradient tensor([-4.9938e-05])\n",
            "epoch 6000\n",
            "linear_1.weight value tensor([[-3.5347,  0.0235],\n",
            "        [ 2.8135, -0.3795]]) gradient tensor([[ 4.0032e-04,  7.4245e-06],\n",
            "        [-3.9007e-04, -4.2508e-05]])\n",
            "linear_1.bias value tensor([-0.1408, -0.2447]) gradient tensor([3.2292e-06, 2.6527e-04])\n",
            "linear_2.weight value tensor([[4.6260, 2.7068]]) gradient tensor([[-0.0003, -0.0003]])\n",
            "linear_2.bias value tensor([-1.7938]) gradient tensor([-8.5084e-05])\n",
            "epoch 7000\n",
            "linear_1.weight value tensor([[-3.6142,  0.0220],\n",
            "        [ 3.1497, -0.3739]]) gradient tensor([[ 1.5909e-04,  1.3009e-04],\n",
            "        [-1.7962e-04, -6.9570e-06]])\n",
            "linear_1.bias value tensor([-0.1513, -0.6866]) gradient tensor([5.3777e-06, 1.0832e-04])\n",
            "linear_2.weight value tensor([[4.7122, 2.8155]]) gradient tensor([[-1.0698e-04, -6.0680e-05]])\n",
            "linear_2.bias value tensor([-1.7736]) gradient tensor([-3.6870e-05])\n",
            "epoch 8000\n",
            "linear_1.weight value tensor([[-3.6679,  0.0209],\n",
            "        [ 3.4038, -0.3749]]) gradient tensor([[ 6.6855e-05,  1.3886e-05],\n",
            "        [-9.1085e-05,  8.1402e-06]])\n",
            "linear_1.bias value tensor([-0.1633, -0.9358]) gradient tensor([1.7533e-06, 3.3224e-05])\n",
            "linear_2.weight value tensor([[4.7733, 2.8296]]) gradient tensor([[-5.0605e-05,  1.5646e-05]])\n",
            "linear_2.bias value tensor([-1.7580]) gradient tensor([-1.8102e-05])\n",
            "epoch 9000\n",
            "linear_1.weight value tensor([[-3.7044,  0.0203],\n",
            "        [ 3.6244, -0.3830]]) gradient tensor([[ 2.5781e-05, -1.0562e-04],\n",
            "        [-5.2767e-05,  1.2391e-05]])\n",
            "linear_1.bias value tensor([-0.1780, -1.0338]) gradient tensor([-2.1115e-06,  4.5719e-06])\n",
            "linear_2.weight value tensor([[4.8219, 2.7795]]) gradient tensor([[-2.6916e-05,  2.9764e-05]])\n",
            "linear_2.bias value tensor([-1.7470]) gradient tensor([-1.1121e-05])\n",
            "epoch 10000\n",
            "linear_1.weight value tensor([[-3.7245,  0.0199],\n",
            "        [ 3.8378, -0.3967]]) gradient tensor([[ 5.9602e-06, -2.5786e-05],\n",
            "        [-3.1935e-05,  9.7542e-06]])\n",
            "linear_1.bias value tensor([-0.1919, -1.0377]) gradient tensor([ 7.8624e-08, -1.1826e-06])\n",
            "linear_2.weight value tensor([[4.8616, 2.7001]]) gradient tensor([[-1.2957e-05,  1.9723e-05]])\n",
            "linear_2.bias value tensor([-1.7403]) gradient tensor([-3.1761e-06])\n",
            "epoch 11000\n",
            "linear_1.weight value tensor([[-3.7248,  0.0196],\n",
            "        [ 4.0332, -0.4107]]) gradient tensor([[-4.2203e-06, -1.8166e-04],\n",
            "        [-1.6246e-05,  4.5565e-06]])\n",
            "linear_1.bias value tensor([-0.2012, -1.0245]) gradient tensor([-5.1452e-06, -3.0358e-07])\n",
            "linear_2.weight value tensor([[4.8951, 2.6333]]) gradient tensor([[-9.8723e-06,  7.8708e-06]])\n",
            "linear_2.bias value tensor([-1.7382]) gradient tensor([-5.8151e-06])\n",
            "epoch 12000\n",
            "linear_1.weight value tensor([[-3.7005,  0.0193],\n",
            "        [ 4.1721, -0.4200]]) gradient tensor([[-7.3225e-06,  2.0330e-04],\n",
            "        [-5.8221e-06,  1.7602e-06]])\n",
            "linear_1.bias value tensor([-0.2081, -1.0250]) gradient tensor([6.8757e-06, 1.8551e-07])\n",
            "linear_2.weight value tensor([[4.9316, 2.5960]]) gradient tensor([[-2.7026e-06,  2.1793e-06]])\n",
            "linear_2.bias value tensor([-1.7410]) gradient tensor([7.5975e-06])\n",
            "epoch 13000\n",
            "linear_1.weight value tensor([[-3.6507,  0.0189],\n",
            "        [ 4.2414, -0.4240]]) gradient tensor([[-7.6346e-06,  8.4652e-05],\n",
            "        [-1.4739e-06,  3.8138e-07]])\n",
            "linear_1.bias value tensor([-0.2199, -1.0330]) gradient tensor([3.8284e-06, 1.8505e-07])\n",
            "linear_2.weight value tensor([[4.9886, 2.5825]]) gradient tensor([[-5.1300e-06,  3.0802e-07]])\n",
            "linear_2.bias value tensor([-1.7478]) gradient tensor([3.8974e-06])\n",
            "epoch 14000\n",
            "linear_1.weight value tensor([[-3.5751,  0.0184],\n",
            "        [ 4.2721, -0.4250]]) gradient tensor([[-6.7333e-06, -1.6013e-05],\n",
            "        [-5.3304e-07,  2.5611e-08]])\n",
            "linear_1.bias value tensor([-0.2413, -1.0451]) gradient tensor([1.5925e-06, 1.3710e-07])\n",
            "linear_2.weight value tensor([[5.0823, 2.5809]]) gradient tensor([[-7.3272e-06, -3.0595e-08]])\n",
            "linear_2.bias value tensor([-1.7584]) gradient tensor([8.1549e-07])\n",
            "epoch 15000\n",
            "linear_1.weight value tensor([[-3.4751,  0.0178],\n",
            "        [ 4.2979, -0.4254]]) gradient tensor([[-5.0385e-06,  1.5087e-05],\n",
            "        [-3.4974e-07,  3.3062e-08]])\n",
            "linear_1.bias value tensor([-0.2725, -1.0607]) gradient tensor([3.4661e-06, 1.0569e-07])\n",
            "linear_2.weight value tensor([[5.2185, 2.5824]]) gradient tensor([[-7.5771e-06, -3.8646e-08]])\n",
            "linear_2.bias value tensor([-1.7732]) gradient tensor([1.9708e-06])\n",
            "epoch 16000\n",
            "linear_1.weight value tensor([[-3.3630,  0.0171],\n",
            "        [ 4.3253, -0.4257]]) gradient tensor([[-3.3866e-06, -7.5832e-05],\n",
            "        [-2.1758e-07, -8.8941e-08]])\n",
            "linear_1.bias value tensor([-0.3108, -1.0779]) gradient tensor([1.4521e-06, 5.1400e-08])\n",
            "linear_2.weight value tensor([[5.3894, 2.5843]]) gradient tensor([[-9.1957e-06, -3.4405e-08]])\n",
            "linear_2.bias value tensor([-1.7909]) gradient tensor([-5.7493e-07])\n",
            "epoch 17000\n",
            "linear_1.weight value tensor([[-3.2559,  0.0164],\n",
            "        [ 4.3502, -0.4260]]) gradient tensor([[-2.3316e-06, -2.4471e-04],\n",
            "        [-1.4048e-07, -3.7299e-07]])\n",
            "linear_1.bias value tensor([-0.3519, -1.0939]) gradient tensor([-3.2692e-06, -1.7535e-08])\n",
            "linear_2.weight value tensor([[5.5759, 2.5863]]) gradient tensor([[-1.1122e-05, -6.2592e-08]])\n",
            "linear_2.bias value tensor([-1.8089]) gradient tensor([-5.1811e-06])\n",
            "epoch 18000\n",
            "linear_1.weight value tensor([[-3.1624,  0.0158],\n",
            "        [ 4.3707, -0.4262]]) gradient tensor([[-1.0292e-06,  3.8477e-05],\n",
            "        [-4.8341e-08,  7.9628e-08]])\n",
            "linear_1.bias value tensor([-0.3921, -1.1074]) gradient tensor([5.4063e-06, 2.7700e-08])\n",
            "linear_2.weight value tensor([[5.7620, 2.5881]]) gradient tensor([[-7.5352e-06, -1.5357e-09]])\n",
            "linear_2.bias value tensor([-1.8254]) gradient tensor([2.5566e-06])\n",
            "epoch 19000\n",
            "linear_1.weight value tensor([[-3.0833,  0.0152],\n",
            "        [ 4.3871, -0.4264]]) gradient tensor([[-2.2748e-05, -1.0338e-02],\n",
            "        [-1.8292e-06, -2.0972e-05]])\n",
            "linear_1.bias value tensor([-0.4296, -1.1186]) gradient tensor([-3.0680e-04, -2.5790e-06])\n",
            "linear_2.weight value tensor([[5.9392, 2.5896]]) gradient tensor([[-1.1272e-04, -2.5185e-06]])\n",
            "linear_2.bias value tensor([-1.8401]) gradient tensor([-0.0003])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAF3CAYAAABqlQinAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3XeYVOX1wPHvmZntC+zCskuHpSuC\nqIgdRcWaWBJj793EEhN77DFGYxLzi4kaaywJWGOLJfaCiqJU6R0W2ML2PuX9/TFDX3bv7M6duXfm\nfJ5nH5k7M/ceEO4758x531eMMSillFLKmTyJDkAppZRSu6YDtVJKKeVgOlArpZRSDqYDtVJKKeVg\nOlArpZRSDqYDtVJKKeVgOlArpZRSDqYDtVJKKeVgOlArpZRSDqYDtVJKKeVgvkQHYIUnPcd4s/Mt\nv168aTZG0zaP12vDOSUG54j+s5g3yuumRXENn8VzWzmnz9PxuWL1Gq90/BpPB6/xWPhjsvy3yAQ7\nfk3IwmsAsfi6rZeO7vUE/dG9HjCBQNTvieX7NwtF+3uN5tx++87d4bW7+OezoLK2whjTO0bhbJFe\nOMqY1oYunSNQU/KeMeaYGIXkCK4YqL3Z+eQdeo2l12Z2j/nfHUuy8/Jif87uGV17f7fOvT83yuv2\nzcuy/NpCizH1ycvs8DW9czo+V35Wxx/aCrI7fk1eZvv/VLLTOh6Fcy28Jtvb8dr7npa6Dl8D4Gmq\nienrAEK1lZZfCxCsKovq9V19H0DrpuhibE/TJut/NlGfu6zKtnN3pLGsa7+vsf9+e3WMQtmOaW2w\nfK/flYo3biiIUTiOoaVvh+rqIN1Zbhmk46mjQdqJohl8naYrg3Qs6SCtnEIH6hiwI5vuqs5m024R\nz2w6FuKdTVvlxGy6K2KZTSvlFEk1UCeq7K06lszZtJWyt1JOoNm0O+kdxoGSsewdS1ayaSvilU1b\nYSWbtkrL3l2XrGVv5U5JM1AnUxNZVyV72dsKK2XvWIhVE5kVWvZun5a9VbJKmoFaxZc2kalY02za\nXlr2di8dqLsgladkJUqqNpFZ5YQpWUqp2EqKgVqbyFQixLOJLNZlbztp2Vup2EqKgTpZJGMTmRPL\n3rFY4MSJtIms67TsrZzI9QO1NpFtlexNZLEqe8eCE1cis0qbyJRyF/elDco1nJhNW+HGbFp1nZ3Z\ndCK5KZsWb5p+ldkG12fUySIZy96x5La5005tInMip5S97aRzp1VXuHqg1rL3Vsle9rbCSWXvWNGy\nd/tSueztKygivd9gxOechXuUPWyt8YnItcDFgAHmARcAfYFpQC/gO+AcY0yrnXGotqVaE5kVWvaO\nL6dk025qIssYNIycUy6B7j1paGqlKDeduo/fouGjN3Z6rZvK3mrXbLsriUh/4Gpgd2NMk4i8CJwO\nHAc8aIyZJiKPAhcBj9gVR6wl09xpt0jVudNu2s5SxUda7z7kX3ITd721hP/Nm48xMKhXNn85fQq5\nQH0bg7VyP7treD4gS0R8QDawATgceDny/DPASZ05sTYcOFcyZ9O6AUfbtOwdH1mTjuf5r9fx3twN\nmMhnvTWbGrlm6jy6Tf4xkqZl8GRk213HGFMC/BFYQ3iAriFc6q42xgQiL1sH9LcrBjfQJrL40A04\nnEfL3tHzDRvDhwt3/nNbW9lIRW0zaUUDthzTsnfysG2gFpF84ESgGOgH5ADHRPH+S0VkpojMDLU2\nbPecNpFtpWVvZzWR6QYc8ZGK2TRAqLWF7lnpOx0XgdysdExLcwKiUnazs453JLDSGFNujPEDrwIH\nAXmRUjjAAKCkrTcbYx4zxkwwxkzwpOfYGKaKpWQue6vY0Wy6c4KzPueCAwfsdPzw3fvgaazFX74B\n0Gw62dg5UK8B9heRbBER4AhgAfAxcErkNecBr9sYQ8w4sYmss9xS9k7VJjKr7GgiU85W/+UH7J7d\nwt/P2pMJQ3syvKgbl08eym9PHEX9K48nOjxlE9vSCGPMDBF5GfgeCACzgMeA/wLTROSeyLEnozmv\nNpFtlexlbydx89zpaGjZ29mMv5Wqh+9m5EFTeOCoQ/BkZOJfsYBNDz2Bv2x9osNTNrG13meMuQO4\nY4fDK4CJdl7XDZIxm9ayd/y4OUvWsnfXGH8rdZ/8Fz75b5vPa9k7+bjvDpUA2kQWf6la9tYmsval\ncjadCjxeryPvt4nmqkmhWvZ2rmTOpnXutFIqkfQOlADJWPaOJbdtwGGFzp0O07K3vbTsnZxcM1Dr\n3Omtkr3sbYXOnbZwPi17K5UUXDNQq/jSJjIVa5pN20uz6eSlA3U7nDh3urPZdLRl70RJ1SYyq3QD\nDqVSjysGavE657tGlTpSZe50tLTsrVR8uWKgThbJ2ETmxLK3lWzajWVvbSLrOi17KzfSgXoXtIks\n/pJxAw6dO911mk2rVKcDteo0J2bTVrgxm1ZdZ2c2nUiaTSc/HajjJBnL3rHktrnTTm0icyKnlL3t\nlMiyt0p+OlC3QcvezuSksnesaNm7fVr2VkrX+k5qqdZEZoWWvePLKdm0NpG5g8crCas+Oplm1DtI\nprnTbpGqc6etZtM6d1q1xZdfQEb/gYhXP3wmO/0/rKLm1mzaCt2Ao21a9naO9AHF9DzxHNIKigjU\n1eHLyaH8rZepfO+NRIembKIDtc20iSw+nDR3WpvIwrTsHXu+XoUUXXw9yx/8K2X/ex+CQbKLh7Db\nPXcjHg+b3nktrvGo+ND0YRvaRBZ/yTh32gptImufZtNt637IMax/9TXK3nkXgkEAGleuYsHNt1Lw\no1OQNF3FMRnpQK2i4taytzaRxZdm0/bIHLYbFR9+vHMsa9bQuqmSjP6D4h6Tsp8O1BFObCLrLLeU\nvVO1icwqN5e9lT1Mayu+brk7PyGCLzeHUEtL/INSttOB2sGSveztJDp3um1a9naWhnkzGHD6qTsd\n73XIwYSaGmndsC4BUSm76UBtk2TMprXsHT9uzqa17G2fui8/JKt/H3b7/T10HzeWrEGDGHDO2Yy8\n9WY2PPePhMSk7Oe+O5gNtIks/lK17K3ZdPs0m26faW1h1b230POoHzPylhvwZmbRsPgHVt17Cy3r\nVic6PGUTHaiVJcmcTevcaeUmoZZmKt58iYo3X0p0KCpO9A5lg2Qse8eS2zbgsEKbyMK07G2vZFsy\nVFmT8hm1lr2dSedOWziflr1VkvF4PXr/a0PKD9SpSpvIVKxpNm2vbbPpXsf/hLyDDgevj+Y1yyn9\n1xMEqnWrzWSV0qXvVJ47nSip2kRmlW7Aodrl8TDsvofJn3w8Ja+8zurHnyIUSmP4A/8ge9SYREen\nbKIph8No2Sd+3Dx32k5a9naufudfQaglwKyzzt+yuEnZu+8x4JyzGHDF9Sz55fmJDVDZIqUz6lhz\nSzbt9rK3kzbgiCVtIuu6ZC9754zbl1X/eHynFchKpr2IJzuHrOGjEhGespltdzMRGQW8sM2hocDt\nwLOR40OAVcCpxpi4/wvQJrL4S8YNOHTudNdpNm2dJyODlspKRv/uHnqMH4d4fbSUbmTF3x6mtXIT\n6UX9aFq2ONFhqhizbaA2xiwGxgOIiBcoAf4D3AR8aIy5T0Ruijy+0a44VOc5MZu2wo3ZtOo6O7Pp\nRNq2icyEQoz98wPUL17CkrvvwV9TQ8HkQ9njgfvB56O13BmVDRVb8bqjHQEsN8asFpETgcMix58B\nPiEJBupkLHvHktvmTju1icyJnFL2tlMiy97b8qSnUzf/B+Zd/Usw4b9/9YsW07B0OSNuvhHj1005\nklG8vqM+HZga+XWRMWZD5NcbgaI4xbCFlr2dyUll71jRsnf7tOwdHdPaytpnnt0ySG9W/uFHmGCQ\ntPxeCYpM2cn2O5aIpAMnADutd2eMMUCbaYmIXCoiM0VkZshFHbPxlGpNZFZo2Tu+nJJNJ3sT2RYi\n+Gva+L0aQ6CuHk9mYipmyl7xSC2OBb43xpRGHpeKSF+AyH/b/JdujHnMGDPBGDPBk9EtZsE4ce50\nsmfTqTp32mo2rXOnlVX+qgp6HTppp+OZ/fqRXtCLutkzExCVsls8Buoz2Fr2BngDOC/y6/OA1+MQ\ng4qCW7NpK3QDjrZp2dsdSl94hoFnn0Wvww4FEQAy+/ZlzAP307BoPqHG+gRHqOxga51QRHKAKcBl\n2xy+D3hRRC4CVgM774LuItpEFh9OmjutTWRhWva2V1sbcDTM/Y6NU59k5G9uxtx4PYH6ejIKC2lY\n/ANr/nRXAqJU8WDrnc0Y0wD02uHYJsJd4HGnTWTxl4xzp63QJrL2aTbdeVUfvkPVh+/Qba+JeHO7\nUztrBqH65Ojj8XrFNcshx5N23qjtuLXsrU1k8aXZtL2sbGdZN+ubOESinCBlvrBzYhNZZ7ml7J2q\nTWRWubnsrZSKn5QZqJ0o2cveTqJzp9umZW+lnE8H6k5Kxmxay97x4+ZsWsve9rJS9lapJSUGam0i\ni79ULXtrNt0+zaaVil5KDNSqY8mcTevcaeUWmk2rtrivZugAyVj2jiW3bcBhhTaRhWnZ2xl8efl0\n3/cgPJlZNC6eT+OShYkOSdko6VMNLXs7k86dtnA+LXurNvQ85kSG3/cInt6D8AfT6XvhNQy+6R48\nWe5e1EjtmmbUSUqbyFSsaTZtLytl75w9xtPzyB8z88yzaS0rB2DlQ39nxM030vfcKyj5x5/tDlMl\nQFJn1Kk8dzpRUrWJzCrdgEN1Rc8jf8TqJ5/aMkgDYAwr/vq38Epl3bonLjhlG01J4kzL3vHj5rnT\ndtKyt3ul9+lH3fwFFF9zNYVHHgEiNK0vYdFtd9K8YT3pvYtoqqtNdJgqxnSgjoJbsmm3l72dtAFH\nLGkTWdelctkbwF9RzrhH/obxByh54UX8NdX0njKFfaf9G2NC+CsrbI7UXmlej+s3ELKD++52FmkT\nWfwl4wYcOne66zSbjh1ffj7+6hpmnX8hoeZmAErf/C8Dzz+XAWedRaDa+R3rKnpJ/R21ap8Ts2kr\n3JhNq66zM5tOpGjmTqfl9WLVo//YMkhvtu7f0/D4vOSOnxjr8JQD6B3PomQse8eS2+ZOO7WJzImc\nUva2kxvmTgOI10tzyXr6nnwivacciTcrm5rZc1j/4ku0VFSQOWQo9bN1V61kk5QDtZa9nclJZe9Y\n0bJ3+7TsHVuhQIDRd99Ba3kF6/41FX9NLQWHTmL800/gzcnRrS+TVFIO1Mki1ZrIrNCyd3w5JZtO\n9SayzYKN9fira5h3zbVgwhWfuvnzaVi2jOE3XEfL6hV2hKkSLOm+o3bi3Olkz6ZTde601Wxa506r\nWPFmZbPm6X9uGaQ3K3v/A0wwRM6Y8YkJTNlK05Md3H3anhw1vh/dstJoag3y3fJN3PTSHFoCoUSH\nFjNuzaat0A042qZl7+QgXh/+yjb+XEMhArU1+Ho472s/pxGRY4D/A7zAE8aY+3Z4/kFgcuRhNlBo\njMmLPBcE5kWeW2OMOSEeMetAvY3nrjmYorwsbn5xDrNXVzGsMJdrjx3NK9ccwo/+9GlcY3FLE1ms\nOGnutDaRhWnZ216d2SnLX7WJnoccQsOy5dsdz+jbh/TehdTN/S5W4SUlEfECfwemAOuAb0XkDWPM\ngs2vMcZcu83rrwL22uYUTcaYuJctkir96ErZe49BPRg7KI/zHv2Sr5dV0OwP8kNJDZc/HW7OOPug\nIZ2LScvejmoi0w044kOzaXuUv/wcg847h54HHbjlWHphb8bc/3salywgVO+eFfISZCKwzBizwhjT\nCkwDTmzn9WcAU+MSWTs0o444/7DhfLqwjOpGP+k+DwXdMqhuaKWxNchLM9Zw7J79eH76qkSH2WVu\nLXtrE1l8aTZtr87uO1036xvKXn6O0XfdQbC1lVBTE+m9e9O4ZCGrH7g9xlEmpf7A2m0erwP2a+uF\nIjIYKAY+2uZwpojMBALAfcaY1+wKdFtJc/frahOZ1yv4QyGuOXoUJ+87kMaWIN2yfHz8QymrKurx\nSIwCtcAtZe9UbSKzyo4mMqVMKEST+Ejrno0/qxsGAV8ahJKnj6aLCiKD6WaPGWMe68R5TgdeNsYE\ntzk22BhTIiJDgY9EZJ4xZvku3h8zSTNQd9WLX67moYsn8v3KSs742xdsqG6mR1YaVxw5gvMOGcpL\n36yJ+pzJXvZ2EjfPnY6Glr1TW7cJB9DzjIv58zsL+c/MEvzBEGP69+BPZ+7F4Dv/zOo7f2V7DI2b\nmmw7t88rlqt+7agwxkzYxXMlwMBtHg+IHGvL6cAvtj1gjCmJ/HeFiHxC+Ptr2wfqpPqOuivKapoJ\nhQzXT53Fhurw8nw1TX7ue3MBG6qbWLaxPi5x6Nzpnbmx7O3mLFnL3vbqbNkboODcK3jx69W8OGMt\n/mA4g/6hpIZfPDuTtMHD8GTlxirMZPUtMEJEikUknfBg/MaOLxKR0UA+8NU2x/JFJCPy6wLgIGDB\nju+1Q1IM1LGYO33AyN68P28DrW1Mw3rtu3XsU9wzupiSPJtO1bK3NpG1T7Npe4Wycnl77gY8AuMH\n53PgiALystNYXlpPVX0LPaccl+gQHc0YEwCuBN4DFgIvGmN+EJG7RWTbqVanA9OM2W7C+m7ATBGZ\nA3xM+DvquAzU7ktVbNIaCJKZ3vYfR1aaF38w2OZzbpHM2bTOnVYpw8DEYb342xljobqK1ppa8k8d\ny+vfrSMjzUtzo72VPzvL3vFijHkbeHuHY7fv8PjONt73JTDW1uB2QQfqiI/nb+S6E8dQ0C2DirqW\nLcczfB5OmjCQu16d1867YyOZmsisiFc2bYXOnQ7Tsre9ulL2Bkj3N3LlIYNYeP0N1Hw/CwBfjx4c\n+Yc/kOM1rP/g7Q7OoNzI9alIrJYMLa9t4ckPl/H4Rftx+JgieuamM2FoTx6+YCI/rKtm1mrr/7iT\nvexthc6dtnA+LXurKIkxrHvm2S2DNECgpoZlt92Kz+vB17vItmsnQzbtVppRb+Mf/1vCqrJ6fnHc\naPrmZVHd0Mq0r1bxwozoO77tpk1kKtY0m7ZXV7NpAPGlUTl9OlmDBzHogvPxZudQ8cknlL39Dq1l\nZeQdNJmK16bFIFrlJLZm1CKSJyIvi8giEVkoIgeISE8ReV9Elkb+m9/Z88d6A44hvXP49YljaPEH\nef27daytbOSiycPZa3B0jWSdEW3ZO1FStYnMKt2AQ9kqFGLYdb9i72f/iScjg9bycoZe+XMmvvEa\naXl5tG5cn+gIlQ3sTln+D3jXGHNKpBU+G7gF+NAYc5+I3ATcBNxocxwd8gg8ctn+PPvFCl75ZuvC\nNROH9eIPZ47np3/5nOpGf4fn0bJ3/KTK3Oloadk7eZlQkJziYmaediYtGzcCsOxPf2bU7bfS85CD\nqf36M1uuq2XvxLLtTiciPYBJwJMAxphWY0w14XVVn4m87BngJLtiiMZBowtp8ge3G6QBvlm+ic8X\nlfOjvfrbdu1UmzvtpA04YkmbyLpOy94dEVY9/OiWQRqAUIjlf3oQj89H5tBRMbqOchI7U5JioBx4\nWkRmicgTIpIDFBljNkResxHoVPdDrMveQ4u6MWdNdZvPzV1TRXHvnI5jSvJsOhk34NC5012n2XT8\niM9H7bz5Ox0P1NXRUlZG7ri92niXcjs7B2ofsDfwiDFmL6CBcJl7i8hk8jbvlCJyqYjMFJGZoTiU\nHTdUNTGsqO1VfYYV5bKxptn2GGLNidm0FW7MplXX2ZlNJ1LssmkwwSDZQ4t3Ou7JyCCjd2+ali2K\n2bU207J34tl5R1wHrDPGzIg8fpnwQF0qIn2NMRtEpC/QZgoQWUT9MYD0XsWx6/bZhRlrqritdy4H\njezN9CXlW44PK8zluPH9OeNv0225rs6dtodTm8icyCllbzslsuwdS6alieKfX07V1zMINjRsOT7o\nwvMJBYI0zJ+dwOi6Ls3rcVzi4AS2DdTGmI0islZERhljFgNHEF4XdQFwHnBf5L+vR3vuWJe9AfzB\nEDdMncWfz9qbr5dVMHt1FUMLczlmz37c/+aCDjPqZC97W+GksnesaNm7fVr2jjOPF8lKZ+KrL7P+\n1VfxV1VTePQUsouHIgKZQ4fTvGJZzC6n2bQz2F1jvAr4V6TjewVwAeFy+4sichGwGjjV5hgsm7Om\nmle/XcOp+w/m4JGFeDwwfXE5787d0PGbOyHVmsis0LJ3fDklm9YmMms86RnMu+qXDL/pevqffhom\nFMIEQyy4/kaG33g9GX0HxnSgVs5g613RGDMbaGu7sSM6e047sunsyID5yPkTGDMwjyc+Xsac1dUM\nLczlsiNG8Pq1kzjxwV1Pe0j2bDpV505bzaZ17rSKl2BDPXv85c80ry9h8V2/JVBTQ8Hhkxnzpz+A\nz2fLd9Qq8TR9iRhWmMteQ3pyxt+ns6IsvLD97DVVfPjDRt749aGce3Axz36xMsFRWuPWbNoK3YCj\nbVr2Tg2hpgZaysqZc8WVEArv9Fczazb1Cxcx7Fe/pLU0dtU/LXs7R8rf9TZn0zf9eHe+XbFpyyC9\nWU2TnxdnrOH0/QfF9LpuaSKLFSfNndYmsjAte9sr1mVvAF9eL9Y89cyWQXqz0nffwxhDzpg9Y35N\nlXiuyqjtKHtv1j0rjVXlDRy7Zz8umNiXgUU9qKxuYOr3GymrbcbrafszjZa9ndVEphtwxIdm04kh\nPh+tmyp2fiIUIlBdgy/P/uWOVfy5aqC206cLSzljvwEcXiSs/+sDzJo7j+ziIZxzxc/xDi5mbVVj\nokO0xK1lb20iS02aTUcnUFtNz4MPpmHZ8u2OZxQVkV5USN3c72JyHS17O4trSt92NpEBvPTNWrK8\nwuLLL6dy+pcE6uqonTuPJVdfTW6giX99Gbvvp91S9k7VJjKrtOyt4q159XIGnnM2+ftN3HIsrWdP\nRv/2LkItzYTqahMYnbKLpjERk0YXsuGzL/BXVSE+H2n5eQRq6wi1tLD+5VfYb8+j+fCH7W9uyV72\ndhKdO902LXunloy+A1n1+OMMv+F6Qq2tBGpryR5azIb/vE5G715kDBhMy7rVXbqGZtPOowN1hM8r\nhFpaGXD5ZfT5yU/wG0hP81H24UcEV68izRub6+jc6Z25seyt2XTXadk7euL10lJaStXa9fTaa0+k\nqA8NNbU0rFxFqLUV8cboRqUcxRV3SI8Nf/mydxgwZyzbxJWXHs6CNZVc/fh3rKtsJD8nnWuO2I3D\nDzuML95avP37kzybTtWyt2bT7dNsOrFaSjdQfNsd/O2j5bxy70e0BEKMH5TPfb+4mrScdJq7mE0r\nZ3LFQB0vQfFw1dS5tATCUx+qGlq5841F7DaoV4Ij61gyZ9M6d1qpsPQRu/HanA38+6utA/LsNVVc\nNXUuz15+AKSnQ1PnS9eJLnv7PBKzfQWSSUreAXfMpgH2G96LD+Zv3DJIb+u179ax37CCLl/XLU1k\nsRKvbNoKbSIL07K3vewsewMEM3N48/uSnY4v3VhHdUMrvY443tbrq8RIyYG6LYGgIWMXmVtGmhd/\ncOsArmVvnTtt6Xxa9lY2yNhFw0y6zwPBQKfPm+hsWu2aDtQRny0q4/Dd+5Cfk77d8TSvh9P2H8wX\ni+N7Y9QmMhVrmk3by+5sGiDDA2cdOHin4/sPLyAzzUvDwvm2x6DiL+UG6rbK3gBFPTJpag3w+MX7\nccioQrpl+hg/KJ+/nz+BYMhQ2KNrZehoy96JkqpNZFbpBhwqkUxjPfv3y+LOE0ZT3DuH/Jx0fjJh\nAA+cMoZMLxiz81d3yv00pYkYOzCP9+dvZO7aKm45YXfyczNoaAnw7+krqW0OMG5gD17/bl3Sl72d\nxM1zp+2kZe8UFgiw/LY72euIIznygqPwZaRTvXAxy669ltF33obsYqnjjmjZ29lSaqDeVTYNUN8c\nYMyAHvx47wGU1zbz1vcljOrbjUsOH8Gi9TXMXt35klqqzZ120gYcsaRNZF2nZe+uCVRVUjB5MkXH\nTKH622/x19TQ66ADSTv/XLy5OYQaG+ISh4ov990tbfLZwlJu/PHu/O1/i5m6zdSHA0cU8Oez9mHa\n16uTPptOxiYynTvddZpNO4e3WzcKj57CrPMvorkk3P293Otl1J234/GlxXSbS+UcKfcd9a788tjR\nlNY0bzdIA3y5tIJPFpZy4SHDEhTZrjkxm7bCjdm0UrsSr2wawJvbnVWPPrZlkAYwwSDLHvgjkpZO\n7j77R31OLXs7X8oM1O2VvQF279+DmSs2tfnctys20SOnc5mkW+ZOx2qRgVRvInMiLXsnDxGhds7c\nnY4HautoKSsl76DJCYhK2S1lBuqObKhuYmTf7m0+N7JPd/zB2N303cpJZe9Y0bJ3+7Ts7SwmFCK7\neMhOxz0Z6WQUFNCwcF5U59Ns2h10oI64940fGN2vO/sP334FssEFOZywT3/+9U30a+imWhOZFVr2\nji/Npu0Vz7I3QKiliSFXXIY3O3u74wPPOYdQMEjV+2/FNR4VHylx1+yo7A3h6VlrKhq497Q9+XxR\nOXNWVzG0MJcf7d2f2aur6JmdvI1kOne6fTp3WjnF0msvYtSj09j3lRdZ/9LL+KuqKTz6KHJGjaT0\n5WcTHV6X+TwSt8qdm6TEQG1FUY8sZq6sZNH6Gq44YiSHjOpNIGR48evVlNY0M25Iz0SHuIVbs2kr\n3Fz2tpOWvdVmi395PqMfeo5+p5+GGJCsTEqnPU3V/96M6jxa9naPpB+orWTTAKvK6zn/kCGcsHd/\nnvl8BbNWhTPqSw8fTksgxKttLITfHrc0kcWKk+ZOaxNZmJa97RXvsjcAubmM+tOTNK1dy7pnn8df\nU0PB4YfT57TzScvvRdkL/4x/TMp2ST9QW7W8tI7uWemc9fCXLCsNZ1ozV1by/vyNvPGrQ6lpak1w\nhPZIxrnTVmgTWfs0m3am4Xf/hcYVK5lz+c8hGASg+tuZ1C9YQPE1V+tAnaS0mSziksnDmbly05ZB\nerOqhlZemLGaE/bsn6DItufWsrc2kcWXZtP2Skg2DXgzc1jz1NNbBunNNr79DoIh/6gfWzqPlr3d\nJanvnlbL3gB5Oemsr2pu87mN1c1kpbe9tVxb3FL21iay9rm57K2SlEcINNQz8IrLyT/6GNKyMqma\nM5eyp5/GX11NRv+BiY5Q2UDiozbAAAAgAElEQVQz6ojpS8o5dLdCRHZ+7sgxRSwpdU/jkRu5uYlM\ny94qXoyBYffex4Ixk7jkpcWc/Oi3PFedx8i//pX0oiI2/a/j6VmaTbtP0g7U0WTTAJ8vLic73ct1\nx+0W3oAd8Aictv9gxg3K59PF5ZbOo3Ond+bGsrebs2kte9srUWVvAMnM4NuyVn7znwUs3VhHWW0L\nL8xYww2v/EBzSPCXrElYbMo+7ruD2mTS6EK+XFrBgJ7ZvHvDZBaur6W4dw6V9a28NGM1E4b0ZPry\ntpcYdaNULXtrNt0+zaadrTlgeH76yp2Of7m0ghZ/kAFX3ci6h+5PQGTKTrYO1CKyCqgDgkDAGDNB\nRHoCLwBDgFXAqcaYhC/Um+71UNvk557X5jOgZzaDC3Ioq21m6cY6Tj9gMKNyE7vgSTJn0/Eseyvl\nbkJTa7DNZ1r8QXIys9t8bjMte7tTPO6Qk40x440xEyKPbwI+NMaMAD6MPI6paMveAN8s38TRY/uS\n7vOwrrKR6UvKWboxnH2dvM9A5q/rOHNySxNZrMQrm7ZCm8jCtOxtr0SWvQHSPHD8+J1noAwryiUv\nN4N1T/4tAVEpuyUilTkReCby62eAkxIQw05O3LsfCDxwxl70iwygedlp3PTj3emTl8nZBwxOcISx\no3OnY0PL3irePCbET/fuy6n7DdrSS7PHgB48dPo4vKEgocCu13vQbNq97P6O2gD/ExED/MMY8xhQ\nZIzZvLv5RqDI5hgsOXHCQD5ZWEpFbQtTrzqIQMCQke7ho/ml/PPzFVw4aWhMr6dNZCrWNJu2V6Kz\naQACAVb9/j4u+MkpXDvlMFpa/EhrMxuefJT8Cy+g31mXsP6RPyY6yk7zecRRlTqnsPtOerAxpkRE\nCoH3RWTRtk8aY0xkEN+JiFwKXArgy+1t+YKdKXsDhIwhy+elT14WGFhb2cCAntn0ycukvLYZoY15\nW9uItuydKKnaRGaVbsChnM3QWlbG0l/8HF+PHngzM2kpL4dQiOJLL8G0tiQ6QGUDSwO1iOQD/YAm\nYJUxJmTlfcaYksh/y0TkP8BEoFRE+hpjNohIX6DNNCCSfT8GkFk43PbNoJ/4eDlXHDmC9+Zu4Jg/\nfExTaxCfRzj7oGIunjyM1RUNdoeQctw8d9pOWvZWuyI+H/1O/Rm18+YTqKkhUBP+wNhjn73xZmWx\n4dlH23yflr3dbZd3ShHpISK3iMg84GvgH8CLwGoReUlEJrd3YhHJEZFum38NHAXMB94Azou87Dzg\n9a7/NsI6m00D1DYHaAmE+N3r87d0VQZChn9+voLFG2pZsWnXA3WqzZ120gYcsaRNZF2nZW97hQJB\neuy9F8N+fS2Z/fvjzcmh6Lhj2e2eu5H0NHwFhYkOUe1CZEy0vsTlNtpLaV4G1gKHGGNGGWMONsZM\nMMYMBO4DThSRi9p5fxHwhYjMAb4B/muMeTfy3ikishQ4MvI44Q4dXcjHC0oJGdinuCenTBzEpNGF\n+DzCu3M3MLqoe6JD7LJkbCLTudNdp9m0ewiw6NbbkfR09n7+GQ547236/uwUFt58Ky2lZRQcfUKi\nQ1QRIuIRkTNF5L8iUgYsAjaIyAIReUBEhls91y7THmPMlHae+w74rr0TG2NWAHu2cXwTcITVAOOl\ntsnPoF7ZvHDlwXi9wpzVVRw/vh+3nDCGr5dV0Bxoe+6inZyYTVvhxmxaqV1xSjYNgDH0P/cc8vfZ\nm6o5c/FXVlFw0AEMv/1W0rrl4i/f+YOelr0T5mPgA+BmYP7mr4wja4lMBu4Xkf8YY57v6EQd3lFF\n5CBgtjGmQUTOBvYG/s8Ys7orv4NY60rZG+Cfnyxj2tWH8MiHS3nui60r/0waXcj9p+/Fv2esavN9\nbpk7bSWbtiLVm8icSMveqcOTkU6PPcbw/dnn0bQmvFzosrQ0Rt1zN74JE9j031cSHKHaxh+B74wx\n67c9aIypBF4BXhERSzdUK908jwCNIrIn8GtgOfBsdPE6300nj6W8rmW7QRrgs0VlTF9Sxo/G9UtQ\nZPHjpLJ3rGjZu31a9naXYKuflY/8Y8sgDWD8fpbdex++NB854/fd7vWaTSfUCcAbIrJWRN4XkT+K\nyNkiMnbzd9XGGL+VE1mpUQYi06hOBP5mjHmyg++mXWlEUS4f/1BKToaP48b3o7h3LmU1zbw1u4Sv\nllYwYUjPnd6Tak1kVmjZO740m7aXo8rehDcKqp01m+yhQymcciSe7CxqZ8+h4rPPaS4tI3/SkTTM\n/jbRYSrAGHMJgIjcAvQHVhAueT8GVAIDrJ7Lyl21TkRuBs4GJomIB3DUjPSulr2zu2VQ2dDKuEF5\nvP6rQ/l+VSVzVlcxtDCXV645hDmrq7B9fpiNdO50+3TutHKLUMgw+NKL6T52D0rffofWsjL6n3Ea\ngy66kIyCXtR8+m6iQ1Q7O80Ys6VfS0QeBq6P5gRWBurTgDOBi4wxG0VkEPBAVGG6wF1vLODJ8/fl\nxmmz+GzR1ixl2terefbyA3lt1tq4xeLWbNoKN5e97aRlb2VFWk42uaNG8d2ZZxOoDf/9XvevqRRf\n+Qv6nHQCle++tuW1WvZ2jFoR2SfShI0x5jsRGRnNCdq9a0bq6FONMX82xnweucgaY4xjvqPuaja9\n2fHj+rKirG67QRpg6cY63p5dwvDe3bY77pYmsljRudPOo2Vvezmt7A0QrK9n1SOPbhmkN1v9xJN4\nfGkU/OTMBEWm2nER8IyIPC0iV4rIPwBL301v1u6d1RgTFJGQiPQwxjjvb20MZEey1wH5WSxY2/ZN\nYUFJDXsN6hHPsGJG507HhjaRKScQj4eGZct3Oh5qbqalvIxue02k4tV/JyCy2PCKuPIDf3uMMUtE\nZG/CG1CNBRYCt0RzDit/IvXAPBF5H9iyPJcx5upoLuR0S0vrmTyyoM3n9h6cx4ba+Kyh69ayd7L9\n41LWaDYdX8YYuu2xO40rt5+d4s3NJaOwkI0vhTcm1LK3c4jICMLbOTcbY37RmXNY+cLwVeA24DPC\ni5x0uNhJvMSq7A3w3Ner6JOXxUn7bL/X6z7FPTl8j778/dMVW465peytTWTt07K3chtPZiZDLr+c\n9MJtNioSYeg1VxPy+6l6943EBad25TnCK30eAiAie4hIVF8fd5gGGWOe6eg1bpW9TfYaCMHtr//A\n3SeO4bT9BvHN8k2M7tudPYt78cTnK1i9qTGBkbqfm5vItOytnCLU1MSmzz9nn389x6bPPsdfU0Ov\nQw6mpawMEaH7/pPY+N/3Eh2m2p7HGPOOiNwLYIyZLyJ7RHMCKyuTjQB+D+wObKm3GmNiu0GzA3y9\nspL61gCDeucyrE93gkFDMBjklW+2dnzr3OmdubHsrdl012nZO/7E42H9Sy+z5vEn6TX5UHzZOSy5\n+x5q581nwksvkN4n+RdmcqH1IlIM4Vm+IiJAVGVWK3fYp4E7gAcJT9a+AGslc1vFYu70jt675mAa\nW0Pc9ep85qwJz6O+5uhRvPnLQzj6L5936Xrxlqplb82m26fZtLsZoOcB+7Pu+X+z4eVXtxxPLygg\no6gQf0V54oJTu/JL4Amgj4hcABxDeCdJy6wMuFnGmA8BMcasNsbcCRwfbaRO99O9+uHzeTn7ken8\nb94GSmua+WppBef/4ysaW4M8fs4+tl4/mbPpeJa9lUpmkpnJoPPPo/vYrZVTX7dujLrzdkwgQEut\nNpE5jTFmFeHB+WpgKPApcE4057CSUbdEViNbKiJXAiVAbnShxlYsm8g2u+ywYXyxuIyyHbq7m/0h\nXvhqNRceOtQ1TWSxEq9s2gptIgvTsre9nFz2BjBNTax77l/sdu/vaKkoJ1BdQ7c9xlD27nvkDB9G\n/kGTqPz4w0SHqbYhItOBW40xLxNuKoualVTnGiCb8KeBfQgvJXpeZy7mFG2Vvb3ioa450Obr61sC\nhIx7FhFNxrnTVmjZu31a9k4CIrRUVRFsbiZ31CjyJu4LxhBsaSHY1IQnK/ZJjOqyy4ArReRDEdm/\nMyew0vX9LYCIhIwxF3TmIm7w1YpyjhhTxL2v/4A/GNruuRP36Y8/FN1ArU1kKtY0m7aX07NpALxe\nRvz6WtY88xzrX3yJYGMj+RMnMurO2/Dm5LD4NzckOkK1A2PMfOCnkUVP7g73kvEbY8wcq+foMJUR\nkQNEZAGwKPJ4z8ii4glhR9kb4LMlm/Bh+POpe1AYuUa3TB83HjuSwXkZLNxQa8t1Yy1Vm8is0g04\nlJuJeCj979usffqfBBsawBiqZsxg/rXXQShEa5077lMpahnwW8JfH0e1FomVlOgvwNHAGwDGmDki\nMinaCJ2irbI3wOkTB1Lz2WcMrK7h9SuPpbahlR7dsiif/hVlz37AmDPOjnOk7ufmudN20rK36iwT\n8LPxrbcByC4uxpudRcOy5dQvWoS/tpbh19/Msjt+k+Ao1bZE5GNgBNAELIj8nB/NOSzVLo0xayPp\n+mbBaC4SK3Zl0wAhAyKw5s9/Zt3DD5PeuwB/VTXB+nr6n3UmZvvff7vcXvbWDTicR8ve9nJF2RvA\nGHJHjWLkb27Gl5ONv7aWzD59KJn2IuLxYAJt99m4hUckGWeJ/BpYaIzpdEu+lbvtWhE5EDAikka4\nuWxhZy+YSLvKpgGe+XIlvzvuYFZ070agto7mtesAEK+Xfqf8hC9K6uMVZqclYxOZzp3uOs2mk4dk\nZDD06l+w+K7fsunTzwDI6NuH3X9/L96cHJbf/7sER6g2E5E7I9OZs7CYFO+KlY8ulwO/APoTrq2P\njzxOKllpPlqCMOrhR+ix916I10vOiOGM+OMfacnMxW9CHZ8kSk7Mpq1wYzatus7ObDqRXJNNA6Gm\nRkqmTtsySAO0bNjIwltuRTxe0rp1T2B0ageb13K9BpghIktF5HUR+a2I/CyaE1m54xpjzFlRhxhj\ndpa9ASaN7M27P5Qyv6SeS+/+HWN7daeurompM9ZQ/cVaTtt/oKXzOHkDDitSvYnMiZxS9rZTIsve\nbiJeHxWffIonK4ueB+yPNyuLmrlzaV67jtaKCgqmHM2Gaf9KdJgKMMZ8FfnvqQAikgGMIbzV5UTg\nJavnsjJQfy0is4GngHeNcdGE4m20V/YGaGgN0D8/i1H982jGx1uz1jO0MJcfTxjM10vLaQnGPqOO\nNyeVvWNFy97t07J3kgmF6H3kEfQ9+STqfliAv6aW4it/QfW33+Lrlkvrpk2JjlDtQES+AG4zxnwM\nfB/5iYqVgXokcCRwIfCQiLwI/NMYsyTaiznZc9NX8dSFE3nyk+U8/dlyNn8cOWJMH+752Tj+/d3a\n9k+A+5vIrNCyd3w5JZvWJjJn8GRn0/fkk5hz2c+37EntyUhn9G/vBq+XTe+/m+AIVRsuB+4SkVsJ\nr1D2VbQn6DD1MWHvG2POAC4hvCrZNyLyqYgcEHXIneDxWu+4bktH2TTAGfsPorK+hac+3TpIA3z4\nw0a+WlrBpGEFXYrBTjp3un06d1oli0BLC6sef3LLIA0Qamll6b334UlLo+j0hH9LqXZgjJlvjPkp\ncD3wGxF5S0T2jOYcVhY86SUi14jITOA64CqggHDL+b87Ebcj7dG/B18trWjzuelLysmLYdnYrdm0\nFW4ue9tJy94qFjxAzXffkzVoEIMuuoDiK39Oz4MPwl9bS3NpGUXH/zjRIapds3XBk6+A54CTjDHr\ntjk+U0QejeZiTlZe18Kworb3GinunYs/2H6GlwobcLix7K1NZF2nZW/nCIUMgy44n7wJe1P2znv4\na2oYdMH5DL7kYjIKelEzb3aiQ1Q7iNeCJ6N21UBmjLk/moslgpWyN8DfPl7GU+fty/jB+cxevfXm\n0S8/i5/sO5APljhzn1edOx0b2kSm3CAtN4fu4/Zg5ulnEagJ/51d+8yzDP3lNWT278/yO25NcIRq\nW5GdJz8GjuvKgie7vGuKyOMiMratQVpEckTkQhFJmi9EbjpmNIEN6/n7GeO49fhRHDOuL1cdMYxp\nl+5L88IFTCrOi8l13Fr2dmM2rbpOs2ln8VeUs+rhR7cM0put+sdjeHw+soYUJygy1RZjTAg4piuD\nNLT/HfXfgdtEZKGIvCQiD4vIUyLyOfAl0A0Le2uKiFdEZonIW5HHxSIyQ0SWicgLIpLeld9ArPTp\nkUnVN9+y5LpfM7lbE9cdNoiTBqVR8of7qXjnHdJDu1411clzp7WJzJ2cUvZWzuLJzKJ+ydKdjoea\nmmgpLyN7+IgERKU6MFdE7ohk152yyzTJGDMbOFVEcoEJQF/CNfaFxpjFUVxj85Kjm5fMuR940Bgz\nLfId90XAI50JviNWy94A6yqbGH3QAeQddRQvzSzh+1krGd47m3N/fT1sLKFZvHaEmDTc3ESmZW/l\nGga67b7bdl3fAN6cbDIKCwm2NCcosNjweGK3P72D9AQOBa4QkRnAXGCuMcbygidWpmfVG2M+McZM\nNca8Fs0gLSIDgOOBJyKPBTicrZn4M8BJVs9np2e/XIanoJBLn5vD/32wnM8Xl/H0F6s47bFvSRs6\nnDU1bf8D0LnTKtackk1r2dt5vLk5DPn55aT36rX1oAhDr7qKkN+PN80RBUq1DWPMqcaY3YDBwF2E\nu7/3i+Ycdt+B/wLcQLhMDtALqDbGbN7iZR3hNcRjLppsGuDOE/dk9uoqFpRs/4+4rLaFl79Zy6n7\nDYpleF2WqmVvq9m0E+ZOazatYi1Y30Dzho3s+8qLlH/wIa2VlfSeciTejAxEhO777semjz5IdJhq\nG5GpzXOAeZGft40xz0RzDtsGahH5EVBmjPlORA7rxPsvBS4FSOteGOPodpaZ5mXNpgYuPmwYZ+5d\nRG5mGi3+AP9bWsOC9TUEuriEaDJn00m4LZ1SjiQeoWTqC4y45UZ6TzkSxIMJBij/4AN6jN+LzH79\nEh2i2tkJwLjIz2XA8SJSbowZYvUElgdqEck2xjRGEdxBwAkichyQSfg76v8D8kTEF8mqBxCe/L0T\nY8xjwGMA2X1H2L6++OqKRo7do4i05gZWPvRXls2dR3bxEI76+RUcNboYbxuro6XC3Ol40SayMC17\n28vNZW8AA4z8zU1Uz/yOdc89j7+mll6HTWLwhRdAWhpL770r0SGqHRhj1gPrgXcBRGQ34JRozmFl\nZbIDRWQBsCjyeE8RedhCcDcbYwZEPjWcDnwU2YXr422CPA94PZqArYi27A3w+px1ZPmE2RdcTNk7\n79JcUkLlF9OZc+HFpPtbKK1riXWYnZaMc6et0Cay9mnZO7k1bmrCk55BzazZLLjhJmrnzadpzRrW\nPfs8i26/E9PcTO2X0xMdptqBiAze9rExZiHhPTQss3IHfRA4GtgUucgcYFI0F9nBjcCvRGQZ4e+s\nn+zCuWLm55OHs+nrGbSUlm53PNTczPqXXqFfzvbFB20iU7Gm2bS93J5NA4Ramln3r8jKzR4Pkhb+\nQL7p8y8I+f2MvPeBBEandmGqiKwTkc8j05zvBfaI5gSW7sTGmLXhhu0tdj2puO33fwJ8Evn1CsJ7\ncTqK1+PBX1Pb5nOBuloIRvVbtk2qNpFZ5YQmMqVsI4KkpzPqztspmHwY4vVSv2Qpa57+J8HGJnx5\nPRIdodqBMebAyIynYYT3ou4JRLUou5WMeq2IHAgYEUkTkesIz4t2pM6UvQG+X1tN4aGTEN/On116\nH3cczR7nfJ/rFG6eO20nLXurWGvcFFnYyuNht7vuoLmkhBk/PpEvJk1mzVNPM+L660gv6MWKB/+U\n2EBVmyK7UC4zxvzHGPPkDvtmdMjKnfZy4BeEp1GVAOMjj5NGbvcMllbUEfL5GPX735HWMx8Ab3Y2\nQ66+ipziIVQ2bP2O2u1lb92Aw3m07G2vZCh7A4jXS8Wnn7P68ScJ1NZBKETlF9NZcPMtEAzSvKHN\n3lyVQCLymYh0j/z6chH5ZbQrcnZ4NzbGVACuWNO7s9k0wMnj+vPpolKGFu/OxNdepbWqmvS8HlTU\nNvP8t+s5dd+BMYy0c5KxiUw34Og6zaZTh/H72fjaazsdr/thAf66eob/+iaW3aUbczhMD2NMrYjs\nA1wCvAU8TriZ2pIOB2oR+Wsbh2uAmcaYmHdsJ4yBoDGc8sgMenfLYEz/HqwsX8jqTY2ce/AQ2Hl2\nVoecmE1b4cZsWqldcXs2vaXsvZmn7Q/AIoKha+s9KFv4RcQHnAvcb4x5MbIIimVWSt+ZhMvdSyM/\n4wjPf75IRP4SZcCOk9s9PJi+MqeEw8b0pVumj/K6Fj5ZVMbqTY14PcLP9hvM+rpWwNkbcFiR6k1k\nTqRlb2WVpKXR9+SdV13uPm4s3twclv/pDwmIKna8hO8LXfnpiIgcIyKLIxtD3dTG8+eLSLmIzI78\nXLzNc+eJyNLIj9WM+CHCK5P9CHgzcizX4nsBawP1OGCyMeYhY8xDwJHAaOBk4KhoLmanrpS9Ab5d\nUw1+P0+cO549B4W3tCzuncNfThtLnifIa3M2xCJMWzmp7B0rWvZun5a9k9uO2bQJBOl54IEM+fnl\npPXMR7xeCiYfxm73/g7x+kjLy09QpO4gIl7CO0MeC+wOnCEiu7fx0heMMeMjP5v3qugJ3EF4ne6J\nwB0isss/8EinN5HlQvcD9jDGNInIcOCrbV/TESt33Hy2H/1zgJ7GmCDgnFVAOmFzNg2wR9/ulP/v\nfeSl5/j7GeOY9btjmXr5AfSf+RGlTz3JnkWZrm8is0LL3vGl2bS93F723okJseiOu8js35/93niN\ng7/4lCFXXM6Se35Ha3k5A889P9EROt1EYJkxZoUxphWYBpxo8b1HA+8bYyqNMVXA+8Ax7bz+YxG5\nSkQGRTa32vypaw3wvIg8g8Xvqa3clf8AzBaRTwh/UzsJuFdEcgBHrP7e1WwaoDkQJHfEcHoeeyzN\n/hDfLChleFE3is48k8DihcwPdHwOu+jc6fbp3GmVMoxhxG23kN6jB7WLl+KvriZ/7/GM/N1v8QSC\nBKqrEx2h0/UH1m7zeB1t72T1UxGZBCwBrjXGrN3Fe9vbVOoY4ELCC54MBaoIf5XsBf4H/MUYM8tK\n0Fa6vp8UkbfZukjJLZG1SwGut3IRN/hyRSWXHbA3z01fxWMfLSUUGUeOGdeXO34ylsqZa9s/wTbc\nmk1b4eayt5207K1ibacmMsCTnY3P42H2RZfSsHRp+FhmJqPv/z3dxo5l0/vvxTtMJyrYoVnrscje\nEVa9CUw1xrSIyGWEt2M+PNogjDHNwMPAwyKSBhQATcaYqD9NWb3rNgMbCH8iGB75pOFq25a9Af56\nyjiqG/08+uHWQRrg3bkb+HpZBWc5YHpWV+jcaefRsre9kq7sDQSam1n92ONbBmkIL3O89K678fm8\n9Dr5ZwmMzjEqjDETtvnZdpAuAba9me+0MZQxZpMxZvPXuk8A+1h977YijWcVIlIZOU99ZwZpsLYp\nx8XAZ8B7hDe9fg+4szMXs0Msyt4AhbkZTF9S3uZzXywpp8WfmGkPOnc6NrSJTCUDD1D97Xf02Htv\nxjz4J/Z89GEGnncu/uoamsvKKTjwoESH6HTfAiNEpDiy6MjpwBvbvkBE+m7z8AS2rsT5HnCUiORH\nmsiOihzblduAKYSbr9cA93Y2aCsp1DXAvsDXxpjJIjK6Kxd0qtZgiOLebXfMD+6VQ5rPWvHBrWVv\nN2bTqus0m3amtsreACZkGHX7rWQPHkTpO+9SX1lF0fHH0f+M0/Ckp9NcXtrm+1SYMSYgIlcSHmC9\nwFPGmB9E5G7Ca4O8AVwtIicAAaASOD/y3koR+S3hwR7gbmNMe5+Ya7f5Dvo2EZnR2bit3J2bjTHN\nIoKIZBhjFonIqM5e0Al2LHsDPPD+Qm46anfGDsxj3tqt1Yk+PTL56cRBVDXGv8Fdm8jap2VvlWp8\nuTmYXj355ic/w18V/iC0+oknGX7dr+h9zNEsuOSCBEfofMaYt4G3dzh2+za/vhm4eRfvfQp4yuKl\n+orIpYS3iF4IdPpGbGWgXiciecBrwPsiUgWs7uwFYylWZW+AXx85mkAwxGMX7cd/Zq7lu5WVDCvK\n5ZyDivEHQhTEaMERt3JzE5mWvZWb7CqbBgjU17Py4Ue3DNKbrXz4UYp+/CMGXnUtax960O4QlTV3\nEN4t66zIf3MjjdlzgLnGmKlWT2Sl6/vkyC/vFJGPgR7Au1GH7BBtZdMAWWleXv5mDc2tQU6ZOJhj\n9+xLmtfDrFVVfLKwlGuO6biIoGXv+NFsuuu07O0+HvFQv2jxTseDjY20lJWTv9/+rH0oAYGpnezY\naS4iAwgP2OOA44DYDdQ7XPjTaF5vp1hm0wBN/iCH796HnEwfr36zlu9XVzKsMJdzDh7KoIJsMi1+\nRx0rqVr21my6fZpNpzZjQuSOHkXjypXbHfdmZ5NR2JuKLz5LUGSqI5GtLdcB70T7XvelUja57c25\n3HfieC5+YsaW76g/+qGUN78v4ZVfTmLFpoZ235/M2XQ8y95KpbL2yt4AnrQ0Bl98IVUzZuCv3Fq1\nGHL5ZQQbG6l4/VW7Q7SXCbpq/YR4SamBeldlb4CrDhvF3DXV2zWSAWysaeblb9Zw0j4D7A4v5uKV\nTVuhTWRhWva2VzKXvQFCfj/1S5cxYeq/KHv/AwLVNfSadAihQABvdjYDLruCxdddm+gwVYy5cqCO\nddkboHtmGjOXbeLcg4s5df/BdMv00ewP8tEPpSwrq8PEbpzpUDLOnbZCy97t07K38vh8dN99dxpW\nrqJwyhTwePBXV+Mv3UigsZHM/u5emEm1zZUDtR0WldVxzLi+BEKGv763mNlrqhhamMtVR41iytg+\n+EO7XvAkmcveKnY0m7aX27PpjsreAKFgEG92FqGmJhbcdDP+mloKDjuUgeeejfh8rJv6XBwiVfGW\nMnfq9sreAF+v3MSEgfmc/uBnrK8O/4NZVd7A10sreOu6w6ht8ccjzJRtIrNKN+BQqcyTlUXNtzOZ\nf+2vtxxbs2IFjStXMlJRfMwAACAASURBVPLWW9j47+cTGJ2yi+u6hOwoewNccfBQvlpavmWQ3qyx\nNci0r1fTO9dZ2XA8uHnutJ207K1izUo2DRBqbGTdc//aesAT/jda8cmnmECAUX/8PzvCUwmWEhl1\nR9k0gM/robKhtc3nqhtaCe6i9O3EsrduwOE8Wva2l9vL3paJgNfLyN/cTO8pR+JJT6d2/nzWPP0M\ngfoG0vLzEh2hsoGrMmq7smmAkqomDt+9Dz6P7PTcceP7kZnmte3amyVjE5nOne46zabVFh4Po+++\ng9aqKr45+RS+OOQwSqa+wMjf3Ex6YW9KplleQ0O5iKsGajstLqsjzSPce9p4ekQGw8w0D1dOGcnI\nPt2pqN8523ZiNm2FG7NppXbF7dm01bI3gPjSqJz+Jasiy4iaYJCKjz9h4c2/wQQCtFRW2BipSpSk\nv2NbKXsDjO7TnYavvmCf4mH876bDKattpqBbBs3VtWx6+UXyTjjJ1jitZNNWpHoTmRNp2VvFSqi1\nlQ2v/men47Xz5hNoaGDUzbcz65QTEhCZspNrMmo7y94A/mCIUMhgAkEgnE0LggkGMZHnEs1JZe9Y\n0bJ3+7TsndyiyaY7FM/FHlRcJXVGbTWbBnhx1jp+OelgvllRyW//8DFVDa1kpXu57PDh/OzU01hQ\ntv2AomVvZYVm0/Zye9k7WpKeRp8TT6TuhwXbHe+2xxh8ud34/vKLExSZspMr7toer/0Z3o/G9CVg\n4IZpswgEw59Mm1qD/OXdxew9pCdj+nS37do6d7p9OndaqYhAgIJDD6G1opySaS8SqK+n50EHMuKG\n6xCvh+yiQhrLNiQ6ys4LBV39NZddXFP6ttuYvt356IeNBIKGEX26cdTYvowflA/Af2evJxTcOj3L\nrdm0FW4ue9tJy94q1jpV9g6FWHjHXWT27ct+b77GwZ9/wqDzz2Pp/Q/QWlHBsOtujH2gKuFsy6hF\nJBP4DMiIXOdlY8wdIlIMTAN6Ad8B5xhj2p7A3AXRlL0BMFDYPZPHL96PAT2zmb+2mqGFuQB8s7wC\nr8fZn2l07rTzaNnbXqlW9gbAGExrK4vv+i2Lf/s7xOvF+P0gwshbb6G1clOiI1Q2sPPO3QIcboyp\nF5E04AsReQf4FfCgMWaaiDwKXAQ8YmMclswpqWavIT3595eruPypbwhGmsd+tFd/fnPiGEzAniVE\nde50bGgTmUoFnvQMBpx1JjXfz4JQCBNZiKnXIYfgSUtj1YMPJDhCZQfb0kQTVh95mBb5McDhwMuR\n488A9s57smhsv+7UNrby9/eXbBmkAd6aVcLMFZvISAsPlm4te7sxm1Zdp9m0M3W22zvU2kL3sXuw\n+wP30X3cWLIGDWLAuecw+u47wOcj/5jjYhypcgJb67ki4hWR2UAZ8D6wHKg2xgQiL1kH9I/1daMt\ne/fNyyLN62H64rYzp08WldHsD8YitO1oE1n7tOyt1PY8aWnUL1+B+NLY/Q/3sddTT1B07NGsf/0N\nTEsLRYdPSXSIyga2plnGmCAwXkTygP8Ao62+V0QuBS4FSM8rtCfAHQwuyG7z+KD8LHw+Z39H3VVu\nbiLTsrdyk67MnQ61+vFlZRIMhVh67/34a6rpdegkio49BklLo7m8NIaRKqeIy93ZGFMNfAwcAOSJ\nyOYPCAOAkl285zFjzARjzIS0HOsLzXcmmwaY+u1Kxg3uxe79e2z3fGH3DH6632Ca/CEte8eRZtNd\np2Xv5OPtlot4vJS9/wH9fvZThl59JRjD+pdewQSDLLjsokSHqGxg20AtIr0jmTQikgVMARYSHrBP\nibzsPOB1u2KIxo/GDaQ1EOTJS/bjV0ePZNLoQi6cVMzLVx9Ca2sg5hlnqpa9NZtun2bTqj2B+npC\nLS30+8nJlH/wIWuffZ70/Hz6nnwSnvR0in9ze6JDVDawM9XqCzwjIl7CHwheNMa8JSILgGkicg8w\nC/j/9u48Pqrq/v/468xkJnsggSSELSHsi6CCCirgAoi2St0Qra1a97UubbXVatW61rY/W7uodUHt\nt+5FbK3aikqrgiyyC8galux7Msms5/fHTEICk2SWe2funTnPx4OHyZ3JzLlC7ns+n3vuuc/pOIaQ\nZdpTePvLveytdXD1KaM4Z+owhAXe33CQbeXN3DZvdEivY8ZqOpZtb0VJZtEuGWoRFrY/8hhDL72Y\n4muuRghw1tSy/uZbmPTE4/Q/dppGI1WMRLegllJuAI4Jsn0XcLwe7xlp2xugze1l+qh85ky28d76\nctaX1VNakMUFxw9nVGE2thjc5jJcsaqmQ6Emkfmptre+krntDSClj4m//hVCwL6XXsbT2Ej+3Dkc\n+/xfECkpNG3bGu8hKjow38lLnTz/+XaunTmO657/knV7Dx2I3lmznzdvmUldm1Oz90rEa6dDodre\nvVNtb6Uv1sxMXFXVfPWDq/A5/cekqvc/YOj3vsuwy75P3fv/jPMIFT2onmfA1SePZfP+hm4hDXCw\nvo23V+2jf3rf4WrGtreiHVVN68vs1bQWd8rytrSy5+lnO0O6w4FXX0dYrAy+4uqo30MxnoQ5kkfT\n9gawWy3srGwJ+tzd1S14PL6gj4UrWSeRhUrdgENReiYsgvbKSgZfeAH58+ZiTU+ncd06Drz2Oq7a\nGuxFRfEeYlSEuilHUAkT1NGqd7g4cUx+0Mdmji3AbsBz1NEy87XTelJtb0VrWt13WgLjH7iPtgMH\n2fvsX/A0NjJg9iyOfvZpUjIzqflypSbvoxhLQrS+o62mAd5Yd4DcTDs/mD0SIQ5tP33iIE4YNYBa\nR+/nqGPZ9lY34DAe1fbWl9nb3lqxpKfjrK5h8x0/puHLVbRs287eZ/7Czid+g9flYs+D6vKsRGS+\no7lOLj+hmA176zltQiHnHDuEDWX+u2f1z7Tzz3UHOGvK4KjfIxEnkalrp6OnqmklVB5HG/teXAyy\n++9d9UfLGPWTHzPxmRfZfM3l8RmcohsV1AFWi+BAfRsPLlnFUcP6U5qfxb/WH2TlzhouOH44847q\nOZDUJDJFUXqiVdsbwCIEEii+6y4K5s7BnpZK9cYtVD33LO6WFlL6ZWv2XopxmP6IrkXbG2B7VQun\nTijk4aWb2bivgY37Gjofmz95MCnW6M4ShFJNhyLZJ5EZkWp760u1vQ/xWayMfOhh3tlQyeKnVtDo\ncHHqhEJ++suHSc2ws+2xh+I9REUHCXGOWgubK5qwWS08eMFksgMVqT3FwrWnjWLc4BzqW126j8FI\nbW+tqLZ371TbWwmHxZbCJ7sb+dX726lqasfp8fH+hnJue30jTilo2bAu3kNUdGDqilqrahrg2xMG\n4fhyJSdNPpp///R0qpvayctKxev20PD+ewycG/z2cartndxUNa0vs1fTWra9Ado9Pl5fUXbE9rV7\n6ml1epjy7GLWLzpP0/dU4k9V1B0EeJ1OPOUHEEC6zUqKReBrqMddV3fE5I1wqGune6eunVaUUAm8\nvuC/ez6fRHS9ZEVJGKr8Cli2vZo5J53M2r313P/EJ1Q3O8lKTeHGOaNYcPEl1Lu8R/yM0arpUJi5\n7a0n1fZWzMBuFZx73FA2H+j+oXXikH7kpNtZd/01cRqZoifTVtRatr0BctLseBDc9n/rqG72XzPd\n4vTw2D+3sqe6FXuUk8mipa6dNh7V9taXansfyep1c+b4fK45pZTstBSEgBNHD+R3F0/Gho+8seM1\nf08l/kwb1Fo7bnh/Pt5cjtt75FKh73x1kNQIO0rq2mltqElkigLS62XXffdyjrWSj+48hZX3zuGB\nmQVUPPYw7toaim/7UbyHqOjAfCWYTrxSkp0WPDCzU60cfurHaG1vM1bTSvT0rKYVA5ISn8PBrp/9\nlN0pKQibDV+bv3IffddPkB5PnAcYHen1qvklQZiyota67Q3w2tr9nDiukILDXjvNZuGiGSW0uMO/\nKYeaRNY71fY2NtX2jpwebW8AkZ7O0O9eAoD0eDpDOu+kE7HY7Gz/ye26vK8SX6YMaj1ccfww2lwe\n/nLVdM6YXERhvzRmjB7I01eegNPtZUCmPd5DjIqZJ5Gptrei+Mn2djJHjmTc/feRNX48aUVFDFl0\nEWN+fjfCbiNv/lnxHqKiA9MFtR7VNIDFYuE/myp44r2vOXfqMF66bgY3zBnDktX7eOG/u3A4D836\nVm3v5GaUalpNIjMmvappAAFs+fm9OMrKGHvfPUx5+o9kjx/HxptvxVlRScFpwdd7UMxNHeG7GJqX\nwfKtVSzf2v1A/MMzxmJLCe8zTbK2vUOtpo1w7bRRAldRQiV9EltODmXPvUDZcy90bhdWK/a8XJy1\ntXEcnaIX01XUevl0RyXHluQxtiin2/aB2alceMJwJP5z1GaspmPZ9lZ6p9reSjQsWZmUXH0Vwmrt\ntn3QgnOQUrLncbXWdyIyVUWtV9sbYGxhf3w11Tz3/aN5ddUB1uxrZFR+JpfPGIZ7z24sJSVhjjZ6\nsaqmQ6EmkfkZpQpXbe/k5GttRUrJlGefpvzNt3A3NjJg1izyTj4Ri93OwLPOpvXJX8d7mIrGTBXU\nespNt1H70RfUfPAh5994A4smDMPb0srB3z6BNTOTYTffFPJrJeK106FQk8h6p6rpxKfn+WkAIQTb\nf/kwGSXF5M+bgzU9g6Z161l76WVMeeZP9DvueF3fX4mPhA3qcKrpguxUmp0e+k89lsLTTqV62cdU\nvv13MkaMYOQdt9Gyew+k2EzZ9la0kwzVtGJs0ucjc9RIqj/8NzXLPu7cbklLIzW/gNrPPo3j6BS9\nmOZIH27bO1yfbq/ivImFbLrtDhrXftW5vWLpUqa+8hJNntBav8k6iSxUekwiU7Sj2t7GZs3OZsT1\n11G/YgWepkMdrOKrr8TncbPnicfiODpFL6YJar2df8xQGjdu6hbSAO37D1C+9B8UfmdBnEYWOTNf\nOx0O1fZWjEDvtjeAu6UVa3YWx7/9JuXvLMVdX0/BvHmkDR0CQjD+j8/y9Q1X6z4OJbZMMR3Yag1v\noe1w294dWnfuDPocx65deN3usMYQDXUDDuNJhrZ3PKtpJTQWi2DLT+9BptgYdM7ZDLvs+6QNH8a+\nN97EWVNL+uAh8R6iogPzHe114pWSvOOmsSvIY/2nn0BKWt8t7UScRKZuwKHEgmp7h0ZKmPjoQ7Ru\n3cq+l1/B3djIwFNPYfiiiyAlherln8R7iNHxutXvaBCmqKj10rWafnvdQewDBjI4sI5uh7yZJ5M3\nYzqtTuMsdm/GajqZqba3ohVrejotW7ex/vobqfvsc5o3bWb37//ANw8/imxvp+zxh+M9REUHCRfU\n4bS9uzp3ymDWHmzFcu4iJr72OsV338PY556n6Kf38O6mKuw2a68/H0o1HYpkn0RmREb5hK/a3sYV\ni/PTAD5HK2WLX/KX1l1U/fs/SJ+Po199OybjUGJLt9JMCDEMeAkoBCTwjJTySSFEHvAaUALsARZK\nKeN+lLAIwb46B9cs2cSxJbmMKBhG1ZoWvvjmM849bhhzJgyK+j2M1PbWimp7905V031Tbe8wCIH0\neBh5+63kz52DNT2dxnXr2bf4JTxNTaTkD4z3CBUd6HlE9wB3SCknANOBG4UQE4C7gI+klKOBjwLf\nayLSSWQAB5vaOGV8IRYBa/fU89aX+/jvtio8Psm8SUWk2Y3RblZt79gySjWtKAAIwbgH7wchWHfl\nNaz41jlUf/hvxj/8S+yFhVS+syTeI1R0oFtQSynLpZRrA183A18DQ4AFwOLA0xYD39FrDOFYsrGC\n1BQL9503mQy7v82dYhVcMauUiUP7sa6i56JfXTvdOyPcgMPsVNtbARA2G41rv2Lnr39L+8GDeFtb\nqXzvX3x9z71Il5uGtaviPURFBzEpz4QQJcAxwEqgUEpZHnioAn9rPKYOr6YBZpYOwPXVak6bcgzz\njppDeYOD/Jw0kJKWz5ZTMmUa/431QCNg5ra3nlTb25hU2zs80unk4OtvAJDSrx/W9HScVVU0rlmL\nt83BqDt/xoaLL4zzKBWt6R7UQogs4C3gVillkxCHromWUkohRNDSTQhxDXANQFpe31ke6SSyLu+H\nq6kJa3MzYkAeuZmp2K0W2lvbaD9wkIwpUb18n9S108ZjlLa3WjJU6SQE9oJCjvrdVWRPGI+3rR3p\n8VD2wotIjweLLbrjoGJMuh75hRA2/CH9Vyllx3TESiFEkZSyXAhRBAQ9GkopnwGeAehXPE67PmwP\nVpXVc/Hs09iwr4EHX/qU8oZ2+qXbuHHuGL514UVsrQpePaprp7WRaJPIzEK1vc1F2GyM+elP2P3H\nP7Ppjh8j3W6yxo9n3AP3YevXjzU3qlXJEpFufVLhL52fA76WUv6my0NLgcsCX18GvKPXGIIJ1vYG\nOHlEHj7g1lfWUN7QDkBjm5uHl26mrM7BhMPuUx1rZqymk5lqe/dNtb0j4PNR8e4/KH/778jAaokt\nX3/Nljt/BkKQVTIizgNU9KDnCc2TgO8Bpwkh1gX+nAU8CswVQnwDzAl8H5Vo294Ao/OzWLalApfH\nd8Rj76zZjyfITTnUJLLeqbZ39FTbW+lKer1Uvf/BEdsdu3bhrqtn9F33xGFUit50K9OklP8Delqk\n+3S93jdSUkqyUoP/78iwW7EafGkYM08iU23v+FBtbxOSEkt68MLEkpaKdBtnBUVFO6bvp0Zz7XRX\nn+yoZubYAgZmp1LT7OzcnppiYdH0ElzeIyvtWFFtb3NRbW9FLyI9naEXL2LLuvXdtufOmI4lNZW1\n558dp5FpQ3o86sN1EAavE2Nn1qiBtLs8PHvVCZw2sZC8LDvTSvP44xXH4/Z6ybJ3X0JUtb17Z+b7\nThvlQJHIbW91fjoyst1J1rixjPn53WSOHoU9fyBFF5zH2Pt+jrDZyF+4KN5DVHSQNEHdWzUNYLNY\n+GhjOU99uJ1LTizhzVtm8qOzxvPBhoO8uHw3TpdxW0pmbnuHwwxtb7NU06rtra2MAbG6LEry9T33\n4m5qZtJvf83U/3uFAbNmsenWO3BVVjJ04SV9v4RiOqbuqWoxiayrwbnpfLS5go82V3Tbfsvc0aRY\ne78pRyTUtdPGY5RqWlGC8kkK5p9B4RnzqPvsc9yNTQyYeRIl11+LrX9/2mur4z1CRQfmSwGdLNta\nwczRhYwqzGZH5aGqMTfTzoXTS/B1mRanrp3WhloytGeJ3PZOVBkD0nW/i5YlK5P8005lzaWX4azw\nFxQ7/9+TjPn53Ugh2HLtlbq+vxIfSdH67qvtDTBleB5uj5fF107n2lNHMq00j4umD+fNW07G6/HS\ndUW1WDFjNW0Uqu2tJCJvq4M9f3q6M6QB8PnY9Zv/hyXFxsBzFsRvcIpuTJsEWre9+6XZWLJ6P1WN\n7Xzv5BIuPrEEASzfVs26vfXcesZYQE0i64tqexufOj+tH72raouApo2bjtjuaW7GWVVJ/unzqFka\n0zWklBgwbVBrrc3tZeqIPHKz7Hz8dRXry+opLcjm28cMIT8nlZQU4zUfzDyJTF07rSQqPcNaSklG\n6Qgcu3d3225JTSU1P5/yJct1eV8lvkwZ1FpdO93Vh1vLOXvSUH740mpW7qzt3P7ml2W8etNJ1Dqc\nvfy09lTb21y0bHur89Pm1zELXOvAtmZlMeKG66hf+SXelpbO7cOvuAyfx8PBxc9r+n6KMag0CDhz\nwmC2HmzqFtIAe2taWbJmP9+ZOlS1vfug2t6K0p3Wge1tbqF1126m/e0VKv7xT9wNjQycPRNbXh4W\nq5WRDz7Ezp/frcl7KcaR0EEdajU9qH8aaSlWtpc3MX5wDotmlDAiP5PKpnbeXrWPHRXNuIOsAR5P\nqu0dnApcxYi0CmxhEez5458RNhsFc+eQMXwY5X9/h5qPP2Hq314ha9RYLYarGIzpglrrSWQdmto9\nnDqhgFMnFPLy/3bz9qoySguyuOvsiTjdXuwp2lxHnajXTiva0LvtrSaSxdfhC6OEG9xSQr+jJ1P+\n93fYvX175/aUnBxSCwup/Oe7moxTMRaVCAHvb6/kvEmDufip/7G7uhWA9WUNLNtcybt3zKa6tb3P\n10jma6eTue2tLstSIhVucItUOyXXXUv9l6tpP3DAv81qZdSd/ntT73/mj7qNNRakx6N+n4JI2KAO\np+0NcMaYQlbvqu0M6Q6NbW5eW1nGxTOKNR9jMIleTau2twKQUdBPrfcdRF9Lkbbt+IbUIUOZ+rdX\naFi1GnddHQNmzQSrFZ/TSWrRYJzlB2M0WiVWTJUKerW9wX+XrIqG4FVzZWM7Pl/v1aeRJpEpipKY\nUrKz2PbALym+8QZyZ0wHIfA6HOz+/VMMueB8MocMwOpSpzcSjfEuDo6ThnYXsycUEGwBsrmTBpEa\nw8lbvTFz29vM7XFFexkF/eI9BNNx7i9j/AP307p5M2sWfZcV87/F7id/T+ktN5M2bBjOg/viPURF\nB8ZInxDoce10R9sboKHNTZrNyt0LJpIWCDqrRXDpSSUcNbw/Lqc7vAFHINHb3uGI1dre6vx0fKmw\nDo8tbwB1X3zBNw89QltZGZ7GRiqWvsuWu36G9HiQztiu96DEhkqGgOH9M9i0t57TJgzirClD2FXV\nwrABGQjgky2VnDK+oMefNVLbO1mvnU6E89PJutCJOl8dOnvhYL75ze+P2N7w5Sp87U6yp06nec2K\nOIxM0ZNpKupQRVJNd6hrdbGrqgWLRTCqMJt0u5XKxnb2Vrfg7eMcdSyY+dppxRjSC3LjPYSgVGUd\nIiHw9VA1+9wuhM0e4wEpsWCKitpm1T+g1h9sZNaEQr4+0MgFT/6X/XUOcjPt3HLGWL43sxSHW98F\nTxK97a1uaan0pSOsVXXdM1dVOQXzz6Bl67Zu2zNHj8LWrx9Na1U1nYgSrqKOVLXDBcDNi1ezv84B\nQH2ri/vf3siB+jZqWoN/ik3mtrdRRNr2ToR2eSJS1XXPKl5+hqLvLGDIoouwpPq7hzlTJjPpN0/Q\nuPpzcLniPEJFDwlVxkXT9p5YmM2yzZU4gywVumT1Pi6fPTLq8UXDiG1vo5yfjhezTiRLL8g1/Apl\nXcNaVdiHtO3aTtnvHmHo5Tcw4sbr8Xk84PPRuGI55S/8Id7DU3SSUEEdDa+Pztneh0uzWYm0DlVL\nhqpAD1X6gH4xm1BmhrDuoEL7MF4vTmGltr4Vh8vDkAFZONvaQVhARn6KTnUyjCuxEyIMaw40cOFR\ng8nLslPXcqh9ZLNaWDi9mLLGI5f2i9WSoaFIlLa3Oj+t9CZYmCRTeKcOKyb/5p/xozc2s2JHDQB5\nWXZ+t+gk8i7wUPfGYkCFbqJJmKCOpu0NUN3q4mBjGy9ddyKPvbuF9WX1lBZkcev8cdhSLGw7bGnR\nWIpl2ztUqko2PzNV1b3pK5TMFuS97U/OuZfwwmdlnSENUNfi4kdvbGbJzWfj/OJfSJd5r6X2eb1J\ne5libxImqLWw5OtKTi0dyC8vnEy63YrT7aOuzcUH26sjej0ztr3NdllWPCeE2QfkaX6eOpbtbzh0\nuVYiBHZPEqm6TCkezfKV2xmSm85Vp4wiKy2FDzeW8+9NFVTVt2IrHIxr3+54D1PRmLFSIs76paVQ\nkmFBVFVQ9dVa0keNpqC0lAGZdqpbu8+mNFvbO15U5W0OiVJdJzpfu4M7zhzL0SUD+PKbKupaXNy9\nYCK3zx9LRgo0tjk0ey+jXnOfjBIiqKNte3c4b3QeNc89R/nrr3duy51+Aqc+8jBLvqnH5dX3Wupg\ntGp7m+H8tOIX66q6832ToLo2uzS3g3GDh3Su9QCQsnQLjyyczIkjB+CpqezzNVQAm49xS7EYK+6f\njqir7RbSAPUrVlL32eeMzAvvzl2J3PbWq0pWE8kOSR8Qv3ZtekFu5x/FWHyDSvj9h1s7QxrA45M8\n+M4WrHYbWZOndPv7C/Yn2Qkh5gshtgkhdggh7gry+O1CiC1CiA1CiI+EEMVdHvMKIdYF/iyN1Zh1\nSwohxPPAt4EqKeWkwLY84DWgBNgDLJRSRvXxPdRqui95GXaav1oZ9LHm1avpP/Hozu+N1PZW4kuP\n89Qd4lVZdxtDlwO7qrRjp8dATbGxbm8D4wfncNakQjLtFr4sa+KjzZVUNTjILZ1IS0WZduOI4wdG\nPQghrMAfgLnAfmCVEGKplHJLl6d9BUyTUjqEENcDjwMXBR5rk1IeTYzpWdK9CDwFvNRl213AR1LK\nRwOfZO4C7tRxDJ36anu3uDxkjB4V9LGM0aOp9cW++RDLW1oqxmSEsO4QLDxUePdNyypWer3cPnck\nkwvTqVmyBG9jIyeeNoebZh/PgJx0HOV7QhtTggVwGI4HdkgpdwEIIV4FFgCdQS2l/LjL81cAl8Z0\nhEHoFtRSyuVCiJLDNi8ATgl8vRj4hBgFdV/21jk4a+po+h9/HA1frurcnj58OEXfOpONe0OfDW3G\ntrcekmUimZ5VNRgrrA/XWwglSogbqV2c2lLNMf0sfLXwIrytgUtGX3+D4dddi/WC87E2HdQ9hO0D\n8nR9fZ0NAbretHs/cEIvz78S+FeX79OEEKsBD/ColHKJ9kM8UqzTolBKWR74ugIojObFtGp7AxTn\nZtByoJxxD/yCus8+p2nDRjJGlFB41pk0bNhE0ZBR1Dhcqu2dQKy5BZpd3hWLsAZz3QrTSAFndh1/\n/z5HK3v+8tdDIR2w/4UXGbrwfERGDtLRFNF7mDyAuxoYCNMOz0gpnwn3RYQQlwLTgNldNhdLKQ8I\nIUqBZUKIjVLKnVGOt09xK+uklFII0WNPVghxDXANQObAQVG9V19tb4Cs1BSa16+jrqqaIYsWknfy\nSQig9rPPaVq/gazLSqMag9HFeyJZpLQM22jpHdbQvWVpptBWjhRJ5WvJ7Idj15HXSfucTlwVFVgy\nsvEGCeoECuFQ1Egpp/Xw2AFgWJfvhwa2dSOEmAPcDcyWUnauICOlPBD47y4hxCfAMUDCBXWlEKJI\nSlkuhCgCejzCY6+odgAAFrtJREFUBj4BPQMwsHSC7idZfVJSMHcOFouFfS+/QtP6DWSMGEHxlVeQ\nO2M6G5u1G0IobW+tzk8rvdM66GMR1h1UaBtLLM77+prryDlqEo7d3cM6JTub1MFDcG4Ba5ShbM0t\niOrnDW4VMFoIMQJ/QC8CLun6BCHEMcDTwHwpZVWX7bmAQ0rpFEIMBE7CP9FMd7EO6qXAZcCjgf++\nE+P371G7y4vVbuerK67EsXMXAI1rv6Jm2cdMe+NVMu3SULe0DJWZJpJZcvLicomWHmENsb27VrCQ\nUOEduXhPtuqpArYNKab4+uuoX7UKZ3mFf6PVSsmP7sDj9YHryHsSdNAqgM0c5FJKjxDiJuADwAo8\nL6XcLIR4AFgtpVwK/ArIAt4QQgCUSSnPAcYDTwshfPgvbX70sNniutHz8qy/4Z84NlAIsR+4D39A\nvy6EuBLYCyyM9PW1WuSkw0kj8mhcu7YzpDu46+spf+ttShcuZGd9z78EypF86f1i0irXImj1aKHH\nI7C76ilskiXA4x22h9Oi/ezw2fjX1mrO/utfqVmxEl99HbkzZ7Gtzkm21Y79qFmwf2vErx/vEPa5\nvbpPQpRSvge8d9i2e7t8PaeHn/scOErXwfVAz1nfF/fw0Ol6vWc07FYLDR2fUA/jrKhEeDwxHpES\nDqOGNcQ/sA8XTYBpGfJGC9JI6H3u9/Dg9FosfLy1hvFFOYw/eQbCYqGhuY2lmw4wKL8fRRn98Ib4\nWuGy5CTVeW5DSfxrhEKQn5lKeZOToTNPYsfjAmT3dvHAU2bTlpIKaLeOrlnpXSVH0/7WKqxBn5t9\ndD2oGyW0w5UI4dqXWEy8ijQ0rT4vT140idrly1l39yt4GpsYMHsW9910AzI1FbZXRfTaKoSNzZRB\nrXXbG+DrqmaKh2cx8vbb2PX7p5AuF1gsFJ13LjlTJvNNU3ufr6HV9dNGvK2lWWhVFes9mzxYGJg1\nvI0s1rOdtW4dH/56VjzUrlzDN794oHNb+Vtv037gAOMefgjaj7wdb7Qh7EtP/A9nRmfKoNbDhMJs\n1hxsYcoZ8yj81pm0frOD9OHDEXYb/9lez9TSXHbUqXPU4YqkAo92UpmWYd0hFpeA9RQqyR7g8b60\nSI/ztpG+ps8rKX/ttSO2169Yic/Zjm1QKTgaQn89FcKmoII6wGoRVDU6eb6skUtPLCZt4iS80sfS\ntQc5UO9g6ojEXrzBl5qt272ozRzWXV+vQ6yv2w43qOIZ7PEO1VDoOWFKq9fuqQqWQuBrC14w+Jwu\nEIe6cdGGsApx40j6oM7P9LfRd9a2csqkIjYfaOT7T69gT3UrBTmp3Dh3LFfMLKXWqSaTdYjVbG4t\nwhq0D9Z4hnYozBCWWtJ7prLWrx9VK1r4GHjGGbRs295tc0ZpKfbc/vjqGiGEgFUhbC6mC2otlw3t\nqsnpRQi49eU1tLv98yarmpz84u0NvHnLTBpcPc2lNDaHV+hyLXW4YR1puHcc1LQIbNA3tLsyYoAb\nXSwvDdLjvbSYkNVXgAphYcj55+I8eICKpf9AulxkTxjPuEcewgdIDQLYl5od9Wso2jJdUIcqnIlk\nAINzUlm2pZJ2t5dxRdkcU5LHzsoWvtxVy1ur9nHeCcOpaHH2/UImpmf7G6KrxLVaDCVW1XAoQZAo\nYR7va287GDV8QZsK1pfeD+GDvc8+w9DLLqP0lpvxuVwIi4Xqjz8hd9pUrFmpSHfw45QWAezwiqhf\nQwlfwgZ1uHwSslNT+NcPZ1CQk07Lvn1knDIBh0fy/td1yBj++3S4fZrO/DZKVd3xMxDZmuFdD5pa\nhzbEPjiNEnBGpOf/Gy0vRdIqgEMmJdLtot3ppqmxjdZ2N4PyMnFU1ZCXkoJMScNnsUc0DhXCxqWC\nOuBAYztnl+ZQ8/GnfPHEr/G1tSGsVgZfcgnnX3k5a2uMN+O7xe3TfL3vcKvqSKvkaM9za9ESP1yw\ncEiUqjceYvlBROvrgLU6h6tJkHephK3WFAbfdAt3vr6e/26rBqAgJ5UnF30LmZmF9AU/RadVCLe4\nfZq8jhIeFdQBg7LtyHYnOx56GHz+f4zS6+XAyy+Te+J0Bo0YS1WLO86jjFw4VXUkYQ3hV8nRVNcd\nDj9Aa71WeDK1sLuKd7WvxwIcRgpfiKwV7fLB4s/2dIY0+OfS3P76Bv5+22wc7ZEHqQph4zJVUOs1\nkQxgaL90aj79T2dId1X77/+Qf+0oTd6nod0T0qInoba/w6mq9QxriK667hDtbHK9gzuYeIeakem9\n4pWWs5fjGcDBBKuCU1IEH2+pPGJ7eUM71U3t5KRZ8Pq6/46bKYB9Hg+OquRYiz4cpgpqPbm8PjIL\n8oM+Zhs4EK/FGuMRxV/HAScW1fXhPx/Na3TVW1DE405dZhSr5SX1uGRI0yDXMYBDJSUMyErlG7r/\nTloE5KTbaHW58fiim4/iMFGwJwsV1AEbK5pYMPVY0ocPp62srHN7SnY2Qy44j13tfV+eVeNwh7SM\naLyragjv9peRVtcdtAjtaF6nJ+EEkFlC3ShrNut1na7Wr2uE8A2mpyo40+LjqlNGsnJnTbdbEsyf\nPBig15BWAWxeKqgDThiWS327j3FP/5mKxYtpXr+BzBElFFzxAw60+hiSl8k3tca9KUe4E8vCnQke\nSXXd+bMaVck9HaRjtfhKsonFohi6VNEaXgccqwAOVavTw6hBWTx/9XReWL6LhlYXc48q4vzjhlHZ\n0o7To18YN7SrRZ/iRQV1QG66jX+sPcDStfv5/sxzGHXuIiqbXTz1cTkFOanccsbYkF4nXlU1HDoI\n6F1dd4g2tEGbkA3lYB+LMDeKeK06pVsVrfECHEYL3570VAG3uZ2MHpTNrxYdjc/nw5piZV+9A3eE\nLW8VwMaX9EFd3eokPzOVNreP0UXZbNrfyE/2dz+o33n2BKxW7a8xDCesIfS7akVSXUN4gQ3RhzYE\nP7jrEapqycTQxKSK1mHlK7OHbziG56Th9kn+tnIvda1uzppcxPD8TOodLpoDKyiq8E0spgrqqmZn\nyDO/Kxraw1qd7IuyKuaMKmLaiDxW7z50PnJYXgYLpg6lurmd+jY3uel9V8uhVtUQeliDvtU1dD/Y\nRRPaEHlwg6qQIxXrDyN6LjWpx+Ibes5+jtX53+LcDOpanCx66jOaA2H80v92c9sZYzj/uGHsa0rs\n1ROTlamCWi/VrU7OGT+c8vo2Hr/kGD7eXMm6vfWUFmSxYNpQNu1r5Khh4R0E9QxrCK+6hvACG6IL\nbej5IK7VEqVahFIswt7olXws1nXWa8WrRAheCK/6HeL28LsPt3eGdIc/LdvJwhklDMy0UdMa2XoP\nNQ7zrhOR6BI6qMOpqtNtFlbtquXpZd/wnanDOH7kAKqanFz+5xUcV5rHuMH+A1qoVTXoF9YQeWBD\ndKENkQV3h76CQc+1xg9n9BDtS6xvnqD3EpN6X+8bq/DVs+0sLBZ2VBz5O9Lu9lLd2EZuhr1bUKvw\nTQymC+pw2t/haGhzc+yIPGpbXDz36c5uj11z2khs1kPhFm5YAyFPMAN0DWw48oAYbXB30GI98WjD\nJ5ZB3xMj330oVus5J0rodjDKOV8pJZOG9WdnVUu37dlpKRT0z2BTRaMK5wRkuqAOV6hV9buby7n4\nmGEsmDqUd9bs79w+dUQecyYVsbO2+y9GOGEN4VfXHcJtiUN4oQ3RB3fnGEIIAT1uDtKVkUMyGvG4\nYUKsVrRK1tCF8Cve9NQUbpk3hhU7aqhsbAf8i5385KxxeN0eKky8zLHSM1MGdbhVdShhPa04D+/B\nfdz57QlcPKOYFTtqGTc4h6OLc3Hv2kl+4ZAjfqa+zf9LoUd13SGaKrtDtMHdQYsbgEQbOHoHfTiM\nfrehWC8dGY8FNcwcupFodXpxtLt55/bZfLq5nJoWF/OOKiLNZsFnsVDcP529DfrdQKjjmKfElimD\nGrQP6wyblcYv1mPfvZdRJ81gTGEx0uuleft2qt9dyoBrb+jxZyMNbAg9tA8/IEUT3BB+eEPoB36t\n7+jVldHDMVrxXpc5XqtXGSlwwbjndi1C8LM3N7LwuCGccVQRFouF/TXN3PTmZh6/+BiyU0Nb6tio\ngevzSBy1xrtTYbyZNqhB27De29DGrDPPwNfcwvb7H6Rp40YyR4yg+KYbGH7TTexv77uSCzewIbIq\nG6ILbuj9gBztvbC1Chs9Az8U8Q7NcMV7iUgVtvqTSH574UTa16xi0zW/wN3YSN7s2Tx/5ZXYMtL4\nYHu14f4elOiZOqhBu7AWUmIVFtb+4Epc1TUAuKqqaVy3nmlvvU6/jJyQ36Prp9VIqmyIPrgh/PDu\nEOoBP9pA74vZgjIc8Q7VYIx4gE/EsO0QSVWbZhW4tmxg1733dm4rf/U1nPv2MfbB+w35d6hEz/RB\nDZGFNdAtsE8eMYCa//6vM6Q7+JxOyt96m8GXXUZ1q38xgfzM0N8rktCG4AcoLcK7q0iDvIPeYaPH\nBwEjBmQ0jH5gTsSgjWvb2NnOgb/+DQBhs2Gx2fA6HNR99jnS5WLyoCw2VLT08SKK2SREUIM/rCG8\ne1Z3DWyLEHhb/P/AhdWKLTcXT3MTPqcLb3NLt/tUdwQ2RB7aEF5wQ88HvXADvEM4B/loQz0SiRKq\nRg/TYFTAGpXAkpnByMd/ReGJJwDQXF7FwT8+hbetHXtKVpzHp+ghYYK6Q6SBvaW8mQmzZ9FeW0fh\nud/BKwU2m5Wq/3xE/3Fj8NjsQX820tCG4AeOcMMb+j6oRhrkXZkxbJJFIoYqJEqwaktarYx66CF8\nFiv/21FLQ6uLmeMKGHrPvdhsFjZtq4r3EBUdJFxQdwg3sFeU1TPqmCLqZ87nh8+uYV+dg7wsO7fO\nncyc4kFsKW/q8zW6hjaEH9zQ+8EpkhCHyA7kWoR7MkvU8AxGBWoMpdhoc3m54k+fsbemFQCb1cJD\nF07mpDH5eNXn6YRkiqB2e32UN7RR1D897J/tCGzoPbTnjBmIDws3vrSG9kDLta7Fxb1/38TYof0Z\nXZDN8rL6sN778ODuEEmAQ2gHxEjD/HDJFDSJTIVoYnF6JX/66JvOkAb/8fHhpZt5/87TmDlyAMt2\n1sZxhIoe4hLUQoj5wJOAFfiLlPLRUH6uvMuF/FqHdl6GnWVbKjtDuqslq/dx3emjO89pdxXOHbo6\n9BTgEHmId4jmwKxVyCvdqbBUtCKAtV3u7tehweGmsrGdnHRT1F5KmGL+tyqEsAJ/AOYC+4FVQoil\nUsot4byOlqHd8X1aD7OM02xW3N7g11EHC2+ILMCh9xA/XLShfjgVKIqRhPO7kCwkUJyfecRa3/YU\nC/nZqaw92KD+vyWgeHz8Oh7YIaXcBSCEeBVYAIQV1F1FG9oAf127n5+ePobcTDv1ra7O7TarhYXT\ni/li75GfYnvTU4B3iDTIu9LiF1LrsFdiSx2Uk0uKRXDT3LF8vr2Gdre3c/tlM0fg9vrY19j7cUcx\np3gE9RBgX5fv9wMnaPXi5YetcxtqcJfVt7GztoWXr5/BY+9u6bwf9a1njgMBb20oB8KbTd6bWAR5\nKNSBXlHMY3e9A4vXx5LbZvHair3Ut7qYP2UwpflZ2FMsVHcpMpTEIaSM7U0OhBAXAPOllFcFvv8e\ncIKU8qbDnncNcE3g27HAtpgO1G8gUNPnsxJDMu0rJNf+JtO+QnLtb7z2tVhKma/1iwoh3se/T9Go\nkVLO12I8RhGPivoAMKzL90MD27qRUj4DPBOrQQUjhFgtpZwWzzHESjLtKyTX/ibTvkJy7W+i7Wui\nBaxW4nHXg1XAaCHECCGEHVgELI3DOBRFURTF8GJeUUspPUKIm4AP8F+e9byUcnOsx6EoiqIoZhCX\ni+6klO8B78XjvcMU19Z7jCXTvkJy7W8y7Ssk1/4m074mrZhPJlMURVEUJXTxOEetKIqiKEqIkj6o\nhRDzhRDbhBA7hBB3BXk8VQjxWuDxlUKIktiPUjsh7O/tQogtQogNQoiPhBDF8RinFvra1y7PO18I\nIYUQpp49G8r+CiEWBv5+Nwsh/i/WY9RKCP+OhwshPhZCfBX4t3xWPMapBSHE80KIKiHEph4eF0KI\n3wX+X2wQQhwb6zEqOpNSJu0f/JPZdgKlgB1YD0w47Dk3AH8OfL0IeC3e49Z5f08FMgJfX2/W/Q1l\nXwPPywaWAyuAafEet85/t6OBr4DcwPcF8R63jvv6DHB94OsJwJ54jzuK/Z0FHAts6uHxs4B/4V8K\nfDqwMt5jVn+0/ZPsFXXncqZSShfQsZxpVwuAxYGv3wROF0KIGI5RS33ur5TyYymlI/DtCvzXuZtR\nKH+3AA8CjwFmX3sxlP29GviDlLIeQEpp1psXh7KvEsgJfN0POBjD8WlKSrkc6G0N4wXAS9JvBdBf\nCFEUm9EpsZDsQR1sOdMhPT1HSukBGoEBMRmd9kLZ366uxP9J3Yz63NdAi3CYlPKfsRyYTkL5ux0D\njBFCfCaEWBG4i50ZhbKvvwAuFULsx3+Fyc2xGVpchPt7rZiMuieaEpQQ4lJgGjA73mPRgxDCAvwG\nuDzOQ4mlFPzt71Pwd0qWCyGOklI2xHVU+rgYeFFK+WshxAzgZSHEJCnlkfexVRSDS/aKOpTlTDuf\nI4RIwd9GM+ud2UNavlUIMQe4GzhHSmnWu3b0ta/ZwCTgEyHEHvzn9paaeEJZKH+3+4GlUkq3lHI3\nsB1/cJtNKPt6JfA6gJTyCyCN6NeQNqqQfq8V80r2oA5lOdOlwGWBry8AlkkpzXrxeZ/7K4Q4Bnga\nf0ib9Rwm9LGvUspGKeVAKWWJlLIE//n4c6SUq+Mz3KiF8m95Cf5qGiHEQPyt8F2xHKRGQtnXMuB0\nACHEePxBXR3TUcbOUuD7gdnf04FGKWV5vAelaCepW9+yh+VMhRAPAKullEuB5/C3zXbgn9CxKH4j\njk6I+/srIAt4IzBnrkxKeU7cBh2hEPc1YYS4vx8A84QQWwAv8GMppem6QyHu6x3As0KI2/BPLLvc\nrB+whRB/w/8Ba2DgnPt9gA1ASvln/OfgzwJ2AA7giviMVNGLWplMURRFUQws2VvfiqIoimJoKqgV\nRVEUxcBUUCuKoiiKgamgVhRFURQDU0GtKIqiKAamglpRQiCE+DyG79USq/dSFMX41OVZimIwQogW\nKWVWvMehKIoxqIpaUULQUeUKIYqEEMuFEOuEEJuEEDODPHePEOKRwHNWCyGOFUJ8IITYKYS4LvCc\nrMD9vtcKITYKIYLd2QshxI+FEKsC9xm+X9+9VBTFiJJ6ZTJFicAlwAdSyoeEEFYgo4fnlUkpjxZC\n/BZ4ETgJ/zKWm4A/47+t5rlSyqbAcp4rhBBLu66eJYSYh38t7uPx32t4qRBiVuC2h4qiJAkV1IoS\nnlXA80IIG7BESrmuh+d1LFG6EciSUjYDzUIIpxCiP9AKPCyEmAX48N+WsBCo6PIa8wJ/vgp8n4U/\nuFVQK0oSUa1vRQlDoJqdhf/uRC8KIb7fw1M77jrm6/J1x/cpwHeBfGCqlPJooBJ/xd2VAB6RUh4d\n+DNKSvmcRruiKIpJqKBWlDAIIYqBSinls8BfgGMjfKl+QJWU0i2EOBUoDvKcD4AfCCGyAu89RAhR\nEOH7KYpiUqr1rSjhOQX4sRDCDbQAPVXUffkr8K4QYiOwGth6+BOklB8GbtH4ReBOZi3ApYCZbz+q\nKEqY1OVZiqIoimJgqvWtKIqiKAamglpRFEVRDEwFtaIoiqIYmApqRVEURTEwFdSKoiiKYmAqqBVF\nURTFwFRQK4qiKIqBqaBWFEVRFAP7/wWAWfnNxIUKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsGlCr6EyWUE",
        "colab_type": "text"
      },
      "source": [
        "The next code block visualizes the hidden layer activations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg-tANIOwwWW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "c97c76c2-2e88-43b1-a34a-6e0e771c6154"
      },
      "source": [
        "f = plt.figure(figsize=(12, 5))\n",
        "xx, yy = np.mgrid[-.1:1.1:.01, 0:85:.1]\n",
        "grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "hidden_units = mlp_pytorch.hidden(Variable(torch.Tensor(grid))).detach().numpy()\n",
        "for i in range(2):\n",
        "    ax = f.add_subplot(1,2,i+1)\n",
        "    contour = ax.contourf(xx, yy, hidden_units[:,i].reshape(xx.shape), 25, cmap=\"RdBu\",\n",
        "                        vmin=0, vmax=1)\n",
        "\n",
        "    ax.scatter(experiment_1_data['male'], experiment_1_data['Age'], c=experiment_1_outputs, s=50,\n",
        "            cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
        "            edgecolor=\"white\", linewidth=1)\n",
        "    ax_c = f.colorbar(contour)\n",
        "    ax_c.set_label(\"learned feature %d\" %(i+1))\n",
        "    ax_c.set_ticks([0, .25, .5, .75, 1])\n",
        "\n",
        "    ax.set(xlim=(-.1, 1.1),\n",
        "        ylim=(0, 85),\n",
        "        xlabel=\"is male\", ylabel=\"age (years)\")\n",
        "plt.show()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtgAAAFBCAYAAABNUtgTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x360 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3HTkn73xCMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}