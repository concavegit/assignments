{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlfa19/assignments/blob/master/Module%201/m1_project/Examples/Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qb7zZas2f1u",
        "colab_type": "text"
      },
      "source": [
        "# Transfer Learning with Pytorch\n",
        "\n",
	"This notebook is also available for comment [on NB](http://nb.mit.edu/f/55895).\n",
        "\n",
        "These have been adapted from [Transfer Learning for Computer Vision Tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html).\n",
        "\n",
        "In this notebook we'll be using the Caltech 256 dataset (which we've used for a bunch of the examples in this module) to show how we can adapt a pretrained model to a new dataset.\n",
        "\n",
        "All of the pretrained models were trained on the [ImageNet](https://en.wikipedia.org/wiki/ImageNet) dataset.  Specifically, these networks were trained to recognize 1,000 different object classes.\n",
        "\n",
        "[Transfer learning](https://en.wikipedia.org/wiki/Transfer_learning) is a branch of machine learning that focuses on using knowledged acquired from one learning problem and applying it to another.  In the case of a neural network, what we'll wind up doing is modifying the network trained on ImageNet so that it can be used on the Caltech data.  Specifically, we'll be chopping off the last layer of the pretrained network and replacing it with a linear layer that produces the 257 numbers (there are 256 object classes in Caltech 256 and a \"clutter\" category) necessary for prediction in the Caltech 256 dataset.\n",
        "\n",
        "Once we've modified our network, we can train it on the Caltech 256 Dataset.  The important caveat here is that we are going to freeze the weights for all but our newly added final layer.  This will allow the network to fairly rapidly converge to a decent solution.  You can also modify the code so that all weights in the network are trained and compare the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1682SEiMB6gU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# standard importants for pytorch and torchvision\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "supSJdvQCjlM",
        "colab_type": "code",
        "outputId": "7df3d659-1741-405c-b7f0-4a3d746f045a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "# We have created a precropped, resized version of Caltech 256\n",
        "# The images are 224 by 224, which is a standard input size for models trained\n",
        "# on ImageNet\n",
        "import gdown\n",
        "gdown.download('https://drive.google.com/uc?authuser=0&id=1ysiTEWE0ZAYPycw-Nt7zhd-pPKyUYSE1&export=download',\n",
        "               'caltech_224_224.hdf5',\n",
        "               quiet=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?authuser=0&id=1ysiTEWE0ZAYPycw-Nt7zhd-pPKyUYSE1&export=download\n",
            "To: /content/caltech_224_224.hdf5\n",
            "4.61GB [01:01, 74.4MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'caltech_224_224.hdf5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0KFhYJMFlFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "import PIL\n",
        "\n",
        "# This is the class that we gave for wrapping an hdf5 file.  It is much faster\n",
        "# than loading the images from JPGs every time.\n",
        "class H5Dataset(Dataset):\n",
        "    def __init__(self, h5_path, augment_data=False):\n",
        "        super(H5Dataset, self).__init__()\n",
        "        self.h5_file = h5py.File(h5_path, 'r', libver='latest', swmr=True)\n",
        "        self.augment_data = augment_data\n",
        "        # data augmentation is when you apply random transformations to your\n",
        "        # training data in order to increase the generalizability of the learned\n",
        "        # model and avoid overfitting\n",
        "\n",
        "        # these are the transformations to apply if we are augmenting data\n",
        "        self.augmentation_transformations = transforms.Compose([transforms.ToPILImage(),\n",
        "                                                                transforms.ColorJitter(hue=.05, saturation=.05),\n",
        "                                                                transforms.RandomHorizontalFlip(),\n",
        "                                                                transforms.RandomRotation(20, resample=PIL.Image.BILINEAR),\n",
        "                                                                transforms.ToTensor(),\n",
        "                                                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]) # maybe try with no normalization\n",
        "        # these are the transformations to apply if we are not augmenting data\n",
        "        self.normal_transformations = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        self.target_cache = []\n",
        "        for i in range(len(self)):\n",
        "            self.target_cache.append(self.h5_file['targets'][i])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.augment_data:\n",
        "            return self.augmentation_transformations(self.h5_file['data'][index]), self.target_cache[index]\n",
        "        else:\n",
        "            return self.normal_transformations(self.h5_file['data'][index]), self.target_cache[index]\n",
        "\n",
        "    def set_augmentation(self, augment_data):\n",
        "        self.augment_data = augment_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.h5_file['data'])\n",
        "\n",
        "    def close_dataset(self):\n",
        "        self.h5_file.close()\n",
        "\n",
        "cal_tech = H5Dataset('caltech_224_224.hdf5', True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyk9Ifw8gPE0",
        "colab_type": "code",
        "outputId": "25d9bfe0-cd01-4c19-9446-bce5a2075aed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "im, target = cal_tech[500]\n",
        "\n",
        "plt.imshow(im.transpose(0,1).transpose(1,2))\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NDiUXGOB_eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"densenet\"\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 257\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 32\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 15\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HxupeHmCHqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "        batch_num = 0\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "                # TODO: access this through dataloader somehow\n",
        "                cal_tech.set_augmentation(True)\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                cal_tech.set_augmentation(False)\n",
        "\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                #print(phase, \"processing batch\", batch_num)\n",
        "                batch_num += 1\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].sampler)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].sampler)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZMl5VG2COmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this function freezes the weights of the network, unless we are not in\n",
        "# feature extracting mode.  The last layer (the one we will train) is added\n",
        "# after this function is called (so its weights will not be frozen)\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s03SO4cCQXA",
        "colab_type": "code",
        "outputId": "f9a2c905-4ff2-4fe1-8133-56fb6cab240b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # try a more complex final layer by uncommenting the following line\n",
        "        # I (Paul) didn't adapt this to other network types, but you could\n",
        "        #model_ft.fc = nn.Sequential(\n",
        "        #        nn.Linear(num_ftrs, 512),\n",
        "        #        nn.ReLU(),\n",
        "        #        nn.Dropout(0.4),\n",
        "        #        nn.Linear(512, 257)\n",
        "        #)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DenseNet(\n",
            "  (features): Sequential(\n",
            "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu0): ReLU(inplace=True)\n",
            "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (denseblock1): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition1): _Transition(\n",
            "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock2): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition2): _Transition(\n",
            "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock3): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer17): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer18): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer19): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer20): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer21): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer22): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer23): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer24): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition3): _Transition(\n",
            "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock4): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (classifier): Linear(in_features=1024, out_features=257, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19E8Ux3lCbaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# do stratified sampling\n",
        "splitter = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "# trick sklearn to letting us do this without X values by passing None for the inputs\n",
        "splitter.get_n_splits([None]*len(cal_tech), cal_tech.target_cache)\n",
        "train_idx, test_idx = next(splitter.split([None]*len(cal_tech), cal_tech.target_cache))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# Get our data into the mini batch size that we defined\n",
        "train_loader = torch.utils.data.DataLoader(cal_tech, batch_size=batch_size,\n",
        "                                        sampler=train_sampler, num_workers=2)\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(cal_tech, batch_size=batch_size,\n",
        "                                        sampler=test_sampler, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRMPh-0hektg",
        "colab_type": "code",
        "outputId": "6bf8f224-7b59-43ad-b194-d397224f7572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "device = 'cuda'\n",
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "optimizer_ft = optim.Adam(params_to_update, lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t classifier.weight\n",
            "\t classifier.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zQNb9pwfJPU",
        "colab_type": "code",
        "outputId": "2d8d9390-6110-4914-cc96-17f65fc510bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        }
      },
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "dataloaders_dict = {'train': train_loader, 'val': test_loader}\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=500, is_inception=(model_name==\"inception\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/499\n",
            "----------\n",
            "train Loss: 2.2521 Acc: 0.5635\n",
            "val Loss: 1.0137 Acc: 0.7698\n",
            "\n",
            "Epoch 1/499\n",
            "----------\n",
            "train Loss: 0.9989 Acc: 0.7737\n",
            "val Loss: 0.8713 Acc: 0.7874\n",
            "\n",
            "Epoch 2/499\n",
            "----------\n",
            "train Loss: 0.8039 Acc: 0.8071\n",
            "val Loss: 0.8339 Acc: 0.8079\n",
            "\n",
            "Epoch 3/499\n",
            "----------\n",
            "train Loss: 0.6999 Acc: 0.8266\n",
            "val Loss: 0.7836 Acc: 0.8025\n",
            "\n",
            "Epoch 4/499\n",
            "----------\n",
            "train Loss: 0.6433 Acc: 0.8406\n",
            "val Loss: 0.8242 Acc: 0.8085\n",
            "\n",
            "Epoch 5/499\n",
            "----------\n",
            "train Loss: 0.5926 Acc: 0.8501\n",
            "val Loss: 0.8279 Acc: 0.7984\n",
            "\n",
            "Epoch 6/499\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-505eeed1ba40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"inception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-52-a2dc453100f9>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, num_epochs, is_inception)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6W5iJY-dnKZl"
      },
      "source": [
        "A thorough examination of doing transfer learning with [big convolutional neural network architectures on CalTech 256](https://github.com/TropComplique/image-classification-caltech-256).  This shows the results of a bunch of experiments.  The methods are a bit fancier than what we are doing here.  For instance, some of the layers farther down in the network are trained while some are held fixed."
      ]
    }
  ]
}
