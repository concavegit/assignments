{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "How to (Re)train Your ConvNet?.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlfa19/assignments/blob/master/Module%201/m1_project/Examples/How_to_(Re)train_Your_ConvNet%3F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDsFkbVlupVu",
        "colab_type": "text"
      },
      "source": [
        "# How to (Re)train Your ConvNet?\n",
        "\n",
        "If you haven't already, hopefully sometime soon you will get to the point where you are able to train a ConvNet on your particular dataset.  At this point, you need to ask yourself what you should do next.\n",
        "\n",
        "Before getting into the *how*, let's break down the *should*.\n",
        "\n",
        "Characteristics of a good experiment:\n",
        "* Contribute to your learning goals\n",
        "* Contribute to understanding your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeySWVHr45Yo",
        "colab_type": "text"
      },
      "source": [
        "## Modify the Structure of the Network\n",
        "\n",
        "One of the most logical things to do once you've trained version 1 of your ConvNet is to try modifying the structure of the network in some way.  At first you may manually tweak some aspects of the network and see what the result is.  Eventually, we advise you to actually do an automated experiment where you search over some space of network architectures (e.g., try various numbers of convolutional filters at a particular layer)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b58oqUtlx8mA",
        "colab_type": "text"
      },
      "source": [
        "## Make it Faster\n",
        "\n",
        "When running a bunch of experiments, it will be helpful to try to optimize the speed of model training.  It turns out that for the Colab VMs if you are using a relatively small network, a lot of processing time gets spent loading and transforming the data.  There are a couple of things you can do to speed this up.\n",
        "\n",
        "### Cache Your Data in Memory\n",
        "\n",
        "If your preprocessed data is small enough to fit into memory, you can simply memoize the `__get_item__` function to avoid loading and processing the same data from disk (e.g., on each epoch).\n",
        "\n",
        "Here is some code we wrote to do this for the `ImageFolder` class that we showed last time.  We have found that this results in about a 4-5x speedup when training on a relatively small network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXtf-4DL2D9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# Datasets must always subclass either Dataset (either directly or indirectly)\n",
        "# Here, we use subclass the ImageFolder class.\n",
        "class CachedDataset(ImageFolder):\n",
        "    def __init__(self, root, move_to_GPU=False, transform=None, target_transform=None):\n",
        "        \"\"\" The init method passes most arguments up to the `ImageFolder` class.\n",
        "\n",
        "            The exception is the `move_to_GPU` input, which if set to true will\n",
        "            move the returned data to CUDA and if false, will keep it on the CPU\n",
        "        \"\"\"\n",
        "        # make sure to call the super class init method\n",
        "        super(CachedDataset, self).__init__(root,\n",
        "                                            transform=transform,\n",
        "                                            target_transform=target_transform)\n",
        "        self.total_time_loading = 0\n",
        "        self.move_to_GPU = move_to_GPU\n",
        "        # we'll cache the loaded tensors here\n",
        "        self.tensor_cache = {}\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        t_start = time.time()\n",
        "        if int(index) in self.tensor_cache:\n",
        "            self.total_time_loading += time.time() - t_start\n",
        "            return self.tensor_cache[int(index)]\n",
        "\n",
        "        inputs, target = super(CachedDataset, self).__getitem__(index)\n",
        "        if self.move_to_GPU:\n",
        "            self.tensor_cache[int(index)] = inputs.to('cuda'), target\n",
        "        else:\n",
        "            self.tensor_cache[int(index)] = inputs, target\n",
        "        self.total_time_loading += time.time() - t_start\n",
        "        return self.tensor_cache[int(index)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLy3_NC-2EZ-",
        "colab_type": "text"
      },
      "source": [
        "### Save Your Preprocessed Data as an HDF5 File\n",
        "\n",
        "If your data doesn't fit into memory, another thing you can do is save your data as an [hdf5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) file.  We have found that this can give you a similar performance boost to caching the data in memory.  In this workflow you would use the code below to convert your dataset into an hdf5 file, save it to your Google Drive, and then modify your code to download the file each time you want to train your network.\n",
        "\n",
        "In the example below, we assume that we already have created a dataset called cal_tech (you could created this using our sample code).  We will create an hdf5 file and populate it with the data from cal_tech.  If you want to use this code, you'd have to modify it for the particular aspects of your preprocessed dataset (e.g., resolution of the images)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntr1kkCC7LKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "\n",
        "h5_file = h5py.File(\"caltech.hdf5\", 'w')\n",
        "# note: 128 by 128 is the preprocessed size of this dataset\n",
        "data = h5_file.create_dataset('data', shape=(len(cal_tech), 3, 128, 128), dtype=np.float32)\n",
        "targets = h5_file.create_dataset('targets', shape=(len(cal_tech),), dtype=np.long)\n",
        "\n",
        "# loop through all the data and populate the hdf5 file\n",
        "for i, (im, target) in enumerate(cal_tech):\n",
        "    if i % 2000 == 0:\n",
        "        print(i)\n",
        "    data[i] = im.to('cpu')\n",
        "    targets[i] = target\n",
        "h5_file.close()\n",
        "\n",
        "# download the dataset to Google Drive using rsync\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!rsync -ah --progress caltech.hdf5 /content/gdrive/My\\ Drive/Datasets\\ for\\ ML\\ Class/caltech.hdf5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiFCEpZE733O",
        "colab_type": "text"
      },
      "source": [
        "To use the generated dataset on subsequent runs, you can use the following Dataset class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs6tu5Yy8Byz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.datasets import VisionDataset\n",
        "\n",
        "class H5Dataset(VisionDataset):\n",
        "    def __init__(self, h5_path):\n",
        "        \"\"\" Initialize the dataset with the path to the hdf5 file.  You could\n",
        "            Also add support for transforms, but we decided to leave that out.\n",
        "        \"\"\"\n",
        "        super(H5Dataset, self).__init__('.', transform=None, target_transform=None)\n",
        "        self.h5_file = h5py.File(h5_path, 'r', libver='latest', swmr=True)\n",
        "        self.target_cache = []\n",
        "        # caching the targets speeds up training\n",
        "        for i in range(len(self)):\n",
        "            self.target_cache.append(self.h5_file['targets'][i])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.h5_file['data'][index], self.target_cache[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.h5_file['data'])\n",
        "\n",
        "    def close_dataset(self):\n",
        "        self.h5_file.close()\n",
        "\n",
        "# for example\n",
        "cal_tech = H5Dataset('caltech.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5o_Ri5TxsLf",
        "colab_type": "text"
      },
      "source": [
        "## Weight Decay\n",
        "\n",
        "* https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7ZaBjhRzrtJ",
        "colab_type": "text"
      },
      "source": [
        "## Do some image normalization\n",
        "\n",
        "* https://discuss.pytorch.org/t/understanding-transform-normalize/21730/7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJdOGCNbzuKM",
        "colab_type": "text"
      },
      "source": [
        "## Test with Out-of-dataset images\n",
        "\n",
        "One interesting thing you can try is to test your network on images you collect (or that are from a dataset you didn't use for traning).  One thing to watch out for is to make sure your input images have similar average R, G, B values to the images in your data.   Image normalization can be particularly useful for doing this.  Further, comparing how well out-of-dataset images work with and without image normalization could be particularly interesting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roDFGg_F2N7j",
        "colab_type": "text"
      },
      "source": [
        "## Do Some Data Augmentation\n",
        "\n",
        "If you want your system to be more robust to rotations, translations, and other sorts of variation, you can augment your data by randomly generating transformed versions of the original images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC4DQND8zW-D",
        "colab_type": "text"
      },
      "source": [
        "## Modify the Optimizer\n",
        "\n",
        "* Change learning rate\n",
        "* Try a different optimizer (explore various parameter settings)\n",
        "* [Other ideas](https://pytorch.org/docs/stable/optim.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TQxSoAq85KS",
        "colab_type": "text"
      },
      "source": [
        "## Visualize What Your Network is Doing\n",
        "\n",
        "While we are still working on a more complete writeup of this, you should certainly consider the following sorts of visualizations.\n",
        "* Show the activation gradients (we showed this in the example on [training on the COCO dataset](https://colab.research.google.com/github/mlfa19/assignments/blob/master/Module%201/m1_project/Examples/Working_with_Large_Datasets_COCO_Example.ipynb))\n",
        "* Maximize the class output (e.g., start with an image from the test set and use gradient ascent to maximize a particular output of the model).\n",
        "* Maximize the output of a particular unit in the network."
      ]
    }
  ]
}