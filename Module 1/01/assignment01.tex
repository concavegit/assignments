\documentclass[assignment01_Solutions]{subfiles}

\IfSubStr{\jobname}{\detokenize{Solutions}}{\toggletrue{solutions}}{\toggletrue{solutions}}

%\IfSubStr{\jobname}{\detokenize{Solutions}}{\toggletrue{solutions}}{\togglefalse{solutions}}

\fancypagestyle{firstpage}

{\rhead{Assignment 1 \linebreak \textit{Version: \today}}}

\title{Assignment 1: Linear Regression}
\author{Machine Learning}
\date{Fall 2019}

\begin{document}

\maketitle
\thispagestyle{firstpage}


\begin{learningobjectives}
\bi
\item Gain some familiarity with some of the key ideas in machine learning.
\item Review of mathematical concepts we will be using in the beginning part of this course.
\item Familiarizing yourself with computational toolset
\item Learn linear regression using a ``top-down approach.''
\ei
\end{learningobjectives}


\begin{priorknowledge}
\bi
\item Basic machine learning terminology
\item Supervised learning problem framing
\ei
\end{priorknowledge}


\begin{recall}[Supervised Learning Problem Setup]
In the last class we saw the basic supervised learning problem setup.

Suppose you are given a training set of datapoints, $(\mlvec{x_1}, y_1), (\mlvec{x}_2, y_2), \ldots, (\mlvec{x}_n, y_n)$ where each $\mlvec{x_i}$ represents an element of an input space (e.g., a d-dimensional feature vector) and each $y_i$ represents an element of an output space (e.g., a scalar target value).  In the supervised learning setting, your goal is to determine a function $\hat{f}$ that maps from the input space to the output space.

We typically also assume that there is some loss function, $\ell$, that determines the amount of loss that a particular prediction $\hat{y}_i$ incurs due to a mismatch with the actual output $y_i$.  We can define the best possible model, $\hat{f}^\star$ as the one that minimizes these losses over the training set.  This notion can be expressed with the following equation  (note: that $\argmin$ in the equation below just means the value that minimizes the expression inside of the $\argmin$, e.g., $\argmin_{x} (x - 2)^2 = 2$, whereas $\min_{x} (x-2)^2 = 0$).
\begin{align}
\hat{f}^\star &= \argmin_{\hat{f}} \sum_{i=1}^n \ell \left ( \hat{f}(\mlvec{x_i}), y_i \right )
\end{align} 

\end{recall}



\section{Six Big Ideas in Machine Learning}
Before diving into the specifics of our first machine learning algorithm, let's examine some important ideas in machine learning.  Why six instead of seven?  if Rob Martello has taught us anything, it's that all good things come in sixes.%  For this set of six big ideas, we'll pay special attention to those that are most relevant to the module at hand (computer vision).


\subsection*{Idea 1: Correlations for the Win?}
ML algorithms learn to exploit correlations in data in order to make predictions.  For instance, if one was using a machine learning approach to learn to recognize smiles from images, the algorithm might determine that bright pixels around the mouth area of a face are correlated with smiling faces (e.g., they indicate that a person's teeth are showing).  This correlation would likely be useful for determining whether a new image of a face was a smile or not.  Unfortunately, while exploiting correlations is one of the most powerful aspects of ML systems, it is also one of the most potentially problematic aspects.


\bi

\item \emph{Example 1: Reinforcing Hiring Biases}
You likely heard the news that \href{https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G}{Amazon scrapped a secret AI recruiting tool that showed bias against women}.  More specifically, the tool performed automatic keyword analysis of job applications to predict whether or not the the applicant was worth forwarding on to a human evaluator for a closer look.  Early in the development of this system, researchers discovered that the model the system had learned placed a negative weight on words such as ``women's'' as well as the names of some women's colleges.  While there is of course no causal link between these words appearing in a job application and the suitability of the candidate for the job, there was a \emph{correlation} in the training set that was used to build the system between the presence of words such as ``women's'' and the candidates not being invited for interviews.

Why might such a correlation exist in the training set?  There are many different possible explanations for this correlation, ranging from overt or unconscious bias in the applicant evaluators whose judgments helped form the training data to systemic discrimination that denies women equal access to educational opportunities in STEM.  The important thing to take away from this is not that why there was a correlation, but that since the correlation existed in the training data the model learned to utilize that in order to evaluate new data.  Amazon realized that this was suboptimal and decided to take steps to address the problem (they say they never used the system to make actual job-screening decisions).  Despite efforts to prevent the algorithm for exploiting such correlations, the group determined that they couldn't fully guarantee that the algorithm had not found another way to achieve the same discriminatory outcome and terminated the project.


\item \emph{Example 2: Adversarial Machine Learning}

A second example of an ML algorithm exploiting correlations in training data in unexpected ways can be found in the field of of computer vision methods for object detection.  Identifying salient visual objects such as road signs and pedestrians is an important building block for applications such as autonomous driving.  A popular algorithm for this task, \href{https://pjreddie.com/darknet/yolo/}{YOLO} (You Only Look Once)\footnote{\href{https://www.youtube.com/watch?time_continue=77&v=MPU2HistivI}{Cool video of YOLO version 3}, \href{https://www.youtube.com/watch?v=Cgxsv1riJhI}{TED talk from the YOLO head researcher}}, can identify and localize objects in images with surprisingly good accuracy.  For instance, in the image below you can see how YOLO can be used to detect stop signs in an image.
\begin{center}
\includegraphics[width=0.6\linewidth]{figures/stopsignyolo}
\end{center}

While this all seems great, and YOLO achieves high accuracy at tasks such as this, there is a catch.  It is very difficult to understand \emph{how} YOLO is making these predictions.  That is, what is it about this image that causes the YOLO algorithm to be able to tell that it is a stop sign?  Perhaps it is the white text on the red background.  Perhaps it is the actual word ``STOP.''  The fact is that the network that makes this prediction is so complex, that is impossible for us to say definitively exactly how it makes its decision.

\begin{marginfigure}
\includegraphics[width=1.6in]{figures/yolofooled}
\caption{A stop sign with a specially crafted sticker that causes a neural network to fail to identify it as as top sign.}\label{fig:yolofooled}
\end{marginfigure}
The complexity of the model makes it vulnerable to bad actors (or adversaries).  Researchers at University of Michigan used a form of ML known as \emph{adversarial machine learning} to \href{https://iotsecurity.engin.umich.edu/physical-adversarial-examples-for-object-detectors/}{create a specially crafted sticker that could be attached to a stop sign that would make it invisible to the YOLO model} (that is YOLO would not identify it as a stop sign).  Clearly, this has major implications for the safety of using a model such as this in an application like a self-driving car.   An example of the attach is shown in Figure~\ref{fig:yolofooled}.


\ei

\subsection*{Idea 2: There's No Such Thing as a Free Lunch}

\begin{quotation}
\href{https://en.wikipedia.org/wiki/All_models_are_wrong}{``All models are wrong, but some useful.''}

--- George Box
\end{quotation}

At the beginning of this document we have a reminder of the basic supervised machine learning setup.  At the most basic level, we try generalize from a set of training data to construct a function $\hat{f}^\star$ that best predicts the corresponding output data for unseen input data (e.g., predicting the facial expression of a face that was not in the training set based on a training set of sample faces and their corresponding expressions).  In the previous big idea, we discussed how machine learning could go wrong when there are correlations in the data that seem useful to the ML algorithm, but are ultimately counterproductive to how we'd like the system to make decisions.  It turns out that even before you choose the training for your algorithm, you must provide an \href{https://en.wikipedia.org/wiki/Inductive_bias}{inductive bias} to constrain the space of possible models you might fit.  Examples of common inductive biases include the following (the previously linked article has some more).
\be
\item The prediction function $\hat{f}^\star$ should smoothly change as you vary the input $\mlvec{x}$.
\item The prediction function has a particular form (e.g., linear).
\item The prediction function is sparse in that it ignores the majority of the inputs.
\ee

In fact, there are a whole class of theorems called \href{https://en.wikipedia.org/wiki/No_free_lunch_theorem}{No-Free-Lunch (NFL) theorems} that state that without inductive biases (such as the ones stated above), learning from data is essentially impossible.  This connects us back to the quote from George Box.  While the inductive bias we encode into our model will never be a fully represent reality, having this bias is necessary to allow the model to do the useful work of making predictions.  What's important for us as machine learning scientists and practitioners is to be explicit about the biases we are introducing when settling on a particular model so that we can best evaluate our results and predict the limitations of our systems.

\subsection*{Idea 3: It's All About How You Frame the Problem}
Using Machine Learning algorithms can be a bit disorienting for someone used to the typical engineering workflow.  A cartoon picture of the engineering workflow is that you are given a problem (perhaps it is initially difficult to solve or ambiguous), you might reframe the problem to make it easier to solve, and then you work to devise a solution to the reframed problem.  In machine learning, the last step is automated!  Your job as an ML practitioner is to reframe the original problem so that the ML algorithm can compute a solution.  If you've done the reframing properly, the solution to the reframed problem will also be a good solution to the original problem.

As an example, consider the use of a machine learning algorithm to teach a virtual character to walk in a simulated environment.  You might reframe this problem for the ML algorithm as tasking it with computing a controller for the virtual character that moves the character's center of mass forward as fast as possible.  The ML algorithm can now search over a vast space of possible control strategies to learn the one that most quickly propels the center of mass.  However, it doesn't necessarily follow that this controller will result in the character walking using a normal bipedal gait.

\begin{center}
\includegraphics[width=.6\linewidth]{figures/fallingbot}
\end{center}

The notion that the solution an algorithm finds might be unpredictable to the designer is known as ``emergence.''  Some cool examples of this played out in actual experiments in evolving virtual creatures are summarized in the paper \href{https://arxiv.org/pdf/1803.03453.pdf}{The Surprising Creativity of Digital Evolution}.  For instance, a virtual character learned that falling down, see picture above, and getting up was more efficient for locomotion than constantly hopping (which is what the designer had intended the system to learn).

For more examples of this sort of thing, consider checking out \href{https://www.youtube.com/watch?v=bBt0imn77Zg}{Karl Sims: Evolved Virtual Creatures} or the short article \href{https://aiweirdness.com/post/172894792687/when-algorithms-surprise-us}{When AI Surprises Us}.  This also connects back to the age-old debate over whether \href{https://www.youtube.com/watch?v=8M_1GAX3WcI}{falling with style can be considered flying}.


\subsection*{Idea 4: ML Systems Can Learn Intermediate Representations}

In the next few weeks we'll learn about artificial neural networks (ANNs).  ANNs are biologically inspired algorithms since their functioning, at an abstract level, is modeled on the functioning of biological neurons (e.g., in the brain).

\begin{marginfigure}
\includegraphics[width=1.8in]{figures/Colored_neural_network}
\caption{An artificial neural network with a single hidden layer.}\label{fig:ann}
\end{marginfigure}
ANNs accept input patterns at an array of virtual neurons called the input layer (see Figure~\ref{fig:ann}).  The neurons in the input layer are connected to other neurons via virtual axons that control to what extent a particular input neuron activates a downstream neuron.  The second set of neurons, called the ``hidden layer'' (shown in blue in the figure), is responsible for computing intermediate, hidden representations of the input data.  This process continues as activations propagate through the network until activations are generated at the output layer (shown in green). These outputs could correspond to any salient properties of the input (e.g., if the input is an image, the output might encode the objects in the image).

What's amazing about ANNs is that there are learning algorithms for setting the connections strengths between these virtual neurons (the black arrows in the figure) based on training data (input / output pairs).  These learning algorithms tune the connections strengths (also called ``weights'') such that for the provided training data, the network produces the appropriate training outputs (e.g., if you show the network a training set of images of cats or dogs, over time the network will adjust its weights so that the output says ``cat'' when presented an image of a cat and ``dog'' if presented an image of a dog).  The algorithms used to tune the network weights are only concerned with reproducing the output patterns, the network is free to choose how it represents information within the network (i.e., at the hidden layer).

\begin{marginfigure}

\caption{12x12 receptive fields learned from an neural network trained to optimally compress images}
\includegraphics[width=1.5in]{figures/learned_receptive_fields}\label{fig:learnedfields}
\end{marginfigure}
What's super amazing is that we can actually examine the internal representations of a neural network to understand how it's performing the computation from input to output. For instance, Figure~\ref{fig:learnedfields}\footnote{From \href{http://www.cnbc.cmu.edu/~tai/nc19journalclubs/Olshausen-Field-CON-2004-1.pdf}{Sparse coding of sensory inputs}} shows a visualization of the internal representations learned by a network trained to best compress a training set of images (these sorts of networks are called ``auto-encoders'').  The receptive fields of each of the hidden units in the network and can be understood as specifying how each input pixel activates a particular hidden unit (gray corresponds to no activation, black to negative activation, and white to positive activation).  It's remarkable that these receptive fields have coherent structure: they are localized in space, tuned to a particular orientation, and tuned to features at a particular scale.  You can think of these as oriented edge detectors that the network learned completely on its own (it was never told to try and extract edges from the images in the training set).

What's super-duper amazing is that if we compare the receptive fields learned by the artificial neural network to the \href{https://en.wikipedia.org/wiki/Simple_cell}{simple cells} in the primary visual cortex of a cat, there are a number of striking similarities.  Just as in the ANN, the biological neural network responds to edges at particular orientations and scales.  The scientists Hubel and Wiesel performed the pioneering work in neuroscience to establish the properties of receptive fields in the primary visual cortex.  Consider watching \href{https://www.youtube.com/watch?v=8VdFf3egwfg}{a video of their experiment} that eventually garnered a Nobel prize (note that in the video the static sound corresponds to the measurement of spikes in activity of an individual neuron in the brain of an anesthetized cat.\footnote{There are a variety of opinions on the \href{https://en.wikipedia.org/wiki/Animal_testing\#Ethics}{ethics of performing research on animals}}


\subsection*{Idea 5: Machine Learning Zoomed Out}

Historically, most ML courses have been hyper-focused on the learning about learning algorithms (e.g., neural networks, support vector machines, decision trees, etc.).  The learning algorithms 

\begin{center}
\includegraphics[width=.6\linewidth]{figures/MlSystem}
\end{center}

Also include the Alexa figure that Sam Daitzman found.

Also link to papers (e.g., \href{https://link.springer.com/article/10.1007/s11023-017-9417-6}{this} or \href{https://dl.acm.org/citation.cfm?id=3287598}{this}) on the socio-technical view of AI.


\subsection*{Idea 6: It's Not All Doom and Gloom}
While we'll be talking a lot about how ML can go wrong, unleashing unexpected consequences, we'll also be talking about the positive things that ML can do.  TODO: write this.


\begin{exercise}
t
\end{exercise}

\section{Mathematical Background}


\begin{notice}
For the purposes of this class, we will be consistent with the notation we use.  Of course, when we link to other resources, they may use other notation.  If notation is different in a way that causes confusion, we will try to point out pitfalls you should watch out for.  A guide to our notation conventions can be found on Canvas.\marginnote{link out when we have this posted}
\end{notice}

In order to engage with this assignment, you'll want to make sure you are familiar with the following concepts (links to resources embedded below):
\bi
\item vector-vector multiplication
\bi
\item Section 2.1 of \href{https://see.stanford.edu/materials/aimlcs229/cs229-linalg.pdf}{Zico Kolter's Linear Algebra Review and Reference}
\ei
\item Matrix-vector multiplication
\bi
\item Section 2.2 of \href{https://see.stanford.edu/materials/aimlcs229/cs229-linalg.pdf}{Zico Kolter's Linear Algebra Review and Reference}
\item The first bits of the Khan academy video on \href{https://www.khanacademy.org/math/linear-algebra/matrix-transformations/linear-transformations/v/matrix-vector-products-as-linear-transformations}{Linear Transformations}
\ei
\item partial derivatives and gradients
\bi
\item Khan Academy videos on partial derivatives: \href{https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivatives/v/partial-derivatives-introduction}{intro}, \href{https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivatives/v/partial-derivatives-and-graphs}{graphical understanding}, and \href{https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivatives/v/formal-definition-of-partial-derivatives}{formal definition}
\item \href{https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/gradient-and-directional-derivatives/v/gradient}{Khan Academy video on Gradient}
\ei
\ei

\section{Linear Regression from the Top-Down}

\subsection*{Motivation: Why Learn About Linear Regression?}
Before we jump into the \emph{what} of linear regression, let's spend a little bit of time talking about the \emph{why} of linear regression.  As you'll soon see, linear regression is among the simplest (perhaps \emph{the} simplest) machine learning algorithm.  It has many limitations, which you'll also see, but also a of ton strengths.  \textbf{First, it is a great place to start when learning about machine learning} since the algorithm can be understood and implemented using a relatively small number of mathematical ideas (you'll be reviewing these ideas later in this assignment).  In terms of the algorithm itself, it has the following very nice properties.

\bi
\item \textbf{Transparent:} it's pretty easy to examine the model and understand how it arrives at its predictions.
\item \textbf{Computational tractable:} linear regression models can be trained efficiently on datasets with large numbers of features and data points.
\item \textbf{Easy to implement:} linear regression can be implemented using a number of different algorithms (e.g., gradient descent, closed-form solution).  Even if the algorithm is not built into your favorite numerical computation library, the algorithm can be implemented in only a couple of lines of code.
\ei


For linear regression we assume that our input points, $\mlvec{x_i}$, are d-dimensional vectors (each entry of these vectors can be though of as a feature), that our output points, $y_i$, are scalars, and that our prediction functions $\hat{f}$ are all of the form $\hat{f}(\mlvec{x}) = \mlvec{w}^\top \mlvec{x} = \sum_{i=1}^d w_i x_i$ for some vector of weights $\mlvec{w}$ (you could think of $\hat{f}$ as also taking $\mlvec{w}$ as an input, e.g., writing $\hat{f}(\mlvec{x}, \mlvec{w}$).  When it's obvious what the value of $\mlvec{w}$ is, we'll leave it as an implicit input instead, e.g., writing $\hat{f}(\mlvec{x})$).

In the function, $\hat{f}$, the elements of the vector $\mlvec{w}$ represent weights that multiply various entries of the input.  For instance, if an element of $\mlvec{w}$ is high, that means that as the corresponding element of $\mlvec{x}$ increases, the prediction that $\hat{f}$ generates for $\mlvec{x}$ would also increase (you may want to mentally think through other cases, e.g., what would happen is the element of $\mlvec{x}$ decreases, or what would happen if the entry of $\mlvec{w}$ was large and negative).  The products of the weights and the features are then summed to arrive at an overall prediction.

Given this model, we can now define our very first machine learning algorithm: \href{https://en.wikipedia.org/wiki/Ordinary_least_squares}{ordinary least squares} (OLS)!  In the ordinary least squares algorithm, we use our training set to select the $\mlvec{w}$ that minimizes the sum of squared differences between the model's predictions and the training outputs.  Thinking back to the supervised learning problem setup, this corresponds to choosing $\ell(y, \hat{y}) = (y - \hat{y})^2$.
Therefore, the OLS algorithm will use the training data to select the optimal value of $\mlvec{w}$ (called $\mlvec{w}^\star$), which minimizes the sum of squared differences between the model's predictions and the training outputs.

\begin{align}
\mlvec{w}^\star &= \argmin_{\mlvec{w}} \sum_{i=1}^n \ell \left ( \hat{f}(\mlvec{x_i}, \mlvec{w}) , y_i \right) \\
\mlvec{w}^\star &= \argmin_{\mlvec{w}} \sum_{i=1}^n \left ( \hat{f}(\mlvec{x_i}, \mlvec{w}) - y_i \right)^2 \\
&= \arg\min_{\mlvec{w}} \sum_{i=1}^n \left ( \mlvec{w}^\top \mlvec{x_i} - y_i \right)^2
\end{align}

While we haven't talked at all about how to find $\mlvec{w}^\star$, that will be the focus of a later part of this assignment, once we have $\mlvec{w}^\star$ we can predict a value for a new testing point, $\mlvec{x}$, by predicting that the corresponding (unknown) label, $y$, as $\hat{y} = \mlvec{w}^\top \mlvec{x}$.  In this way, we have used the training data to learn how to make predictions about unseen data points, which is the hallmark of supervised machine learning!

\begin{exercise}
Todo: Some conceptual questions to check understanding
\end{exercise}

\section{Getting a Feel for Linear Regression}
In this class we'll be learning about algorithms using both a top-down and a bottom-up approach.  By bottom-up we mean applying various mathematical rules to derive a solution to a problem and only then trying to understand how to apply it and how it well it might work for various problems.  By top-down we mean starting by applying the algorithm to various problems and through these applications gaining a sense of the algorithm's properties before learning how to derive / implement it.  We'll start our investigation of linear regression using a \textbf{top-down approach}.


\subsection{Linear Regression with One Input Variable: Line of Best Fit}

If any of what we've said so far sounds familiar, it is likely because you have seen the idea of a line of best fit in some previous class.  To understand more intuitively what the OLS algorithm is doing, we want you to investigate its behavior when there is a single input variable (i.e., you are computing a line of best fit).  Use the \href{http://www.shodor.org/interactivate/activities/Regression/}{line of best fit online app} to create some datasets, guess the line of best fit, and then compare the results to the OLS solution.

\todo{It would have been cool to find something that visualized linear regression with two input variables, but I couldn't find it easily.  At a minimum we need to actually write down the formula we are fitting.}

\begin{exercise}
Todo: Some conceptual questions to check understanding of what happened here.
\end{exercise}



\subsection{Linear Regression with Multiple Input Variables: Explorations in Python}
Work through the \href{https://colab.research.google.com/drive/12pLbQkhrPoI-22FVV6gZNObi1IJCW-mF}{Assignment 1 Companion Notebook} to get some practice with {\tt numpy} and explore linear regression using a top-down approach.  You can place your answers directly in the Jupyter notebook so that you have them for your records.

\section{Linear Regression from the Bottom-up}

Now that you have some idea of how the algorithm behaves, let's figure out how to implement it.  That is, how do we find the vector $\mlvec{w}$ that best fits a dataset?

\subsection{Linear regression with one variable}

Before handling the case where each $\mlvec{x}$ is a d-dimensional vector, we'll derive the algorithm for the simple case where $\mlvec{x}$ is a scalar (i.e., $d=1$).

\begin{exercise}
\bes
\item Given a dataset $(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)$ (where each $x_i$ and each $y_i$ is a scalar) and a potential value of $w$, write an expression for the sum of squared errors between the model predictions, $\hat{f}$, and the targets, $y_i$.

\iftoggleverb{solutions}
\begin{boxedsolution}
\begin{align}
e(w) &= \sum_{i=1}^n \left (  w x_i - y_i \right)^2
\end{align}
\end{boxedsolution}
\fi

\item Compute the derivative the error function you found in part (a).

\iftoggleverb{solutions}
\begin{boxedsolution}
\begin{align}
\frac{de}{dw} &= \sum_{i=1}^n 2 \left (  w x_i - y_i \right)x_i \\
&= w \sum_{i=1}^n 2 x_i^2 - \sum_{i=1}^n 2 x_i y_i
\end{align}
\end{boxedsolution}
\fi

\item Set the derivative to 0, and solve for $w^\star$.  $w^\star$ corresponds to a critical point of your sum of squared errors function.  We will show in a later assignment that this is critical point corresponds to a global minimum.  In other words, this value of $w$ is guaranteed to drive the sum of squared errors as low as possible.

\iftoggleverb{solutions}
\begin{boxedsolution}
\begin{align}
\frac{de}{dw} &= 0 \\
&= w \sum_{i=1}^n 2 x_i^2 - \sum_{i=1}^n 2 x_i y_i \\
\sum_{i=1}^n 2 x_i y_i  &= w \sum_{i=1}^n 2 x_i^2 \\
w^\star &=\frac{\sum_{i=1}^n x_i y_i}{\sum_{i=1}^n x_i^2}
\end{align}
\end{boxedsolution}
\fi

\ees


\end{exercise}
We can start here and then motivate the mathematical tricks.

\subsection{Building our bag of mathematical tricks}

\begin{exercise}[30 minutes]
\bes
\item Quadratic forms \href{https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/quadratic-approximations/v/expressing-a-quadratic-form-with-a-matrix}{really nice Khan Academy video showing this}
\item FOIL method for matrix multiplication

\item Using the definition of the gradient, show that $\nabla \mlvec{c}^\top \mlvec{x} = \mlvec{c}$ where the gradient is taken with respect to $\mlvec{x}$ and $\mlvec{c}$ is a vector of constants.

\iftoggleverb{solutions}

\begin{boxedsolution}

\begin{align}
\mlvec{c}^\top \mlvec{x} &= \sum_{i=1}^d c_i x_i \\
\frac{\partial  \sum_{i=1}^d c_i x_i }{\partial x_i} &= c_i  \\
\nabla \mlvec{c}^\top \mlvec{x} &= \mlvec{c}
\end{align}

\end{boxedsolution}

\fi


\item Using the definition of the gradient, show that the $\nabla \mlvec{x}^\top \mlmat{A} \mlvec{x} = 2 \mlmat{A} \mlvec{x}$ where the gradient is taken with respect to $\mlvec{x}$ and $\mlmat{A}$ is a \emph{symmetric} $dxd$ matrix of constants.  If you'd like, you can utilize the fact (without deriving it yourself) that $\mlvec{x}^\top \mlmat{A} \mlvec{x} = \sum_{i=1}^d\sum_{j=1}^d x_i x_j a_{i, j}$.%  \todo{this might be too hard... Can we make this optional with appropriate sign-posting.... you can prove this is true, but you do not need to do so in order to make progress.  It can also be made easier if you assume $A$ is symmetric.}
\ees

\iftoggleverb{solutions}
\begin{boxedsolution}

\begin{align}
\mlvec{x}^\top \mlmat{A} \mlvec{x} &= \begin{bmatrix} x_1 \\ \vdots \\ x_d \end{bmatrix}^\top \begin{bmatrix} a_{1,1} & \ldots &  a_{1,d} \\
\vdots &  \ddots &  \vdots \\
a_{d,1} & \ldots & a_{d,d}
\end{bmatrix} \begin{bmatrix}x_1 \\ \vdots \\ x_d \end{bmatrix} \\
&= \begin{bmatrix} x_1 \\ \vdots \\ x_d \end{bmatrix}^\top\sum_{i=1}^d x_i \begin{bmatrix} a_{i, 1} \\ \vdots \\ a_{i,d} \end{bmatrix} \\
&= \sum_{i=1}^d x_i \sum_{j=1}^d x_j  a_{i, j} \\
&= \sum_{i=1}^d\sum_{j=1}^d   x_i  x_j  a_{i, j} \\
\frac{\partial (\mlvec{x}^\top \mlmat{A} \mlvec{x})}{\partial x_i} &= \sum_{j=1}^d x_j a_{i,j} + \sum_{j=1}^d x_j a_{j, i} \\
&= \left ( \mlmat{A} \mlvec{x} \right)_i + \left ( \mlmat{A}^\top \mlvec{x} \right)_i \\
&= 2\left ( \mlmat{A} \mlvec{x} \right)_i \\
\nabla \mlvec{x}^\top \mlmat{A} \mlvec{x} &= 2 \mlmat{A}\mlvec{x}
\end{align}

\end{boxedsolution}

\fi

\end{exercise}

\section{Linear Regression with Multiple Variables}
\textbf{We might need to choose between this and a reading. If we do the reading, this will be done in class.}
Suppose you are given a training set of datapoints, $(\mlvec{x_1}, y_1), (\mlvec{x}_2, y_2), \ldots, (\mlvec{x}_n, y_n)$ where each $\mlvec{x_i}$ is a d-dimensional input vectors each $y_i$ is a scalar representing a target output.
\begin{exercise}[60 minutes]
Next, let's consider the more general case where $\mlvec{w}$ is a d-dimensional vector.  In order to solve this problem, you'll be leveraging some of the new mathematical tricks you picked up earlier in the assignment.  As you go through the problem, try as much as possible to treat vectors as first-class objects (e.g., work with the gradient instead of the individual partial derivatives).
\bes
\item Given $\mlvec{w}$, write an expression for the sum of squared errors between each prediction $\hat{f}(\mlvec{x})$ and training output $y_i$.  If your expression initially contains a summation, rewrite it as the inner product between some vector $\mlvec{v}$ and itself (i.e. $\mlvec{v}^\top \mlvec{v}$).  In rewriting your expression as an inner-product, you may find it useful to refer to the matrix that contains all of your training data $\mlmat{X} = \begin{bmatrix} \mlvec{x}_1^\top \\ \mlvec{x}_2^\top \\ \vdots \\ \mlvec{x}_n^\top \end{bmatrix}$.  You may also want to expand your inner product using the FOIL method for matrices that we learned about earlier.

\iftoggleverb{solutions}
\begin{boxedsolution}
\begin{align}
e(\mlvec{w}) &= \left ( \mlmat{X} \mlvec{w} - \mlvec{y} \right)^\top  \left ( \mlmat{X} \mlvec{w} - \mlvec{y} \right) \\
&= \mlvec{w}^\top \mlmat{X}^\top \mlmat{X} \mlvec{w} - 2 \mlvec{w}^\top \mlmat{X}^\top \mlvec{y} + \mlvec{y}^\top \mlvec{y}
\end{align}
\end{boxedsolution}
\fi

\item Compute the gradient of the sum of squared errors that you found in part (a).
\iftoggleverb{solutions}
\begin{boxedsolution}
\begin{align}
\nabla e(\mlvec{w})  &= 2 \mlvec{X}^\top \mlvec{X} \mlvec{w} - 2 \mlmat{X}^\top \mlvec{y}
\end{align}
\end{boxedsolution}
\fi

\item Set the gradient to 0, and solve for $\mlvec{w}$.  This value of $\mlvec{w}$ corresponds to a critical point of your sum of squared errors function.  We will show in a later assignment that this is critical point corresponds to a global minimum.  In other words, this value of $\mlvec{w}$ is guaranteed to drive the sum of squared errors as low as possible (note: you can assume that $\mlmat{X}^\top \mlmat{X}$ is invertible).

\iftoggleverb{solutions}
\begin{boxedsolution}
\begin{align}
\nabla e(\mlvec{w})  &= 0 \\
&= 2 \mlvec{X}^\top \mlvec{X} \mlvec{w} - 2 \mlmat{X}^\top \mlvec{y}\\
\mlvec{w} &= \left ( \mlmat{X}^\top \mlmat{X} \right )^{-1} \mlmat{X}^\top \mlmat{y}
\end{align}
\end{boxedsolution}
\fi

\ees
\end{exercise}
%
%\section{Connecting Bottom-up and Top-down}
%\textbf{Won't have time for this, maybe we do this in-class}Revisit earlier problem using the math that you just learned?  Could also do something more interesting (e.g., bump detection dataset from Comprobo).



\section{Context and Ethics Reading}
What's the best thing to give here?  Should it be a reading about FAT in ML?  My other thought would be on \href{https://statisticsbyjim.com/regression/confounding-variables-bias/}{confounding variable bias}



\end{document}
